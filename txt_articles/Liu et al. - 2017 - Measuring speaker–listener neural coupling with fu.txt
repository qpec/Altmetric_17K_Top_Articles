 1
Scientific RepoRts | 7:43293 | DOI: 10.1038/srep43293
www.nature.com/scientificreports
Measuring speaker–listener neural 
coupling with functional near 
infrared spectroscopy
Yichuan Liu1, Elise A. Piazza2, Erez Simony2, Patricia A. Shewokis1,3, Banu Onaral1, 
Uri Hasson2,4 & Hasan Ayaz1,5,6
The present study investigates brain-to-brain coupling, defined as inter-subject correlations in 
the hemodynamic response, during natural verbal communication. We used functional near-
infrared spectroscopy (fNIRS) to record brain activity of 3 speakers telling stories and 15 listeners 
comprehending audio recordings of these stories. Listeners’ brain activity was significantly correlated 
with speakers’ with a delay. This between-brain correlation disappeared when verbal communication 
failed. We further compared the fNIRS and functional Magnetic Resonance Imaging (fMRI) recordings 
of listeners comprehending the same story and found a significant relationship between the fNIRS 
oxygenated-hemoglobin concentration changes and the fMRI BOLD in brain areas associated with 
speech comprehension. This correlation between fNIRS and fMRI was only present when data from the 
same story were compared between the two modalities and vanished when data from different stories 
were compared; this cross-modality consistency further highlights the reliability of the spatiotemporal 
brain activation pattern as a measure of story comprehension. Our findings suggest that fNIRS can be 
used for investigating brain-to-brain coupling during verbal communication in natural settings.
Verbal communication involves the relaying of information between individuals through the use of sound pat-
terns within a structure of language. For decades, neuroimaging technologies have been applied to study the 
neural mechanisms underlying the production and comprehension of language. Multiple brain areas have been 
identified to be involved with verbal communication using Positron Emission Tomography (PET) and functional 
Magnetic Resonance Imaging (fMRI)1, whereas the timing of auditory processing was studied with the aid of 
Electroencephalogram (EEG) and Magnetoencephalogram (MEG)2–7. Although important findings have been 
discovered using these technologies, there are two limitations in traditional neurolinguistic studies. First, these 
studies are mostly concerned with the cognitive process of either speech production or speech comprehension 
and confine the analysis to be within individual brains. Verbal communication, however, is an interactive process 
between speaker and listener. As pointed out by Hasson and others8, a complete understanding of the cognitive 
processes involved cannot be achieved without examining and understanding the interaction of neural activity 
among individuals. Second, cognitive functions are traditionally studied in a controlled laboratory environment. 
While this practice helps to isolate various factors (e.g. syntactical transformations or the representation of iso-
lated lexical items), the ecological validity of the findings is not clear until tested in a real-life context. In addition, 
many studies confined the auditory stimuli to short lengths, often using isolated words or sentences for experi-
mental control1,7,9. As a result, questions regarding the brain’s ability to accumulate information over longer time 
scales cannot be effectively investigated8,10,11.
With the recent advances in neuroimaging systems and methodology, researchers can now address which 
brain processes are involved in social interaction. Stephens et al. investigated the alignment (correlation) of neu-
ral activity between speaker and listener during natural verbal communication using fMRI12. In the study, brain 
activity was recorded when a speaker was telling a real-life story and later when listeners were listening to the 
audio recording of the story. Listeners’ brain activity was found to be coupled with the speaker’s brain activity 
1School of Biomedical Engineering, Science & Health Systems, Drexel University, Philadelphia, PA, USA. 2Princeton 
Neuroscience Institute, Princeton University, Princeton, NJ, USA. 3Nutrition Sciences Department, College of 
Nursing and Health Professions, Drexel University, Philadelphia PA, USA. 4Department of Psychology, Princeton 
University, Princeton, NJ, USA. 5Department of Family and Community Health, University of Pennsylvania, 
Philadelphia, PA, USA. 6Division of General Pediatrics, Children’s Hospital of Philadelphia, Philadelphia, PA, USA. 
Correspondence and requests for materials should be addressed to H.A. (email: hasan.ayaz@drexel.edu)
received: 14 October 2016
Accepted: 20 January 2017
Published: 27 February 2017
OPEN
 www.nature.com/scientificreports/
2
Scientific RepoRts | 7:43293 | DOI: 10.1038/srep43293
with a delay, although for certain brain areas, listeners were ahead of the speaker in time, possibly due to a pre-
dictive anticipatory effect. Remarkably, higher coupling was found to be associated with better understanding 
of the story. This neural coupling between speaker and listener was further supported by a recent EEG study in 
which the coordination between the brain activity of speakers and listeners was investigated with canonical cor-
relation analysis13. Additional findings in the same EEG study suggest that this speaker-listener neural coupling 
might not be restricted to homologous brain areas. In another study using fMRI, Lerner et al. recorded the Blood 
Oxygenation Level Dependent (BOLD) response of participants listening to a real-life story scrambled at the 
time scales of words, sentences and paragraphs. Inter-subject correlation analyses were employed to estimate the 
reliability of neural responses across subjects, and striking topography differences in brain activation were found 
at the different time scales14.
Although novel findings have been discovered using fMRI and EEG to address the aforementioned challenges, 
certain limitations of the two neuroimaging technologies have hindered the investigation of neural coupling 
during natural verbal communication. fMRI, for example, requires subjects to lie down motionlessly in a noisy 
scanning environment. Simultaneous scanning of multiple individuals engaged in a face-to-face communication 
is impractical for fMRI based setups. EEG, on the other hand, is able to provide a more naturalistic environment. 
However, EEG is susceptible to muscle induced artifacts during vocalization, and is therefore less suitable for 
studying speaker-listener interactions15. Furthermore, the localization of sources from the EEG signal requires 
higher-density recordings and additional computation to solve the inverse problem16–18.
In this study, we propose using functional near-infrared spectroscopy (fNIRS) to investigate speaker-listener 
coupling as an effective complement to the existing studies. fNIRS is an optical brain imaging technology for 
monitoring the concentration changes of oxygenated hemoglobin (Δ 
HbO) and deoxygenated hemoglobin 
 
(Δ 
HbR) in the cortex. By utilizing portable and wearable sensors, fNIRS provides an imaging solution with high 
ecological validity for studying cortical hemodynamic changes in real-life contexts19. Furthermore, fNIRS has 
been used in natural environments, including on mobile individuals outdoors20, consistent with the neuroergo-
nomic and mobile brain/body imaging approaches21,22. fNIRS has been adopted to study brain-to-brain coupling 
during a cooperation-competition game23 and a finger-tapping imitation task24. fNIRS has demonstrated use-
fulness for studying single brain activations during social interactions in a natural setting with traditional block 
design25. At present, studying brain-to-brain coupling during natural verbal communication using fNIRS has not 
been demonstrated.
The main objective of this study is to evaluate speaker-listener brain-to-brain coupling in natural everyday 
settings. To achieve this objective, we designed an fNIRS experiment to replicate the speaker-listener neural 
coupling results from a previous fMRI study12. A native English speaker and two native Turkish speakers told an 
unrehearsed real-life story in their native language. An additional real-life English story E2 (“Pie-man”
, recorded 
at “The Moth”
, a live storytelling event in New York City) used in recent fMRI studies of natural verbal communi-
cation14,26,27, was also used here. The resulting two English stories (E1 and E2) and two Turkish stories (T1 and T2, 
the control conditions) were played to listeners who only understand English. We hypothesized that: (1) the lis-
teners’ brain activity will demonstrate inter-subject correlation only when listening to a story they understand; (2) 
the English speaker’s brain activity during production of E1 will be coupled with the activity of the listeners dur-
ing comprehension. We have targeted both prefrontal and parietal cortices, as these include cognitive and higher 
order extralinguistic areas that are known to be involved in social information processing crucial for successful 
communication including, among others, the capacity to discern the beliefs, desires, and goals of others12,28,29.
A second objective of this study is to compare the fNIRS recorded in this study with the fMRI BOLD response 
recorded in the previous fMRI study14. It has been known that fNIRS and fMRI BOLD signals, both of which are 
based on the neurovascular coupling phenomenon, are correlated in various cognitive tasks30–32. However, pre-
vious studies primarily adopted block designs with simple stimulation to investigate the mean activity induced 
by trigger-averaging a condition over time. The relationship between fNIRS and BOLD during natural verbal 
communication is yet to be shown. To this end, we hypothesized that fNIRS biomarkers (Δ 
HbO and Δ 
HbR) of 
our listeners are correlated with the fMRI BOLD responses of the previously tested listeners14 during the compre-
hension of only the same English story E2 (which all of these listeners heard) and not for the other English story 
E1 and Turkish stories T1 and T2 (which the previously tested fMRI participants did not hear). The convergence 
of fNIRS and fMRI for comprehension of the same story serves as a further validation that fNIRS can be used to 
investigate brain-to-brain coupling during natural verbal communication.
Results
Natural communication unfolds through collective participation of speaker and listener: speakers construct 
grammatical sentences based on thoughts, convert these to motor plans, and execute the plans to produce vocal 
sounds; listeners analyze the sounds, build phonemes into words and sentences, and ultimately decode sound 
patterns into meaning. In our study, we observed significant speaker–listener temporal coupling only during 
successful verbal communication. When communication was blocked (i.e., during listening to a foreign, incom-
prehensible language), the synchronization was lost. As expected, this synchronization was present in a tempo-
rally shifted time course of the speaker’s brain activity relative to the moment of vocalization. Hence, listeners’ 
brain activity mirrors the speaker’s brain activity with a delay. These lagged responses suggest that on average, 
the speaker’s production-based processes precede and likely induce the mirrored activity observed in the listen-
ers’ brains during comprehension. Furthermore, synchronization was also present between listeners with zero 
shift, representing temporally aligned listener-to-listener inter-subject coupling. Again, this coupling was only 
present during successful communication and disappeared when communication was blocked. Finally, we found 
strong consistencies between the evidence from fNIRS and fMRI for the presence of coupling during successful 
communication.
 www.nature.com/scientificreports/
3
Scientific RepoRts | 7:43293 | DOI: 10.1038/srep43293
Listener-listener fNIRS inter-subject correlation. 
For each story, significantly coupled optodes were 
identified using multilevel general linear model (GLM) and the results are shown in Fig. 1. As expected, signifi-
cant results were found only for the English conditions E1 and E2 (false discovery rate33 [FDR] q < 0.01), indicat-
ing that neural coupling only emerges during successful communication (i.e. when subjects understand the story 
content). Δ 
HbO shows a much stronger coupling effect than Δ 
HbR. A contrast for listening comprehension 
using successful communication stories (E1 and E2) minus control conditions (T1 and T2) was further included 
in Fig. 1 as E1 + 
 E2 − 
T1 − 
 T2. Consistent with previous fMRI studies, superior frontal gyrus, inferior parietal and 
angular gyrus were robustly correlated across listeners during speech comprehension34. Although the function of 
these regions is far from clear, they have been associated with various linguistic functions—in particular, semantic 
processing and comprehension35,36.
Speaker-listener fNIRS coupling. 
The neural coupling between speaker and listener may not be restricted to 
homologous brain areas13. Previous studies also showed that the neural responses of listeners can lag behind12,13 or 
precede12 those of the speaker, facilitating comprehension and anticipation, respectively. To investigate these effects, 
multilevel GLM has been adopted to evaluate the coupling between all permutations of (speaker optode, listener 
optode) pairs with the speaker’s time course shifted with respect to those of the listeners from − 
20 s to 20 s in 0.5 s 
increments, where a positive shift represents the speaker preceding (listener lagging), and the results are shown in 
Fig. 2. For the English story E1, the listeners’ fNIRS signals were found to be significantly coupled with the speaker’s 
signal with a 5–7 s time delay, and the number of significantly coupled optodes peaked at 5 s (Fig. 2a). As expected, 
no temporal asymmetry has been found for the listener-listener case and alignment is coupled to the incoming 
auditory input (i.e. lag 0, moment of vocalization) (Fig. 2b). The speaker-listener lagged correlation replicated the 
speaker-listener lagged correlation observed with fMRI12. Significant couplings can mainly be found between pre-
frontal of speaker and parietal of listeners in the medial prefrontal and left parietal areas for Δ 
HbO and no results 
was significant at FDR q < 
 0.01 level for Δ 
HbR (Fig. 2c). The relationships between significantly coupled anatomical 
locations in speaker and listener brains are further listed in Figure S1. These areas include many of the sensory, 
classic linguistic-related, and extralinguistic-related brain areas, demonstrating that areas involved in speech com-
prehension (listener–listener coupling) are also aligned during communication (speaker–listener coupling). No 
significant speaker-listener coupling was found for either of the Turkish stories (stories T1 and T2). Using identical 
analysis methods and statistical thresholds, we found no significant coupling between the speaker and the listeners 
or among the listeners during these control conditions (see Fig. 1, T1 and T2).
To further investigate the temporal asymmetry of coupling, the average t-statistics for all significantly coupled 
speaker-listener optode-pairs were assessed across time shifts between the speaker and listener time series, as 
shown in Fig. 3 (red curve). The peak of the curve is centered at 5 seconds, which shows that, on average, listeners’ 
time courses lagged behind the speaker’s. In comparison, the time courses of the listeners were synchronized 
(with each other) at 0 sec (Fig. 3, blue curve).
Listener-listener BOLD coupling. 
As a verification of the fNIRS approach, we reanalyzed an fMRI dataset 
of 17 subjects listening to story E2 (the “Pie-man” story), which was recorded and used in a previous study14,27. To 
compare with the fNIRS results, we considered only voxels from the outer layer of the cortex in the neighboring 
regions of prefrontal and parietal sites. The coupling results estimated using the multilevel GLM model are shown 
Figure 1. Listener-listener fNIRS inter-subject correlation. The top row shows the t-Map of coupling results 
from Δ 
HbO and the bottom row shows the results from Δ 
HbR. White crosses represent non-significantly 
coupled optodes; Black crosses represent significantly coupled optodes (n = 15, FDR <
.
.
q
0 01)  The t-Maps 
were smoothed using a spline method.
 www.nature.com/scientificreports/
4
Scientific RepoRts | 7:43293 | DOI: 10.1038/srep43293
Figure 2. Speaker-listener and listener-listener neural coupling. (a) The number of optode-pairs at which the 
fNIRS time courses between a speaker and the listeners were significantly coupled (n = 15, FDR <
.
q
0 01). 
Results are shown with the speaker’s time course shifted from − 
20 to 20 sec. with respect to the listeners’ in 0.5 s 
increments. Significant results can be found from 5 to 7 sec. of shift (speaker precedes) with a peak at 5 sec for 
the English condition E1. (b) The number of optodes showed significant listener-listener inter-subject 
correlation (n = 15, FDR <
.
q
0 01). Results are shown with the average listener’s time course shifted from − 
20 
to 20 sec. with respect to those of each individual listener in 0.5 s increments. No temporal asymmetry effect can 
be found. (c) Significantly coupled speaker-listener optode-pairs were in non-homologous areas (n = 15, FDR 
<
.
q
0 01).
 www.nature.com/scientificreports/
5
Scientific RepoRts | 7:43293 | DOI: 10.1038/srep43293
in Fig. 4. Of the 994 investigated voxels, 551 showed significant listener-listener coupling (FDR q < 
 0.01). This 
result replicates published result14 and demonstrate a nice convergence across fNIRS and fMRI methods.
BOLD and ΔHbO are correlated during comprehension of the same story. 
Previous studies have 
shown that fNIRS and fMRI signals are highly correlated across multiple cognitive tasks31,32,38,39. In our study, two 
groups of subjects, the brain activity of one group measured with fNIRS and the other with fMRI, were engaged 
in the same task of listening to the E2 story (“Pie-man”). We hypothesize that the BOLD and fNIRS signals share 
common information even though they were measured from different subjects and in different recording envi-
ronments. To directly compare the signals across fMRI and fNIRS, we estimated correlations between spatially 
overlapping voxel-optode pairs while subjects listened to the exact same story. Widespread significant correla-
tions can be found between BOLD and Δ 
HbO only when the participants were listening to the same story (i.e. 
E2) as shown in Fig. 5a. For control stories T1, T2 (Turkish) and E1 (English), we observed no coupling effect.
Discussion
During social interaction, the brains of individuals become coupled as those individuals send and receive signals 
(light, sound, etc.) through the environment, analogous to a wireless communication system8. This brain-to-brain 
coupling relies on the stimulus-to-brain coupling which reflects the brain’s ability to be coupled with the physical 
world in order to represent it, veridically and dynamically. In this study, we identified the brain-to-brain coupling 
between a speaker telling an unrehearsed real-life story and a group of listeners listening to the story, with the aid 
of fNIRS. We have demonstrated for the first time that it is feasible to study neural coupling during natural verbal 
communication with fNIRS. While there is a growing literature using fMRI and EEG to study brain-to-brain cou-
pling during social interaction40, the application of fNIRS in the field is still rare. Cui et al. in 2012 first adopted 
fNIRS to investigate neural coupling between pairs of subjects playing a simple cooperation and competition 
Figure 3. Delayed synchrony between speaker and listener. The mean distribution of t-values across 
significantly coupled optodes for speaker-listener (red) and listener-listener (blue) analyses. Results are shown 
with the speaker’s (or average listener’s) time course shifted from − 
20 to 20 sec. with respect to the listeners’ 
in 0.5 s increments. A larger t-statistic indicates stronger synchrony between the signal time courses. Listener-
listener coupling was centered at 0 sec whereas speaker-listener coupling was centered at 5 sec. This suggests 
that, on average, the speaker preceded, and listeners needed time to process the information conveyed in the 
stories in order to synchronize with the speaker. Similar results have been found previously12,13.
Figure 4. T-map of listener-listener coupling during the comprehension of story E2 (“Pie-man” story) 
evaluated with fMRI. The significance threshold was at t(16) = 2.9 (FDR <
.
q
0 01). The t-statistics were 
superimposed on the ch2better template and rendered using MRIcron software37.
 www.nature.com/scientificreports/
6
Scientific RepoRts | 7:43293 | DOI: 10.1038/srep43293
Figure 5. Correlation between fNIRS optodes and corresponding fMRI voxels. 994 related voxels were selected 
according to optode spatial registration (See Materials and Methods for more details). (a) The number of 
significant BOLD-Δ 
HbO and BOLD-Δ 
HbR correlations (n = 15, FDR <
.
q
0 05); here we compared the fMRI 
time series from story E2 with the fNIRS time series from stories E1, E2, T2, and T2. When comparing time series 
corresponding to different stories, we found no significant correlations between BOLD and fNIRS. (b) Brain maps 
showing voxels correlated with the Δ 
HbO of at least one optode (red) and voxels with no significant correlations 
with fNIRS (blue). The images were rendered with MRIcron37. (c) Six examples of voxel-optode pair. Three of the 
examples are the most correlated within prefrontal and the other three most correlated within parietal. Each 
colored circle represents one voxel-optode pair. For each pair, the voxel and optode locations are illustrated in I. 
fMRI Voxels and II. fNIRS optodes respectively, and the BOLD (blue line) and Δ 
HbO (red line) time course 
during the comprehension of story E2 are compared (duration = 385 s). Time courses were first standardized and 
averaged across the subjects and the Pearson’s correlations (r) between BOLD and Δ 
HbO were estimated.
 www.nature.com/scientificreports/
7
Scientific RepoRts | 7:43293 | DOI: 10.1038/srep43293
game23. In the game, participants were asked to press a response key after a ‘go’ signal, either in synchrony with 
(cooperation mode) or faster than (competition mode) their partner. An increase in neural correlation between 
the members of a pair was found only during cooperation and was associated with better cooperation perfor-
mance. Holper et al. in 2012 investigated neural coupling between a model and an imitator during a finger tap-
ping task24. A stronger increase in neural coupling was found during the imitation condition compared with a 
control condition in which the imitator no longer needed to follow the model’s tapping pace. These two studies, 
however, involved only simple stimuli and contexts.
Our results demonstrated that: (1) the brain activation recorded by fNIRS was coupled between a speaker 
telling a real-life story and listeners listening to the story (speaker-listener coupling); (2) on average, the listeners’ 
brain activity lagged behind that of the speaker (5-s delay); (3) the brain activity evoked by the same story was 
reliable across the listeners (listener-to-listener coupling); and (4) coupling was not present when listeners heard 
stories in a language incomprehensible to them. These findings are consistent with previous work using fMRI12 
and EEG13 and demonstrate that fNIRS can be used to study brain-to-brain coupling during social interaction in 
a natural communicative context.
During brain-to-brain coupling, activity in areas of prefrontal and parietal cortex previously reported to be 
involved in sentence comprehension were robustly correlated across subjects, as revealed in the inter-subject 
correlation analysis34. As these are task-related (active listening) activation periods (not resting, etc.), the corre-
lations reflect modulation of these regions by the time-varying content of the narratives, and comprise linguistic, 
conceptual and affective processing. As expected, and in agreement with previous work12, the activity among 
listeners is time locked to the moment of vocalization. In contrast, the activity in the listener’s brain lagged behind 
the activity in the speaker’s brain. Though the sluggish hemodynamic response measures of fMRI and fNIRS have 
lower temporal resolution and could mask the exact temporal speaker–listener coupling, the delay (5-sec) we 
have identified in this study is consistent with previous work on the multiple timescales of linguistic processing10. 
In particular, analyses integrating single-unit, ECoG, and fMRI data have uncovered a hierarchy of timescales 
over which natural communication unfolds in the brain, ranging from hundreds of milliseconds (single words) 
to a few seconds (sentences) to tens of seconds (paragraphs)10. These previous findings indicate that each brain 
area along this hierarchical pathway accumulates and integrates information at a preferred timescale (e.g., early 
auditory areas integrate phonemes to detect words, while later areas integrate words to form a sentence, etc.) and 
transmits the chunked information upstream to the next processing level. The relatively long (5-sec) lag between 
speaker and listener seems to match the processing timescale of natural discourse, which unfolds at the sentence 
level. In agreement with such an observation, the speaker-listener neural coupling emerges in areas with relatively 
long processing timescales.
Another interesting observation is that significant inter-subject correlations were found primarily between 
prefrontal areas in the speaker and parietal areas in the listeners. This result supports a previous EEG study in 
which the coupling between speaker and listener was found to be mainly between different channels13. In that 
study, listeners watched the video playback of speakers who were telling either a fairytale or the plot of their 
favorite movie or book. A canonical correlation analysis between the EEG of the speakers and listeners showed 
that coupling was mainly limited to non-homologous channels although source localization was not applied. To 
our best knowledge, our study presents the first fNIRS-based evidence that the brain-to-brain coupling between 
speaker and listener was mainly between non-homologous brain areas.
In the current study, we further compared the fMRI and fNIRS signal time courses when two groups of 
subjects were listening to the same audio recording of a real-life story. The neural activation of one group was 
recorded with fNIRS. The neural activation of the other group (the fMRI group) was recorded with fMRI in a pre-
vious study14. We first analyzed the two datasets separately with inter-subject multilevel GLM and found similar 
patterns of coupling between listeners in the two modalities. We then investigated the correlation between fMRI 
and fNIRS signals and found that Δ 
HbO and BOLD were significantly correlated, despite the fact that they were 
collected from different subjects in different recording environments, and with different techniques (fMRI vs. 
fNIRS). Furthermore, the fMRI voxels that were significantly correlated with fNIRS optodes were not randomly 
distributed but came from brain areas usually considered to be related to listening comprehension1. When the 
fNIRS and fMRI signals corresponding to different stories were compared for control purposes, no significant 
correlation was found, as expected. Significant BOLD-Δ 
HbR correlations were found but to a much lesser extent 
compared to Δ 
HbO (Fig. 5a). One possible explanation is the superior reliability of Δ 
HbO across the listeners 
compared to Δ 
HbR as shown in Fig. 1.
For many years, researchers have been interested in comparing the fNIRS and fMRI responses during cog-
nitive tasks. Strangman et al. simultaneously recorded fNIRS and fMRI in a finger flexion/extension task30. 
Although the authors expected the Δ 
HbR-BOLD correlation to be strongest due to the causal relation between 
the Δ 
HbR and BOLD signals, the results suggested stronger BOLD-Δ 
HbO correlations. The authors suspected 
this might be due to a higher signal-to-noise ratio (SNR) of Δ 
HbO in response to the task. Cui et al. simultane-
ously recorded fNIRS and fMRI for the same group of subjects during 4 tasks: finger tapping, go/no-go, judg-
ment of line orientation and visuospatial n-back31. They found that both Δ 
HbR and Δ 
HbO were correlated with 
BOLD, despite differences in SNR, and the type of task did not significantly affect the correlations. Δ 
HbO-BOLD 
correlations were found to be slightly but significantly higher than Δ 
HbR-BOLD. Noah et al. compared fMRI and 
fNIRS measurements in a naturalistic task in which participants played the video game Dance Dance Revolution 
and rested alternately for 30 second blocks, and the results suggested a high Δ 
HbO-BOLD correlation within 
the same measurement areas32. All of the studies above compared the mean triggered average activity induced 
by averaging a condition over time. However, Ben-Yakov et al. demonstrated the shortcoming of the triggered 
averaging method for detecting an event-specific responses which are locked to the structure of each particular 
exemplar26. In our study, each event in the story is unique and singular and cannot be averaged with the responses 
evoked by other events in the story. Our findings provide evidence that the response dynamics to a sequence of 
 www.nature.com/scientificreports/
8
Scientific RepoRts | 7:43293 | DOI: 10.1038/srep43293
events in the story are robust and reliable, and can be detected both with fMRI and fNIRS, by measuring the reli-
ability (correlation) of responses to the story within and between the two methods in real-life complex settings 
that unfolds over several minutes.
The current study, however, is only the first step toward studying brain coupling during natural communica-
tion using fNIRS. While fNIRS has obvious disadvantages relative to fMRI, which include coarser spatial resolu-
tion and an inability to measure signal beneath the cortical surface, it also has some advantages over fMRI. The 
advantages of fNIRS over fMRI include: (1) lower cost; (2) easier setup; (3) higher temporal resolution, (4) greater 
ecological validity, which can allow face-to-face communication (in fMRI setups subjects cannot see each other); 
(5) greater ease of connecting two systems simultaneously to test bi-directional dialogue-based communication; 
and (6) ease of use in real-life clinical communicative contexts. In recent studies, fNIRS has been used in extreme 
settings such as in aerospace applications41,42 and with mobile participants walking outdoors20. In the context of 
the current study, the true advantages of fNIRS can be exploited when the neural activation of two or more sub-
jects is studied during face-to-face conversations in a natural context such as a classroom.
Despite these promising results, our study was limited in certain aspects. First, for the fNIRS-fMRI compar-
ison, the spatial resolution and coverage of our fNIRS system were limited, so fMRI-fNIRS correlations were 
estimated between all possible voxel-optode pairs within large cortical areas or the whole brain. Second, our 
data from fNIRS and fMRI were not recorded simultaneously and involved different participants, so any possible 
between-subject differences should be taken into account when interpreting the results. Future studies, preferably 
with concurrent fNIRS and fMRI, can validate our findings and deepen our understanding of the fNIRS-fMRI 
relationship for complex natural stimuli. Potential future uses of this approach would include everyday settings 
such as classrooms, where we could investigate communication between a teacher and students, or in business 
meetings, across a speaker and attendees. However, due to the nature of the hemodynamic response that fNIRS 
measures, rapid communication may be difficult to analyze at short timescales (e.g., at the word-level). Future 
studies can investigate the temporal and spatial limits and requirements of fNIRS-based speaker-listener coupling.
In summary, our results showed that: (1) A speaker’s and listeners’ brain activity as measured with fNIRS 
were coupled only when the listeners understood the story; (2) listeners’ brain activity mirrored the speaker’s 
brain activity with a delay, (3) only during listening to the same real-life story, common brain activation patterns 
were evoked across listeners that were independent of the imaging technology (fNIRS or fMRI) and recording 
environment (quiet or noisy; sitting down or lying down); and (4) fNIRS and fMRI signals were correlated dur-
ing the comprehension of the same real-life story. These results support fNIRS as a viable future tool to study 
brain-to-brain coupling during social interaction, in real-life and clinical settings such as a classroom, a business 
meeting, a political rally, or a doctor’s office.
Materials and Methods
Participants. 
Three speakers (one male native English speaker, two male native Turkish speakers) and 15 
native English listeners (8 females) volunteered to participate in the study and were included in the analysis. An 
additional six subjects participated in the study but were excluded from analysis due to technical issues during 
recording or the excessive motion artifact (detected both visually and using an automatic algorithm43) presented 
in the large sensor array data that covers both prefrontal and parietal cortices. Subjects were all right-handed 
(mean LQ = 
 74.5, SD = 
 24.1) based on Edinburgh Handedness Inventory44 and ages 18–35 years. All subjects 
had normal or corrected-to-normal vision. Participants did not have any history of neurological/mental disorder 
and were not taking any medication known to affect alertness or brain activity. None of the listeners understood 
Turkish. The protocol used in the study was reviewed and approved by the Institutional Review Board (IRB) of the 
Drexel University (DU). The methods were carried out in accordance with approved guidelines and participants 
gave written informed consent approved by the IRB of DU.
Experimental Procedure. 
All participants were seated comfortably in front of a computer screen through-
out the experiment. fNIRS data of the three speakers were recorded while they told an unrehearsed real-life story 
in their native language (either English or Turkish). Audio of the stories was recorded using a microphone. The 
resulting one English story (E1) and two Turkish stories (T1 and T2) were played to the listeners later. An addi-
tional real-life English story E2 (“Pie-man”
, recorded at “The Moth”
, a live storytelling event in New York City) 
used in several recent fMRI studies of natural verbal communication14,26,27, was also played to the listeners.
fNIRS data were recorded from the listeners throughout the audio playbacks. The playback sequence always 
began with E2 (English story, Pie-man), and order of the remaining stories (E1, T1, and T2) was counterbalanced 
across subjects. Before each story playback, short samples of scrambled audio were played to the subjects so they 
could adjust the volume of the headphones they were wearing. Before the start and after the end of the audio story 
playback, there was a 15-s fixation period for stabilizing the signal. Immediately after each playback, subjects were 
asked to write a detailed report of the story they just heard to verify if they understood the story. Figure 6, below, 
shows the timeline of a story session.
Data Acquisition. 
Two continuous wave optical brain imaging devices were used simultaneously on each 
participant to record brain activity from prefrontal cortex (PFC) and parietal cortex (PL) using 40 measurement 
locations (optodes). Prefrontal and parietal regions were selected based on the significant areas found in the 
previous fMRI-based speaker-listener neural coupling study by Stephens, et al.12. Anterior prefrontal cortex was 
recorded by a 16-optode continuous wave fNIRS system (fNIR Imager Model 1100; fNIR Devices, LLC) first 
described by Chance et al.45 and developed in our lab at Drexel University46,47. The sensor was positioned based 
on the anatomical landmarks as described before in Ayaz et al.47. Briefly, the center of the sensor was aligned 
to the midline and the bottom of the sensor was touching the participant’s eyebrow so that the center point of 
the sensor was approximately at Fpz according to the 10–20 international system (see Fig. 7). The sensor has a 
 www.nature.com/scientificreports/
9
Scientific RepoRts | 7:43293 | DOI: 10.1038/srep43293
source-detector distance of 2.5 cm and the sampling rate was 2 Hz. Parietal cortex was recorded using a 24-optode 
continuous wave Hitachi fNIRS system (ETG 4000; Hitachi Medical Systems). Two “3 × 
 3” measurement patches 
were attached to a cap that was customized for the measurement of the parietal cortex. For each subject, the center 
of the two patches was placed at Pz, which was located using a measuring tape. Sensors from each patch measured 
the fNIRS signal of one hemisphere from 12 channels. The sensor has a source-detector distance of 3 cm and the 
sampling rate was 10 Hz. Figure 7 shows the complete sensor setup and optode configuration.
Time synchronization markers (triggers) were sent from the stimulus presentation computer to both fNIRS 
acquisition computers for registration of audio playback start and end times on both fNIRS devices and for tem-
poral aligning recorded data for all subjects.
The approximate projection of the channel locations onto the cortical surface in MNI space was estimated 
using a virtual spatial registration approach48,49. In this approach, the sensor patches are virtually placed on an 
ideal scalp and the projected Montreal Neurological Institute (MNI) coordinates on the cortical surface and the 
standard deviation of displacement were estimated from the magnetic resonance (MR) images of 17 individuals 
that were obtained from a publicly available dataset50,51. The results are shown in Fig. 8. The optodes covered 
regions in the frontopolar area, orbitofrontal area, dorsolateral prefrontal cortex, primary somatosensory cortex, 
somatosensory association cortex, supramarginal gyrus and angular gyrus. Detailed lists of anatomical locations 
and Brodmann areas corresponding to each optode are included in Table S1 and Table S2, respectively.
fNIRS Data Preprocessing. 
fNIRS raw light intensity signals were converted to changes in oxygenated 
hemoglobin (Δ 
HbO) and deoxygenated hemoglobin (Δ 
HbR) concentrations using the modified Beer-Lambert 
law52. The raw signal and hemoglobin concentration changes were inspected both visually and also using the 
automated SMAR algorithm53, which uses a coefficient-of-variation based approach to assess signal quality and 
reject problematic channels with bad contact or saturated raw light intensity. Two optodes, 1 and 15, were over 
the hairline for most participants and hence were rejected from the study. A total of 11.7% were rejected by visual 
inspection and SMAR. Next, the Δ 
HbO and Δ 
HbR time series for each optode and participant were band-pass 
Figure 6. Story presentation timeline. 
Figure 7. fNIRS acquisition setup. Red circles indicate emitters; blue circles indicate detectors; White squares 
indicate measurement channels between emitters and detectors.
 www.nature.com/scientificreports/
10
Scientific RepoRts | 7:43293 | DOI: 10.1038/srep43293
filtered (0.01–0.5 Hz) and the recordings from parietal sites were down-sampled to 2 Hz to match the sampling 
rate of prefrontal sites. In the fNIRS literature, various filtering settings have been adopted to reduce physio-
logical artifacts31,54–58. The high cutoff of a band-pass filter, for example, ranges from 0.1–1 Hz31,54–56. We chose 
 
0.01–0.5 Hz cutoffs to reduce slow signal drift and physiological artifacts from cardiac activities but maximally 
preserve activities related to listening comprehension. We considered only the period from 15 to 399 seconds, 
with respect to story start, in the signal time courses from each audio story. The first 15 s were rejected to account 
for subjects’ initial period of adjustment to the listening comprehension task, and 399 s is the duration of the 
shortest story. Prior to subsequent analysis, the signal time courses were standardized optode-wise using a 
Z-score transform.
fNIRS Analysis. 
Inter-subject correlation. We first evaluated the reliability of the correlation between listen-
ers’ brain activity using an inter-subject multilevel GLM similar to the one adopted by Stephens et al.12 for each 
of the four conditions: E1, E2, T1 and T2. We expected neural coupling between listeners to emerge only for the 
English story conditions E1 and E2, as none of the subjects understood Turkish.
At the individual subject level, a GLM with AR(1) (first-order autoregressive) error model was estimated using 
the average time course of the listeners as the independent variable and the time course of an individual listener 
as the dependent variable as follows:
β
=
+
y
t
x t
v t
( )
( )
( )
(1)
k
k
k
ρ
=
−
+
v t
v t
( )
(
1)
(2)

where y
t
( )
k
 is the time course of a channel from listener k, x t
( )
k
 is the average time course of a channel from all 
the other listeners except for listener k, ρ is the autocorrelation coefficient and 
∈
σ
~ N (0,
)
2 . AR(1) error model 
has been frequently adopted in event-related fNIRS analysis to model auto-correlated noise caused by 
low-frequency drift and physiological processes such as cardio-respiratory and blood pressure changes57.
At the group level, we tested the hypothesis 
β >
H :
0
1
using a one-tailed one-sample t-test evaluated on the 
slopes βk ( =
…
k
n
1,
, ) estimated at the individual level. We used the Benjamini–Hochberg procedure33 to control 
FDR among 80 statistical tests (2[Δ 
HbO/Δ 
HbR] × 40[optodes]) with <
.
q
0 01.
Speaker-listener coupling. We evaluated the coupling between optode i of speaker and optode j of the listeners 
for all permutations of (i j
, ) (
=
×
=
N
optodes
pairs
40
40
1600
). The multilevel GLM was applied as it was for 
listener-listener coupling except that the time course of optode i of a speaker was used as independent variable 
x
t
( )
i
 and the time course of optode j of each individual listener k was used as dependent variable y
t
( )
k
j
.
Temporal asymmetry of coupling. The speaker-listener coupling analysis was repeated by shifting the speaker’s 
time course with respect to those of the listeners from − 
20 s to 20 s in 0.5 s increments. At each time shift, FDR 
was controlled among 3200 statistical tests (2[Δ 
HbO/Δ 
HbR] × 
 (40 × 
 40)[optode pairs]) with <
.
q
0 01. As a 
Figure 8. Optode locations. (a) Approximate spatial registration of optode locations to MNI space.  
(b) Schematic representation of the same optode locations on head surface which is used to show results. The 
virtual spatial registration approach was adopted to estimate the projection of the optodes on the cortical 
surface in MNI space48. The center of each green colored patch stands for the most likely position and the radius 
represents the standard deviation of displacement.
 www.nature.com/scientificreports/
11
Scientific RepoRts | 7:43293 | DOI: 10.1038/srep43293
comparison, listener-listener coupling was re-evaluated by shifting the average listener time series with respect to 
that of each individual listener.
fMRI Analysis. 
The fMRI dataset included 17 subjects listening to story E2 (the “Pie-man” story), which was 
recorded and used in a previous study14. To compare with the fNIRS results, we considered only voxels from the 
outer layer of the cortex in the neighboring regions of prefrontal and parietal sites as shown in Fig. 8. The “neigh-
boring regions” are defined as voxels within a radius of 2.7 standard deviations from the center of each optode 
projection. A total of 994 voxels were chosen in this manner. The voxel time courses were high-pass filtered at 
0.01 Hz (for comparison with fNIRS signals) and trimmed to only include 15–399 seconds (with respect to story 
start), and the inter-subject multilevel GLM described in section 0 was employed for model analysis. FDR was 
controlled among the 994 voxels with <
.
q
0 01.
fMRI-fNIRS Correlation. 
To estimate the correlation between BOLD and fNIRS signals, both signals were 
high-pass filtered at 0.01 Hz. The BOLD time courses were z-scored normalized for each voxel and then averaged 
across the 17 subjects. fNIRS time courses were down-sampled to 
.
1
1 5 Hz to match the fMRI sampling rate. The 
inter-subject multilevel GLM approach was then applied with the time course of optode i of an fNIRS subject k as 
independent variable x
t
( )
k
i
 and the time course of voxel j averaged across fMRI subjects as dependent variable 
y
t
( )
j
.
The aforementioned procedure was applied first to estimate all possible correlations between channels and 
their corresponding voxels in the left prefrontal (8 optodes × 
 131 voxels), right prefrontal (8 optodes × 
 144 vox-
els), left parietal (12 optodes × 
 376 voxels) and right parietal (12 optodes × 
 343 voxels) areas. The voxels were 
selected as described in section 0. To correct for multiple comparisons, FDR was controlled with a threshold of 
0.05.
References
1. Price, C. J. A review and synthesis of the first 20 years of PET and fMRI studies of heard speech, spoken language and reading. 
NeuroImage 62, 816–847, doi: 10.1016/j.neuroimage.2012.04.062 (2012).
2. Scherg, M., Vajsar, J. & Picton, T. W. A Source Analysis of the Late Human Auditory Evoked Potentials. Journal of Cognitive 
Neuroscience 1, 336–355, doi: 10.1162/jocn.1989.1.4.336 (1989).
3. Miranda, V. T., Hagoort, P. & Brown, C. M. Electrophysiological evidence on the time course of semantic and phonological processes 
in speech production. Journal of experimental psychology. Learning, memory, and cognition 23, 787–806 (1997).
4. Heinks-Maldonado, T. H., Nagarajan, S. S. & Houde, J. F. Magnetoencephalographic evidence for a precise forward model in speech 
production. NeuroReport 17, 1375–1379, doi: 1310.1097/1301.wnr.0000233102.0000243526.e0000233109 (2006).
5. Houde, J. F., Nagarajan, S. S., Sekihara, K. & Merzenich, M. M. Modulation of the Auditory Cortex during Speech: An MEG Study. 
Journal of Cognitive Neuroscience 14, 1125–1138, doi: 10.1162/089892902760807140 (2002).
6. Holcomb, P. J. Semantic priming and stimulus degradation: implications for the role of the N400 in language processing. 
Psychophysiology 30, 47–61 (1993).
7. Kutas, M. & Federmeier, K. D. Electrophysiology reveals semantic memory use in language comprehension. Trends in Cognitive 
Sciences 4, 463–470, doi: http://dx.doi.org/10.1016/S1364-6613(00)01560-6 (2000).
8. Hasson, U., Ghazanfar, A. A., Galantucci, B., Garrod, S. & Keysers, C. Brain-to-brain coupling: a mechanism for creating and sharing 
a social world. Trends Cogn Sci 16, 114–121, doi: 10.1016/j.tics.2011.12.007 (2012).
9. Bookheimer, S. Functional MRI of language: new approaches to understanding the cortical organization of semantic processing. 
Annu Rev Neurosci 25, 151–188, doi: 10.1146/annurev.neuro.25.112701.142946 (2002).
10. Hasson, U., Chen, J. & Honey, C. J. Hierarchical process memory: memory as an integral component of information processing. 
Trends in Cognitive Sciences 19, 304–313, doi: http://dx.doi.org/10.1016/j.tics.2015.04.006 (2015).
11. Hasson, U. & Honey, C. J. Future trends in Neuroimaging: Neural processes as expressed within real-life contexts. NeuroImage 62, 
1272–1278, doi: 10.1016/j.neuroimage.2012.02.004 (2012).
12. Stephens, G. J., Silbert, L. J. & Hasson, U. Speaker–listener neural coupling underlies successful communication. Proceedings of the 
National Academy of Sciences of the United States of America 107, 14425–14430, doi: 10.1073/pnas.1008662107 (2010).
13. Kuhlen, A. K., Allefeld, C. & Haynes, J. D. Content-specific coordination of listeners’ to speakers’ EEG during communication. Front 
Hum Neurosci 6, 266, doi: 10.3389/fnhum.2012.00266 (2012).
14. Lerner, Y., Honey, C. J., Silbert, L. J. & Hasson, U. Topographic Mapping of a Hierarchy of Temporal Receptive Windows Using a 
Narrated Story. The Journal of Neuroscience 31, 2906–2915, doi: 10.1523/jneurosci.3684-10.2011 (2011).
15. Ball, T., Kern, M., Mutschler, I., Aertsen, A. & Schulze-Bonhage, A. Signal quality of simultaneously recorded invasive and non-
invasive EEG. NeuroImage 46, 708–716, doi: http://dx.doi.org/10.1016/j.neuroimage.2009.02.028 (2009).
16. Michel, C. M. et al. EEG source imaging. Clinical neurophysiology: official journal of the International Federation of Clinical 
Neurophysiology 115, 2195–2222, doi: 10.1016/j.clinph.2004.06.001 (2004).
17. Grech, R. et al. Review on solving the inverse problem in EEG source analysis. Journal of NeuroEngineering and Rehabilitation 5, 25 
(2008).
18. Akalin Acar, Z. & Makeig, S. Effects of Forward Model Errors on EEG Source Localization. Brain Topogr 26, 378–396, doi: 10.1007/
s10548-012-0274-6 (2013).
19. Ayaz, H. et al. Continuous monitoring of brain dynamics with functional near infrared spectroscopy as a tool for neuroergonomic 
research: Empirical examples and a technological development. Frontiers in Human Neuroscience 7, doi: 10.3389/fnhum.2013.00871 
(2013).
20. McKendrick, R. et al. Into the Wild: Neuroergonomic Differentiation of Hand-Held and Augmented Reality Wearable Displays 
during Outdoor Navigation with Functional Near Infrared Spectroscopy. Frontiers in Human Neuroscience 10, doi: 10.3389/
fnhum.2016.00216 (2016).
21. Gramann, K. et al. Cognition in action: imaging brain/body dynamics in mobile humans. Reviews in the neurosciences 22, 593–608, 
doi: 10.1515/rns.2011.047 (2011).
22. Parasuraman, R. Neuroergonomics brain, cognition, and performance at work. Current directions in psychological science 20, 
181–186 (2011).
23. Cui, X., Bryant, D. M. & Reiss, A. L. NIRS-based hyperscanning reveals increased interpersonal coherence in superior frontal cortex 
during cooperation. NeuroImage 59, 2430–2437, doi: http://dx.doi.org/10.1016/j.neuroimage.2011.09.003 (2012).
24. Holper, L., Scholkmann, F. & Wolf, M. Between-brain connectivity during imitation measured by fNIRS. NeuroImage 63, 212–222, 
doi: http://dx.doi.org/10.1016/j.neuroimage.2012.06.028 (2012).
 www.nature.com/scientificreports/
12
Scientific RepoRts | 7:43293 | DOI: 10.1038/srep43293
25. Suda, M. et al. Frontopolar activation during face-to-face conversation: an in situ study using near-infrared spectroscopy. 
Neuropsychologia 48, 441–447, doi: 10.1016/j.neuropsychologia.2009.09.036 (2010).
26. Ben-Yakov, A., Honey, C. J., Lerner, Y. & Hasson, U. Loss of reliable temporal structure in event-related averaging of naturalistic 
stimuli. NeuroImage 63, 501–506, doi: http://dx.doi.org/10.1016/j.neuroimage.2012.07.008 (2012).
27. Simony, E., Honey, C. J., Chen, J., Lositsky, O., Yeshurun, Y., Wiesel, A. & Hasson, U. Dynamic reconfiguration of the default mode 
network during narrative comprehension. Nature communications, 7, 12141, doi: 10.1038/ncomms12141 http://www.nature.com/
articles/ncomms12141#supplementary-information (2016).
28. Gallagher, H. L. & Frith, C. D. Functional imaging of ‘theory of mind’. Trends in Cognitive Sciences 7, 77–83, doi: http://dx.doi.
org/10.1016/S1364-6613(02)00025-6 (2003).
29. Amodio, D. M. & Frith, C. D. Meeting of minds: the medial frontal cortex and social cognition. Nat Rev Neurosci 7, 268–277 (2006).
30. Strangman, G., Culver, J. P., Thompson, J. H. & Boas, D. A. A Quantitative Comparison of Simultaneous BOLD fMRI and NIRS 
Recordings during Functional Brain Activation. NeuroImage 17, 719–731, doi: http://dx.doi.org/10.1006/nimg.2002.1227 (2002).
31. Cui, X., Bray, S., Bryant, D. M., Glover, G. H. & Reiss, A. L. A quantitative comparison of NIRS and fMRI across multiple cognitive 
tasks. Neuroimage 54, 2808–2821, doi: 10.1016/j.neuroimage.2010.10.069 (2011).
32. Noah, J. A. et al. fMRI Validation of fNIRS Measurements During a Naturalistic Task. Journal of Visualized Experiments: JoVE, 
52116, doi: 10.3791/52116 (2015).
33. Benjamini, Y. & Hochberg, Y. Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing. Journal 
of the Royal Statistical Society. Series B (Methodological) 57, 289–300, doi: 10.2307/2346101 (1995).
34. Wilson, S. M., Molnar-Szakacs, I. & Iacoboni, M. Beyond Superior Temporal Cortex: Intersubject Correlations in Narrative Speech 
Comprehension. Cerebral Cortex 18, 230–242, doi: 10.1093/cercor/bhm049 (2008).
35. Husain, F. T. et al. Neural bases of categorization of simple speech and nonspeech sounds. Human Brain Mapping 27, 636–651, doi: 
10.1002/hbm.20207 (2006).
36. Keller, T. A., Carpenter, P. A. & Just, M. A. The Neural Bases of Sentence Comprehension: a fMRI Examination of Syntactic and 
Lexical Processing. Cerebral Cortex 11, 223–237, doi: 10.1093/cercor/11.3.223 (2001).
37. Rorden, C. MRIcron (Version 4 Aug 2014). Computer software. Retrieved from http://www.mccauslandcenter.sc.edu/mricro/
mricro/index.html (2014).
38. Funane, T. et al. Concurrent fNIRS-fMRI measurement to validate a method for separating deep and shallow fNIRS signals by using 
multidistance optodes. Neurophotonics 2, 015003, doi: 10.1117/1.NPh.2.1.015003 (2015).
39. Sato, H. et al. A NIRS–fMRI investigation of prefrontal cortex activity during a working memory task. NeuroImage 83, 158–173, doi: 
http://dx.doi.org/10.1016/j.neuroimage.2013.06.043 (2013).
40. Konvalinka, I. & Roepstorff, A. The two-brain approach: how can mutually interacting brains teach us something about social 
interaction? Frontiers in Human Neuroscience 6, doi: 10.3389/fnhum.2012.00215 (2012).
41. Ayaz, H. et al. Optical brain monitoring for operator training and mental workload assessment. Neuroimage 59, 36–47 (2012).
42. Durantin, G., Scannella, S., Gateau, T., Delorme, A. & Dehais, F. Processing Functional Near Infrared Spectroscopy Signal with a 
Kalman Filter to Assess Working Memory during Simulated Flight. Frontiers in Human Neuroscience 9, 707, doi: 10.3389/
fnhum.2015.00707 (2015).
43. Ayaz, H., Izzetoglu, M., Shewokis, P. A. & Onaral, B. In Engineering in Medicine and Biology Society (EMBC), Annual International 
Conference of the IEEE. IEEE. 6567–6570 (2010).
44. Oldfield, R. C. The assessment and analysis of handedness: The Edinburgh inventory. Neuropsychologia 9, 97–113, doi: http://dx.doi.
org/10.1016/0028-3932(71)90067-4 (1971).
45. Chance, B. et al. A novel method for fast imaging of brain function, non-invasively, with light. Optics express 2, 411–423 (1998).
46. Izzetoglu, M. et al. Functional near-infrared neuroimaging. Neural Systems and Rehabilitation Engineering, IEEE Transactions on 13, 
153–159, doi: 10.1109/TNSRE.2005.847377 (2005).
47. Ayaz, H. et al. Using MazeSuite and Functional Near Infrared Spectroscopy to Study Learning in Spatial Navigation. Journal of 
Visualized Experiments: JoVE, 3443, doi: 10.3791/3443 (2011).
48. Tsuzuki, D. et al. Virtual spatial registration of stand-alone fNIRS data to MNI space. NeuroImage 34, 1506–1518, doi: http://dx.doi.
org/10.1016/j.neuroimage.2006.10.043 (2007).
49. Ayaz, H. et al. In Conf. Proc. IEEE Eng. Med. Biol. Soc. EMBS ‘06. 2671–2674 IEEE (2006).
50. Okamoto, M. et al. Three-dimensional probabilistic anatomical cranio-cerebral correlation via the international 10–20 system 
oriented for transcranial functional brain mapping. Neuroimage 21, 99–111 (2004).
51. Singh, A. K., Okamoto, M., Dan, H., Jurcak, V. & Dan, I. Spatial registration of multichannel multi-subject fNIRS data to MNI space 
without MRI. NeuroImage 27, 842–851, doi: http://dx.doi.org/10.1016/j.neuroimage.2005.05.019 (2005).
52. Cope, M. & Delpy, D. T. System for long-term measurement of cerebral blood and tissue oxygenation on newborn infants by near 
infra-red transillumination. Medical and Biological Engineering and Computing 26, 289–294, doi: 10.1007/BF02447083 (1988).
53. Ayaz, H., Izzetoglu, M., Shewokis, P. A. & Onaral, B. In Conf. Proc. IEEE Eng. Med. Biol. Soc. EMBS ‘10. 6567–6570 IEEE (2010).
54. Plichta, M. M. et al. Event-related functional near-infrared spectroscopy (fNIRS): Are the measurements reliable? NeuroImage 31, 
116–124, doi: http://dx.doi.org/10.1016/j.neuroimage.2005.12.008 (2006).
55. Jasdzewski, G. et al. Differences in the hemodynamic response to event-related motor and visual paradigms as measured by near-
infrared spectroscopy. NeuroImage 20, 479–488, doi: http://dx.doi.org/10.1016/S1053-8119(03)00311-2 (2003).
56. Schaeffer, J. D. et al. An fNIRS investigation of associative recognition in the prefrontal cortex with a rapid event-related design. 
Journal of Neuroscience Methods 235, 308–315, doi: http://dx.doi.org/10.1016/j.jneumeth.2014.07.011 (2014).
57. Plichta, M. M., Heinzel, S., Ehlis, A. C., Pauli, P. & Fallgatter, A. J. Model-based analysis of rapid event-related functional near-
infrared spectroscopy (NIRS) data: A parametric validation study. NeuroImage 35, 625–634, doi: http://dx.doi.org/10.1016/j.
neuroimage.2006.11.028 (2007).
58. Herrmann, M. J. et al. Enhancement of activity of the primary visual cortex during processing of emotional stimuli as measured with 
event-related functional near-infrared spectroscopy and event-related potentials. Human Brain Mapping 29, 28–35, doi: 10.1002/
hbm.20368 (2008).
Acknowledgements
The authors would like to thank Dr. Uri Hershberg for his assistance. UH was funded by 1DP1HD091948-01.
Author Contributions
Y.L. performed the experiment, collected the fNIRS data, analyzed the data and prepared/wrote the manuscript. 
E.P. analyzed the data and prepared/wrote the manuscript. E.S. collected the fMRI data, and participated 
in manuscript revision. P.A.S. provided advice on the statistical approach and participated in manuscript 
revision. B.O. supported the idea and participated in manuscript revision. U.H. supported the idea, designed 
the experiment, discussed and interpreted the results and revised the manuscript. H.A. initiated and supervised 
the study, designed the experiment, analyzed the data, discussed and interpreted the results as well as prepared/
revised the manuscript.
 www.nature.com/scientificreports/
13
Scientific RepoRts | 7:43293 | DOI: 10.1038/srep43293
Additional Information
Supplementary information accompanies this paper at http://www.nature.com/srep
Competing financial interests: fNIR Devices, LLC manufactures the optical brain imaging instrument and 
licensed IP and know-how from Drexel University. Drs. Onaral and Ayaz were involved in the technology 
development and thus offered a minor share in the new startup firm fNIR Devices, LLC.
How to cite this article: Liu, Y. et al. Measuring speaker-listener neural coupling with functional near infrared 
spectroscopy. Sci. Rep. 7, 43293; doi: 10.1038/srep43293 (2017).
Publisher's note: Springer Nature remains neutral with regard to jurisdictional claims in published maps and 
institutional affiliations.
This work is licensed under a Creative Commons Attribution 4.0 International License. The images 
or other third party material in this article are included in the article’s Creative Commons license, 
unless indicated otherwise in the credit line; if the material is not included under the Creative Commons license, 
users will need to obtain permission from the license holder to reproduce the material. To view a copy of this 
license, visit http://creativecommons.org/licenses/by/4.0/
 
© The Author(s) 2017
