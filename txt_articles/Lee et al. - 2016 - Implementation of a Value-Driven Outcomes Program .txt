 Copyright 2016 American Medical Association. All rights reserved.
Implementation of a Value-Driven Outcomes Program
to Identify High Variability in Clinical Costs and Outcomes
and Association With Reduced Cost and Improved Quality
Vivian S. Lee, MD, PhD, MBA; Kensaku Kawamoto, MD, PhD, MHS; Rachel Hess, MD, MS; Charlton Park, MBA, MHSM; Jeffrey Young, MS;
Cheri Hunter, BS; Steven Johnson, LSMBB, MBA; Sandi Gulbransen, BSIE; Christopher E. Pelt, MD; Devin J. Horton, MD;
Kencee K. Graves, MD; Tom H. Greene, PhD; Yoshimi Anzai, MD, MPH; Robert C. Pendleton, MD
IMPORTANCE Transformation of US health care from volume to value requires meaningful
quantification of costs and outcomes at the level of individual patients.
OBJECTIVE To measure the association of a value-driven outcomes tool that allocates costs of
care and quality measures to individual patient encounters with cost reduction and health
outcome optimization.
DESIGN, SETTING, AND PARTICIPANTS Uncontrolled, pre-post, longitudinal, observational
study measuring quality and outcomes relative to cost from 2012 to 2016 at University of
Utah Health Care. Clinical improvement projects included total hip and knee joint
replacement, hospitalist laboratory utilization, and management of sepsis.
EXPOSURES Physicians were given access to a tool with information about outcomes, costs
(not charges), and variation and partnered with process improvement experts.
MAIN OUTCOMES AND MEASURES Total and component inpatient and outpatient direct costs
across departments; cost variability for Medicare severity diagnosis related groups measured
as coefficient of variation (CV); and care costs and composite quality indexes.
RESULTS FromJuly1,2014,toJune30,2015,therewere1.7milliontotalpatientvisits,including
34 000inpatientdischarges.Professionalcostsaccountedfor24.3%oftotalcostsforinpatient
episodes($114.4millionof$470.4million)and41.9%oftotalcostsforoutpatientvisits
($231.7millionof$553.1million).ForMedicareseveritydiagnosisrelatedgroupswiththehighest
totaldirectcosts,costvariabilitywashighestforpostoperativeinfection(CV = 1.71)andsepsis
(CV = 1.37)andamongthelowestfororgantransplantation(CV � 0.43).Fortotaljoint
replacement,acompositequalityindexwas54%atbaseline(n = 233encounters)and80%
1yearintotheimplementation(n = 188encounters)(absolutechange,26%;95%CI,18%-35%;
P < .001).Comparedwiththebaselineyear,meandirectcostswere7%lowerinthe
implementationyear(95%CI,3%-11%;P < .001)and11%lowerinthepostimplementationyear
(95%CI,7%-14%;P < .001).Thehospitalistlaboratorytestingmeancostperdaywas$138
(median[IQR],$113[$79-160];n = 2034encounters)atbaselineand$123(median[IQR],
$99[$66-147];n = 4276encounters)intheevaluationperiod(meandifference,−$15;95%CI,−$19
to−$11;P < .001),withnosignificantchangeinmeanlengthofstay.Forapilotsepsisintervention,
themeantimetoanti-infectiveadministrationfollowingfulfillmentofsystemicinflammatoryresponse
syndromecriteriainpatientswithinfectionwas7.8hours(median[IQR],3.4[0.8-7.8]hours;
n = 29encounters)atbaselineand3.6hours(median[IQR],2.2[1.0-4.5]hours;n = 76encounters)
intheevaluationperiod(meandifference,−4.1hours;95%CI,−9.9to−1.0hours;P = .02).
CONCLUSIONS AND RELEVANCE Implementation of a multifaceted value-driven outcomes tool
to identify high variability in costs and outcomes in a large single health care system was
associated with reduced costs and improved quality for 3 selected clinical projects. There may
be benefit for individual physicians to understand actual care costs (not charges) and
outcomes achieved for individual patients with defined clinical conditions.
JAMA. 2016;316(10):1061-1072. doi:10.1001/jama.2016.12226
Editorial page 1047
Author Audio Interview
Supplemental content
CME Quiz at
jamanetworkcme.com
Author Affiliations: University of
Utah, Salt Lake City.
Corresponding Author: Vivian S.
Lee, MD, PhD, MBA, University of
Utah Senior Vice President’
s Office,
175 N Medical Dr E, Clinical
Neurosciences Bldg, Salt Lake City,
UT 84132 (vivian.lee@hsc.utah.edu).
Research
JAMA | Original Investigation | INNOVATIONS IN HEALTH CARE DELIVERY
(Reprinted)
1061
Copyright 2016 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/02/2019
 Copyright 2016 American Medical Association. All rights reserved.
F
ee-for-servicepaymentmodelsrewardcarevolumeover
value.1,2 Under fee-for-service models, health care costs
are increasing at a rate of 5.3% annually, accounted for
17.7% of the US gross domestic product in 2014, and are pro-
jected to increase to 19.6% of the gross domestic product by
2024.3 Value-based payment models and alternative pay-
ment models incentivize the provision of efficient, high-
quality, patient-centered care through financial penalties and
rewards.4 Under alternative payment models, clinicians will
theoretically deliver higher-quality care that results in better
outcomes, fewer complications, and reduced health care
spending. To implement alternative payment models effec-
tively, physicians must understand actual care costs (not
charges) and outcomes achieved for individual patients with
defined clinical conditions—the level at which they can most
directly influence change.
Few large health care organizations have accurately mea-
sured total care costs at the individual patient level and have
related costs to quality.5,6 In 2012, University of Utah Health
Care initiated an enterprise-wide effort to improve clinical out-
comes and reduce costs and built a management and report-
ing tool, called value-driven outcomes, that allows clinicians
and managers to analyze actual system costs and outcomes at
the level of individual encounters and by department, physi-
cian, diagnosis, and procedure.7
This report describes how the value-driven outcomes
tool was used to (1) identify overall care costs across the health
care system, (2) measure cost variability across Medicare
severity diagnosis related groups (MS-DRGs) to identify the
greatest opportunities for cost reduction and outcome opti-
mization, and (3) support value improvement initiatives for se-
lected conditions.
Methods
The project was reviewed by the University of Utah Institu-
tional Review Board and was deemed not to meet the defini-
tion of human subjects research. It was therefore exempt from
institutionalreviewboardoversight,andinformedconsentwas
not required.
Value-Driven Outcomes
The value-driven outcomes tool uses the definition of value
by Porter and Teisberg8: health outcomes achieved per dollar
spent,inwhichoutcomesaremeasuredintermsofqualitymet-
rics, such as the patient’
s overall health status and the avoid-
ance of hospital-acquired morbidities. The value-driven out-
comes tool is a modular, extensible framework that allocates
care costs to individual patient encounters. It draws informa-
tion from the health care system’
s enterprise data ware-
house, which includes data on patient encounters; national
quality metrics and clinician-defined metrics; supply, phar-
macy,imaging,andlaboratoryutilization;humanresourceuti-
lization; and the general ledger (ie, the organization’
s com-
plete record of financial transactions). The value-driven
outcomes tool uses these data to calculate and integrate cost
information with relevant quality and outcome measures.7
Identifying Overall Health Care System Costs
Accurately assigning costs is complex and can take multiple
perspectives, including those of the health care system, payer,
patient, or society. To understand the role of prospective pay-
ment in the health care system context, the value-driven out-
comes cost accounting approach takes the health care system
perspective and identifies costs attributable to direct patient
care. Certain large groups of costs, such as space, equipment,
labor, and professional time, are allocated based on a pa-
tient’
s estimated use of those resources, whereas costs for sup-
plies, medications, and contracted services are based on the
health care system’
s actual acquisition costs. Physician costs
are allocated according to work relative value units (wRVUs)
as follows: physician salary and benefits are multiplied by the
percentage of effort devoted to clinical care; education, re-
search, and service (eg, committee and administrative work)
are not included in the percentage of effort. Annual clinical
compensation divided by annual wRVUs produces a measure
of cost (in dollars) per wRVU for each physician7 (Table 1). For
theanalysisofoverallhealthsystemcosts,totaldirectcarecosts
for inpatient admissions and outpatient visits were deter-
mined overall and by major departments from July 1, 2014,
through June 30, 2015.
Identifying the Greatest Opportunities for Cost Reduction
and Outcome Optimization
Identifying Cost Variability
For every MS-DRG (such as MS-DRG 470, major joint replace-
ment of the lower extremity without major complications or
comorbidities, and MS-DRG 871, sepsis), the overall cost per
unit or cost per case, the components of that cost (Table 1),
and cost variability were identified. Variability was calculated
using the coefficient of variation (CV; standard deviation
divided by mean) to standardize the measure of dispersion
across conditions. Highly variable, high-cost conditions were
identified as potential areas for care standardization and
value improvement.
Defining Outcomes
Clinical teams consisting of physicians, nurses, administra-
tors, and quality improvement staff defined clinically relevant
Key Points
Question Is use of an analytic tool that allocates clinical care costs
and quality measures to individual patient encounters in a health
care system associated with reduced costs and improved patient
outcomes?
Findings In this observational study in a health care system with
1.7 million patient visits per year, costs of care varied considerably.
In pre-post comparisons, implementation of the analytic tool was
associated with a significant decrease in costs (7%-11% for total
joint replacement and 11% for laboratory testing) and
improvement in quality.
Meaning Implementation of a tool that provides physicians
with information about the costs of clinical care and quality for
individual patients with defined conditions was associated with
a reduction in costs and improvement in quality.
Research Original Investigation
Value-Driven Outcomes Program and Health Care Cost and Quality
1062
JAMA
September 13, 2016
Volume 316, Number 10
(Reprinted)
jama.com
Copyright 2016 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/02/2019
 Copyright 2016 American Medical Association. All rights reserved.
and patient-centered outcomes, which were then queried
from the data warehouse. Outcomes included risk-adjusted
mortality,9 patient safety measures (eg, hospital-acquired in-
fections), clinical process measures, and unplanned hospital
readmissions or emergency department visits. Patient satis-
factiondata10andpatient-reportedoutcomes(includingphysi-
cal and emotional functioning) were collected directly from
patients using surveys such as the Patient-Reported Out-
comes Measurement Information System.11 Elements of care
provision, including key quality indexes, were collected on ev-
ery case.
Additionally, the care team selected key quality and out-
come variables that were combined into a single binary mea-
sure termed perfect care. If a continuous variable was chosen
as a key variable, the team established an evidence-based
threshold (for example, for time receiving mechanical venti-
lation following coronary artery bypass grafting surgery, <24
hours of time would be considered perfect care). If a compos-
ite index was included (such as Surgical Care Improvement
Project [SCIP] composite), it was treated as an all-or-none mea-
sure; 1 SCIP failure would result in a perfect care score of 0.
Perfect care was set to 1 for an encounter only if the care team
accomplished all the key elements. The perfect care index is
reported as the percentage of perfect care encounters per pe-
riod of measurement (see eTable 1 in the Supplement for ex-
amples of perfect care indexes).
Using Value-Driven Outcomes to Improve Care
Multidisciplinary value improvement teams included clini-
cians, administrative leaders, and process engineers. After
these teams defined the key metrics for quality and perfect
care, they viewed and monitored care costs and quality met-
rics (Table 2) using institutional web-based value-driven out-
comes visualization tools. The data were used to provide feed-
back to clinicians monthly on an individual patient basis or
aggregated at the clinician or service-line level to facilitate
broader understanding of variations in cost and quality. Ex-
amples of individual patient–specific reports are included in
eFigure 1 and eFigure 2 in the Supplement. Cost and outcome
variability among physicians were used to identify opportu-
nities for clinical improvement.
Three of the initial 5 pilot improvement projects are re-
ported herein: total joint replacement of the lower extremity
(hip and knee), hospitalist laboratory utilization, and sepsis
management. Total joint replacement and sepsis were iden-
tified as initial pilots based on an opportunity assessment of
total volume, total cost, and high variation using the value-
driven outcomes cost variation analyses. Laboratory utiliza-
tion was selected as an initiative to use value-driven out-
comes data to improve care across clinical conditions within
a specific direct cost category and was based on the Choosing
Wisely campaign12 and interinstitutional benchmarking
Table 1. Value-Driven Outcomes Approach to Assigning Direct Cost
for a Given Area
Area of Cost
Sources of Cost Data
Method of Cost
Assignment
Facility
utilizationa
All facility-paid general ledger
expenses for operating a clinical
unit where patients can be
located (eg, emergency
department, cardiology inpatient
ward, family medicine clinic),
including nursing, space,
and equipment costsb
For inpatient units,
time the patient
spent on the unit;
for outpatient clinics,
average facility
expenses for a visit
to that clinic
Imagingc
All facility-paid general ledger
expenses for operating an
imaging unit (eg, magnetic
resonance imaging unit,
computed tomography unit),
including equipment, space,
and technician costsb
Time-based for
patient use
Laboratory
testingc
Existing contracts
Actual patient use
Therapy services
All facility-paid general ledger
expenses associated with
operating a therapy service
(eg, respiratory therapy, physical
therapy), including personnel
and equipment costsb
Patient use of
services as identified
from billing charges
Medications
administeredc
Acquisition costs
Actual patient use
Supplies
Acquisition costs
Actual patient use
Professional
services
Physician human resource costs
for clinical care, as well as other
general ledger clinical expenses
paid by physicians and their
representatives (eg, medical
assistant costs paid by medical
group), grouped by unit
(eg, cardiology)b
wRVU billing by
physician
Abbreviation: wRVU, work relative value unit.
a Costs related to maintenance, renovation, and new construction are
considered indirect costs and are not included in the direct costs.
bGeneral ledger expenses for clinical units refer to all expenses recorded in the
organization’
s complete record of financial transactions.
c Outpatient laboratory, pharmacy (medications administered), and imaging
costs include only that care delivered at the University of Utah.
Table 2. Examples of Value-Driven Outcomes Metrics
Metric
Measure
Description
Visualization Technique
Opportunity
index
Coefficient of
variation multiplied
by total direct cost
At the MS-DRG level, standard deviation of total
direct costs of care across patients divided by
mean of total direct costs per encounter, then
multiplied by total direct costs for the system
across all patients for this MS-DRG per year
Tables and bubble charts
Physician care
costs
Mean cost
For a given patient, the total wRVUs attributed
to a physician multiplied by the cost (in dollars)
per wRVU calculated for that physician
for that year
Tables, column charts,
and bubble charts
Perfect care
index
Aggregate of
multiple quality and
outcome measures
For each patient, attainment of all quality and
outcome measures achieves a perfect care score
of 1; failure in any area means a perfect care
score of 0; index is reported as % of patient
encounters in which perfect care is achieved
Tables and charts,
typically plotted against
time, alongside cost data
Abbreviations: MS-DRG, Medicare
severity diagnosis related group;
wRVU, work relative value unit.
Value-Driven Outcomes Program and Health Care Cost and Quality
Original Investigation Research
jama.com
(Reprinted)
JAMA
September 13, 2016
Volume 316, Number 10
1063
Copyright 2016 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/02/2019
 Copyright 2016 American Medical Association. All rights reserved.
through the University HealthSystem Consortium. The 2 pi-
lot projects not discussed herein were coronary artery bypass
grafting surgery and hip fracture care, owing to delays in proj-
ect initiation.
Statistical Analysis
All evaluations were based on direct comparisons of outcomes
betweendesignatedtimeintervalsprecedingandfollowingthe
exposures without adjustment for covariates (such as age, sex,
race, and socioeconomic status).
Total Joint Replacement
Changes in mean costs and length of stay after exposures
were assessed using a 12-month baseline period of April 1,
2012, to March 31, 2013, and successive 12-month evalua-
tion periods of April 1, 2013, to March 31, 2014, and April 1,
2014, to March 31, 2015. Costs were normalized to the mean
cost during the baseline period. The proportions of patients
meeting initial and modified perfect care criteria were com-
pared between designated 4-month intervals. Two patients
whose costs exceeded the mean cost by more than 5 SDs on
the log scale were excluded from cost analyses. Only attend-
ing physicians who practiced during the entire study period
were included.
Hospitalist Laboratory Utilization
Changes in daily laboratory utilization, daily laboratory costs,
length of stay, and risk of 30-day readmission were assessed
between a baseline period of July 1, 2012, to January 31, 2013,
and an evaluation period of February 1, 2013, to April 30, 2014,
which followed exposure to education (a 30-minute baseline
didactic lecture on laboratory overuse and associated cost im-
plications and provision of a pocket card outlining cost differ-
ences between common laboratory tests).
Sepsis Value Improvement
The primary evaluation of the sepsis value improvement
project was the time from systemic inflammatory response
syndrome (SIRS) criteria13 being met to first anti-infective
agent administration. Criteria for SIRS have historically been
used to diagnose sepsis in the context of infection. All
patients evaluated in this analysis were selected by Interna-
tional Classification of Diseases, Ninth Revision codes and
International Statistical Classification of Diseases and Related
Health Problems, Tenth Revision codes for sepsis; as such, all
were presumed to have infection and should have received
an anti-infective agent. Patients who did not have a diagnos-
tic code for sepsis were not considered in this analysis. For
patients who received anti-infective agents prior to meeting
SIRS criteria, the time to anti-infective agent administration
was considered to be 0 hours. Secondary evaluation mea-
sures included length of stay, mortality, and total direct cost
normalized to the baseline mean cost. The proportions of
patients with anti-infective agents administered within 24
hours of meeting SIRS criteria for nosocomial and multidrug-
resistant infections as well as community-acquired infections
were measured to assess whether the pattern of anti-
infective agent use changed. The baseline period was July 1,
2014, to December 31, 2014, and the evaluation period was
November 2, 2015, to February 29, 2016. Potential sepsis
cases were identified through billing data and confirmed by
physician medical record audit. Patients were excluded if
they never received anti-infective agents, did not have docu-
mentation of infection or sepsis (based on diagnostic code),
or were transferred from another hospital while receiving
anti-infective agents.
Details of Statistical Models
Descriptive summaries are provided as counts and percent-
ages for binary variables and as means and standard devia-
tions for numeric variables, with medians and interquartile
ranges (IQRs) also provided for highly skewed continuous
variables. Proportions of deaths were compared between the
evaluation and baseline periods of the sepsis project using
Fisher exact tests; generalized linear models14 were used to
analyze changes between the baseline and evaluation periods
for all other outcomes. The generalized linear models used
binary outcomes for comparisons of perfect care indexes,
30-day mortality, and the proportions of patients with anti-
infective agents administered for nosocomial and multidrug-
resistant infections and for community-acquired infections.
Gamma outcomes were used for costs, length of stay, and
time to administration of anti-infective agents.
For each of these outcomes, log and identity link func-
tions were used to evaluate relative change and absolute
change, respectively. Negative binomial outcome models with
log link functions and offset equal to log length of stay were
used to analyze relative changes in the number of tests or-
dered per day, including basic metabolic panels, complete
metabolic panels, and complete blood counts. A Taylor series
approximation was applied to the results of these analyses to
evaluate absolute changes in numbers of laboratory tests per
day. In the joint replacement and laboratory utilization proj-
ects, statistical inferences were performed using asymptotic
likelihoodratioorWaldstatistics.Toaccountforpositiveskew-
ness and smaller sample sizes, confidence intervals in the sep-
sis project were obtained using the bias-correction and accel-
erated bootstrap method15 with 1000 bootstrap samples, and
P values were computed using permutation tests.
The joint replacement and laboratory utilization analy-
ses were conducted using SAS version 9.4 statistical software
(SAS Institute Inc). The sepsis analysis was performed using
R version 3.3.0 statistical software (R Foundation). All hypoth-
esis tests were performed using 2-sided α = .05 without ad-
justment for multiple comparisons.
Results
Overall Care Costs
During the fiscal year from July 1, 2014, to June 30, 2015
(Table 3), University of Utah Health Care had approximately
34 000 inpatient discharges, 52 000 emergency department
visits, and 1.7 million total patient visits.
Inpatient total direct care costs ($470.4 million) ac-
counted for 46.0% of total direct costs, and outpatient direct
Research Original Investigation
Value-Driven Outcomes Program and Health Care Cost and Quality
1064
JAMA
September 13, 2016
Volume 316, Number 10
(Reprinted)
jama.com
Copyright 2016 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/02/2019
 Copyright 2016 American Medical Association. All rights reserved.
costs ($553.1 million) accounted for 54.0%. For inpatient care,
facility utilization (37.7%) and professional services (24.3%)
were the largest cost components. Table 3 also shows total an-
nual direct costs by discharge department (inpatient). Re-
source use varied considerably by both department and care
location. With $151.4 million in inpatient costs, the surgery de-
partment had the highest overall costs among departments.
Together, the surgery and internal medicine departments con-
stituted 51.8% of total inpatient costs.
Cost components (eg, laboratory tests, supplies, profes-
sional costs) for inpatient and outpatient care varied consid-
erably across departments (Table 3). Among inpatient epi-
sodes,professionalcostsaccountedfor24.3%oftotalcostsand
exceeded 30% for obstetrics and gynecology (47.5%) and neu-
rosurgery (32.9%). Supply costs represented 32.0% of all or-
thopedic surgery inpatient costs and 16.8% of all neurosur-
gery inpatient costs. Laboratory costs also varied considerably.
For example, 7.0% of inpatient costs in internal medicine were
attributabletolaboratorytesting,comparedwith2.8%forneu-
rosurgery and 2.6% for orthopedic surgery.
Table 3 also shows total annual direct costs by physician
department for outpatient visits. With $107.2 million in out-
patient costs, the surgery department had the highest overall
costs among departments. Together, the surgery and internal
medicine departments constituted 49.3% of total outpatient
costs. For outpatient care, professional services (41.9%),
facility utilization (18.4%), and therapy services (eg, physical
and respiratory therapy; 14.2%) were the largest components
(Table 3). Among outpatient visits, professional costs
accounted for 41.9% of total costs overall, with pediatrics
(78.6%), dermatology (77.3%), and family and preventive
medicine (62.4%) exceeding 60%; however, these 3 depart-
ments had among the lowest supply and medication costs.
Cost Variability
Total professional and facility costs for the MS-DRG discharge
diagnoseswiththehighesttotaldirectcostsover1yearandtheir
CVs across hospitalizations are shown in Table 4. The total cost
and CV provided an assessment of the largest potential oppor-
tunities for value improvement through care standardization.
Table 3. Inpatient and Outpatient Total Direct Care Costs Overall and by Major Departments, From July 1, 2014, to June 30, 2015
Department
Cost, $ in Millions (% of Total Department)
Facility
Utilization
Imaginga
Laboratorya
Therapy
Services
Administered
Medicationsa
Supply
Total
Professional
Total
Inpatient
Internal medicine
30.0 (32.5)
1.1 (1.2)
6.4 (7.0)
15.9 (17.3)
14.1 (15.3)
6.6 (7.1)
18.1 (19.6)
92.2
Neurology
2.5 (32.9)
0.2 (2.8)
0.3 (3.5)
1.7 (22.6)
0.7 (9.4)
0.2 (2.8)
1.9 (26.0)
7.5
Neurosurgery
13.5 (25.7)
1.2 (2.3)
1.5 (2.8)
7.6 (14.6)
2.6 (5.0)
8.8 (16.8)
17.3 (32.9)
52.5
Obstetrics and gynecology
7.4 (32.3)
0.1 (0.4)
0.7 (3.1)
1.5 (6.7)
1.8 (7.7)
0.5 (2.2)
10.9 (47.5)
23.0
Orthopedic surgery
13.0 (25.5)
0.8 (1.5)
1.3 (2.6)
4.3 (8.5)
2.3 (4.4)
16.3 (32.0)
13.0 (25.4)
51.0
Physical medicine and
rehabilitation
5.9 (49.5)
0.0 (0.4)
0.2 (1.5)
3.5 (29.7)
0.5 (3.8)
0.2 (1.8)
1.6 (13.3)
11.9
Radiology
4.0 (31.7)
0.4 (3.3)
0.7 (5.8)
1.9 (15.1)
1.5 (11.6)
1.2 (9.9)
2.8 (22.7)
12.6
Surgery
54.7 (36.1)
0.9 (0.6)
7.5 (5.0)
15.5 (10.3)
12.6 (8.3)
26.5 (17.5)
33.7 (22.3)
151.4
Other departments
41.8 (62.4)
0.2 (0.3)
1.5 (1.7)
5.0 (7.4)
2.3 (3.4)
1.3 (1.9)
15.3 (22.9)
66.9
All departments
177.1 (37.7)
4.5 (1.0)
20.0 (4.2)
55.4 (11.8)
37.8 (8.0)
61.2 (13.0)
114.4 (24.3)
470.4
Outpatient
Dermatology
1.8 (7.8)
0.0 (0.1)
0.3 (1.2)
1.3 (5.5)
1.7 (8.0)
0.0 (0.1)
18.0 (77.3)
23.1
Family and preventive medicine
6.2 (20.1)
1.4 (4.4)
2.1 (6.9)
1.1 (3.6)
0.8 (2.5)
0.1 (0.1)
19.2 (62.4)
30.7
Internal medicine
20.1 (12.2)
4.0 (2.4)
8.8 (5.3)
30.0 (18.1)
50.8 (30.7)
8.6 (5.2)
43.4 (26.2)
165.6
Neurology
3.6 (22.0)
0.8 (4.8)
0.5 (3.0)
1.6 (9.9)
4.0 (24.6)
0.1 (0.2)
5.8 (35.6)
16.4
Neurosurgery
2.9 (18.9)
0.8 (5.5)
0.1 (0.6)
0.9 (5.6)
1.4 (9.4)
4.0 (25.8)
5.3 (34.3)
15.4
Obstetrics and gynecology
6.3 (23.3)
1.4 (5.2)
1.7 (6.4)
2.8 (10.6)
0.9 (3.5)
0.6 (2.1)
13.1 (48.9)
26.8
Ophthalmology
9.1 (23.5)
0.1 (0.1)
0.1 (0.2)
2.9 (7.4)
6.2 (16.0)
1.8 (4.6)
18.6 (48.2)
38.6
Orthopedic surgery
8.1 (24.2)
1.3 (3.9)
0.2 (0.6)
1.2 (3.5)
1.5 (4.4)
3.6 (10.7)
17.7 (52.9)
33.4
Pathology
0.0 (8.5)
0.0 (3.3)
0.1 (9.8)
0.0 (5.1)
0.2 (32.6)
0.0 (0.0)
0.2 (40.6)
0.5
Pediatrics
1.9 (5.4)
0.2 (0.6)
0.5 (1.4)
1.5 (4.3)
3.2 (9.0)
0.3 (0.7)
27.9 (78.6)
35.6
Physical medicine and
rehabilitation
1.5 (25.7)
0.4 (6.8)
0.1 (0.6)
0.1 (2.0)
1.3 (22.6)
0.1 (1.4)
2.4 (41.0)
5.9
Radiation oncology
0.2 (1.7)
0.3 (1.9)
0.1 (0.2)
9.8 (65.8)
0.1 (0.7)
0.2 (1.2)
4.3 (28.5)
14.9
Radiology
0.9 (11.3)
1.1 (13.6)
0.1 (1.7)
0.6 (7.4)
0.2 (2.7)
2.7 (33.9)
2.4 (29.5)
8.0
Surgeryb
30.8 (28.7)
3.1 (2.9)
2.1 (2.0)
16.6 (15.5)
3.2 (3.0)
8.6 (8.0)
42.7 (39.9)
107.2
Other departments
8.6 (27.9)
1.2 (3.9)
0.5 (1.5)
8.0 (25.9)
0.9 (2.9)
0.9 (2.8)
10.8 (35.1)
30.7
All departments
102.0 (18.4)
16.1 (2.9)
17.1 (3.1)
78.4 (14.2)
76.6 (13.9)
31.2 (5.6)
231.7 (41.9)
553.1
a Outpatient laboratory, pharmacy (medications administered), and imaging costs include only that care delivered at the University of Utah.
bEmergency department is included in the department of surgery.
Value-Driven Outcomes Program and Health Care Cost and Quality
Original Investigation Research
jama.com
(Reprinted)
JAMA
September 13, 2016
Volume 316, Number 10
1065
Copyright 2016 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/02/2019
 Copyright 2016 American Medical Association. All rights reserved.
As shown in Table 4, patient conditions with the highest
CV included postoperative infection (MS-DRG 853; CV = 1.71;
magnitude of difference between lowest and highest total di-
rect cost per patient = $225 927) and sepsis (MS-DRG 871;
CV = 1.37; magnitude of difference between lowest and high-
est total direct cost per patient = $210 679), both areas of cur-
rent clinical improvement work. For the highest-volume
elective procedures, component cost variability was also ex-
amined. Total joint replacement of the lower extremity
(MS-DRG 470) showed an overall CV of 0.33. However, the 2
largest component costs, supply costs (CV = 0.66; magnitude
of difference between lowest and highest total supply direct
cost per patient = $20 966) and facility utilization costs
(CV = 0.44; magnitude of difference between lowest and high-
est total facility utilization direct cost per patient = $12 085),
illustratedhighervariability,suggestinganimportantfocusarea
for improvement.
Selected Clinical Improvement Projects
The clinical characteristics of the patients in the baseline pe-
riod and in the evaluation period for each of the 3 clinical im-
provement projects are provided in eTable 2 in the Supple-
ment. Results from the 3 projects are provided in Table 5.
Total Joint Replacement
Orthopedic surgeons identified lower extremity joint replace-
ment (MS-DRG 470) as a high-volume elective procedure as-
sociated with variability in supply and facility utilization costs
(Table 4). In November 2012, a team led by an orthopedic sur-
geon and facilitated by a process engineer developed a con-
sensus clinical pathway for patients undergoing hip and knee
joint replacement (eFigure 3 in the Supplement).
The multidisciplinary team defined a perfect care index
for joint replacement comprising 6 nationally and locally de-
fined quality indicators: (1) 30-day readmission; (2) SCIP
composite16; (3) 35 Hospital Acquired Condition/Patient Safety
Indicator measures17,18; (4) admission to the orthopedic acute
care unit during hospitalization; (5) early mobility (out of bed
on day of surgery); and (6) emergency department visit within
90 days of discharge.
Care process redesign began in April 2013 and included 1
componentofthecarepathwayintervention,earlymobility,19,20
as has been previously reported.21 After 1 year, the 4-month
mean perfect care index increased from 54% to 80% (26% in-
crease; 95% CI, 18%-35%; P < .001). Because several compo-
nents of the initial perfect care index were consistently being
met (readmission, SCIP composite, early mobility), the team
Table 4. MS-DRG Diagnoses With Highest Total Direct Costsa
MS-DRG
Most Common Primary ICD-9
Discharge Diagnosis
CV of
Direct Costsb
Discharging
Physicians,
No.c
Total
Direct Cost, $
853, Postoperative infection
038.9, Unspecified septicemia
1.71
78
6 367 587
871, Sepsis
038.9, Unspecified septicemia
1.37
195
10 277 210
791, Prematurity (neonate)
V30.00, Single liveborn
without cesarean delivery
1.11
45
3 563 059
927, Extensive burns
943.31, Full-thickness skin loss
due to burn of forearm
1.05
4
4 217 139
765, Cesarean delivery
654.21, Cesarean delivery
without antepartum condition
0.87
61
3 501 422
790, Extreme immaturity
or RDS (neonate)
V30.01, Single liveborn
by cesarean delivery
0.86
45
11 156 500
945, Rehabilitation
V57.89, Other specified
rehabilitation procedure
0.78
47
11 940 543
003, ECMO or ventilation
430, Subarachnoid hemorrhage
0.73
54
18 152 760
025, Craniotomy,
endovascular procedure
225.2, Benign neoplasm of
cerebral meninges
0.73
26
8 766 040
014, Allogeneic bone
marrow transplant
204.00, Acute lymphoid leukemia
without achieved remission
0.58
11
3 595 457
897, Alcohol or drug abuse
291.81, Alcohol withdrawal
0.56
56
4 746 488
775, Vaginal delivery
645.11, Postterm delivery
without antepartum condition
0.54
122
6 103 694
219, Cardiac valve
424.1, Aortic valve disorders
0.50
6
3 929 829
005, Liver transplant
070.44, Chronic hepatitis C
with hepatic coma
0.43
4
6 863 669
001, Heart transplant
or implant
428.23, Acute on chronic systolic
heart failure
0.43
3
11 388 979
473, Cervical spinal fusion
721.1, Cervical spondylosis
with myelopathy
0.37
15
3 392 178
460, Spinal fusion
(except cervical)
724.03, Spinal stenosis of lumbar
region with neurogenic
claudication
0.37
14
8 913 159
470, Major joint replacement
(lower extremity)
715.36, Localized osteoarthrosis
of lower leg
0.33
17
10 602 664
652, Kidney transplant
403.91, Hypertensive chronic
kidney disease, unspecified
0.14
3
8 164 310
Abbreviations: CV, coefficient of
variation; ECMO, extracorporeal
membrane oxygenation;
ICD-9, International Classification
of Diseases, Ninth Revision;
MS-DRG, Medicare severity diagnosis
related group; RDS, respiratory
distress syndrome.
a The opportunity index described
in Table 2 is derived by multiplying
the CV of direct costs by the total
direct costs.
bThe CVs (standard deviation divided
by mean) are shown for direct costs
of care across all patient episodes
from July 1, 2014, to June 30, 2015,
for the conditions accounting for
highest total direct costs of care
for the organization.
c Discharging physicians data reflect
the number of physicians who
discharged patients under each
selected MS-DRG.
Research Original Investigation
Value-Driven Outcomes Program and Health Care Cost and Quality
1066
JAMA
September 13, 2016
Volume 316, Number 10
(Reprinted)
jama.com
Copyright 2016 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/02/2019
 Copyright 2016 American Medical Association. All rights reserved.
Table 5. Results From Value Improvement Projects
Outcome Measure
Period
Descriptive Summarya
Statistical Comparison of Evaluation
vs Baseline Periods
Baseline
Evaluation
Baseline
Evaluation
Absolute Change
(95% CI)b
Relative Change,
% (95% CI)c
P Valued
Total Joint Replacement
Perfect care encounters,
No. (%)e
Definition 1
12/2012-3/2013
1/2014-4/2014
126 (54)
(n = 233)
151 (80)
(n = 188)
26 (18 to 35)
49 (30 to 71)
<.001
Definition 2
5/2013-8/2013
12/2014-3/2015
112 (50)
(n = 222)
138 (65)
(n = 211)
15 (6 to 24)
30 (10 to 53)
.002
Length of stay,
mean (SD), d
First evaluation year
4/2012-3/2013
4/2013-3/2014
3.50 (1.53)
(n = 636)
3.17 (1.21)
(n = 637)
−0.33
(−0.47 to −0.20)
−9.5
(−13.0 to −5.8)
<.001
Second evaluation year
4/2012-3/2013
4/2014-3/2015
3.50 (1.53)
(n = 636)
2.88 (1.16)
(n = 658)
−0.63
(−0.76 to −0.50)
−18.0
(−21.1 to −14.6)
<.001
Cost per admission,
normalized to mean
at baseline, mean (SD)
First evaluation year
4/2012-3/2013
4/2013-3/2014
1.00 (0.50)
(n = 634)
0.93 (0.39)
(n = 637)
NAf
−7 (−11 to −3)
<.001
Second evaluation year
4/2012-3/2013
4/2014-3/2015
1.00 (0.50)
(n = 634)
0.89 (0.38)
(n = 658)
NAf
−11 (−14 to −7)
<.001
Hospitalist Laboratory Utilization
Metabolic panels,
mean (SD), No./d
Basic
7/2012-1/2013
2/2013-4/2014
0.75 (1.03)
(n = 2034)
0.63 (1.05)
(n = 4276)
−0.13
(−0.16 to −0.10)g
−17
(−20 to −14)
<.001
Complete
7/2012-1/2013
2/2013-4/2014
0.32 (0.68)
(n = 2034)
0.23 (0.58)
(n = 4276)
−0.10
(−0.13 to −0.07)g
−29
(−33 to −25)
<.001
Complete blood count
tests, mean (SD), No./d
7/2012-1/2013
2/2013-4/2014
0.92 (0.79)
(n = 2034)
0.64 (0.76)
(n = 4276)
−0.28
(−0.31 to −0.26)g
−30
(−32 to −28)
<.001
Length of stay, d
7/2012-1/2013
2/2013-4/2014
(n = 2034)
(n = 4276)
Mean (SD)
4.48 (5.12)
4.54 (4.67)
0.06
(−0.11 to 0.23)
1 (−2 to 5)
.48
Median (IQR)
3.17
(2.02-5.00)
3.20
(2.10-5.14)
Cost/d, $
7/2012-1/2013
2/2013-4/2014
(n = 2034)
(n = 4276)
Mean (SD)
138 (233)
123 (213)
−15 (−19 to −11)
−11 (−14 to −8)
<.001
Median (IQR)
113 (79-160)
99 (66-147)
30-d readmission,
No. (%)
7/2012-1/2013
2/2013-4/2014
280 (14)
(n = 2034)
491 (11)
(n = 4276)
−2 (−4 to −1)
−17 (−27 to −4)
.01
Sepsis Value Improvementh
Time to administration
of anti-infective agents, h
Comparison 1
7/2014-12/2014
11/2015-2/2016
(n = 29)
(n = 76)
Mean (SD)
7.8 (11.0)
3.6 (4.7)
−4.1
(−9.9 to −1.0)i
−53
(−73 to −11)i
.02j
Median (IQR)
3.4 (0.8-7.8)
2.2 (1.0-4.5)
Comparison 2
7/2014-12/2014
11/2015-2/2016
(n = 157)
(n = 76)
Mean (SD)
8.1 (14.4)
3.6 (4.7)
−4.5
(−7.8 to −2.5)i
−54
(−69 to −31)i
<.001j
Median (IQR)
3.7 (1.2-7.8)
2.2 (1.0-4.5)
Length of stay, d
Comparison 1
7/2014-12/2014
11/2015-2/2016
(n = 29)
(n = 76)
Mean (SD)
6.0 (7.1)
4.4 (4.5)
−1.6
(−5.7 to 0.6)i
−27
(−58 to 11)i
.20j
Median (IQR)
3.9 (2.9-6.0)
3.0 (2.1-5.1)
Comparison 2
7/2014-12/2014
11/2015-2/2016
(n = 157)
(n = 76)
Mean (SD)
6.7 (5.9)
4.4 (4.5)
−2.3
(−3.5 to −0.9)i
−34
(−48 to −12)i
.002j
Median (IQR)
4.9 (3.0-7.9)
3.0 (2.1-5.1)
(continued)
Value-Driven Outcomes Program and Health Care Cost and Quality
Original Investigation Research
jama.com
(Reprinted)
JAMA
September 13, 2016
Volume 316, Number 10
1067
Copyright 2016 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/02/2019
 Copyright 2016 American Medical Association. All rights reserved.
undertook a second stage of continuous improvement and in
September 2013 defined a new perfect care index comprising
measures 3, 4, and 6 from the original index plus a new mea-
sure, successful discharge of the patient to home, supported
by home health services. The 4-month mean for the revised
perfect care index increased from 50% during May through
August2013to65%duringDecember2014throughMarch2015
(15% absolute increase; 95% CI, 6%-24%; P = .002) (Figure and
Table 5).
Compared with the baseline year (n = 634 admissions),
mean direct costs were reduced by 7% (95% CI, 3%-11%;
P < .001)duringtheimplementationyear(firstevaluationyear,
n = 637 admissions) and by 11% (95% CI, 7%-14%; P < .001) be-
tween the baseline year and the postimplementation year (sec-
ond evaluation year, n = 658 admissions).
During the first improvement cycle, early mobility (out of
bed on the day of surgery) showed the greatest improve-
ment. After modifying the schedules of in-house physical
Table 5. Results From Value Improvement Projects (continued)
Outcome Measure
Period
Descriptive Summarya
Statistical Comparison of Evaluation
vs Baseline Periods
Baseline
Evaluation
Baseline
Evaluation
Absolute Change
(95% CI)b
Relative Change,
% (95% CI)c
P Valued
Mortality, No. (%)
Comparison 1
7/2014-12/2014
11/2015-2/2016
0
(n = 29)
3 (4)
(n = 76)
NAk
NAk
.56l
Comparison 2
7/2014-12/2014
11/2015-2/2016
8 (5)
(n = 157)
3 (4)
(n = 76)
NAk
NAk
>.99l
Anti-infective agents
in 24 h, No. (%)
For nosocomial and
multidrug-resistant
infectionsm
Comparison 1
7/2014-12/2014
11/2015-2/2016
14 (48)
(n = 29)
45 (59)
(n = 76)
11 (−11 to 33)i
23 (−18 to 93)i
.31j
Comparison 2
7/2014-12/2014
11/2015-2/2016
95 (61)
(n = 157)
45 (59)
(n = 76)
−1 (−17 to 13)i
−2 (−24 to 21)i
.85j
For community-
acquired infectionsn
Comparison 1
7/2014-12/2014
11/2015-2/2016
17 (59)
(n = 29)
50 (66)
(n = 76)
7.2 (−12.7 to 31.0)i
12 (−19 to 65)i
.48j
Comparison 2
7/2014-12/2014
11/2015-2/2016
96 (61)
(n = 157)
50 (66)
(n = 76)
4.6 (−9.0 to 18.2)i
8 (−14 to 31)i
.48j
Cost per admission,
normalized to mean
at baseline, mean (SD)
Comparison 1
7/2014-12/2014
11/2015-2/2016
1.0 (1.5)
(n = 29)
0.8 (1.0)
(n = 76)
NAf
−21 (−58 to 40)i
.47j
Comparison 2
7/2014-12/2014
11/2015-2/2016
1.0 (1.4)
(n = 157)
0.5 (0.7)
(n = 76)
NAf
−49 (−64 to −23)i <.001j
Abbreviations: IQR, interquartile range; NA, not applicable.
a Medians and IQRs are provided for highly skewed continuous variables.
bAbsolute changes in means or percentages between the baseline and
evaluation periods are presented in the original units of the data and were
estimated using generalized linear models appropriate to each outcome
variable with identity link functions. Wald or likelihood ratio 95% confidence
intervals are presented unless indicated otherwise.
c Relative changes in means or percentages between the baseline and
evaluation periods are presented as a percentage change from baseline and
were estimated using generalized linear models appropriate to each outcome
variable with logarithmic link functions. Wald or likelihood ratio 95%
confidence intervals are presented unless indicated otherwise.
dP values are from the analyses of relative change unless indicated otherwise.
e Definition 1 of the perfect care index comprised 6 nationally and locally
defined quality indicators: (1) 30-day readmission; (2) Surgical Care
Improvement Project composite16; (3) 35 Hospital Acquired Condition/Patient
Safety Indicator measures17,18; (4) admission to the orthopedic acute care unit
during hospitalization; (5) early mobility (out of bed on day of surgery); and (6)
emergency department visit within 90 days of discharge. Early mobility was
identified as a key exposure for improving outcomes and decreasing length of
stay and facility costs.19,20 Definition 2 of the perfect care index was defined
as the following: (1) 35 Hospital Acquired Condition/Patient Safety Indicator
measures17,18; (2) admission to the orthopedic acute care unit during
hospitalization; (3) emergency department visit within 90 days of discharge;
and (4) discharge to home with home health services.
f Absolute data and changes are not provided for cost data owing to the
sensitive business nature of these data.
g Wald 95% confidence intervals were constructed by applying a Taylor series
approximation to the estimated log-transformed means and standard errors.
h Comparison 1 is restricted to patients within the pilot acute internal medicine
service for both the baseline and evaluation periods. Comparison 2 is
restricted to patients within the acute internal medicine service for the
evaluation period but includes the full hospital at baseline.
i Confidence intervals were obtained using the bias-correction and accelerated
bootstrap method with 1000 bootstrap replications.
j Obtained by applying permutation tests to the differences in the
log-transformed means or percentages from the analyses of relative change.
k Omitted owing to insufficient sample size.
l Obtained by Fisher exact test.
mAnti-infective agents for nosocomial and multidrug-resistant infections
included cefepime hydrochloride, ceftazidime sodium, piperacillin–
tazobactam sodium, meropenem sodium, vancomycin hydrochloride, and
metronidazole hydrochloride based on local prescribing patterns.
n Anti-infective agents for community-acquired infections included ceftriaxone
sodium, cefazolin sodium, ampicillin–sulbactam sodium, ciprofloxacin
hydrochloride, levofloxacin hydrochloride, moxifloxacin hydrochloride,
azithromycin dihydrate, oseltamivir phosphate, acyclovir sodium, and
valacyclovir hydrochloride based on local prescribing patterns.
Research Original Investigation
Value-Driven Outcomes Program and Health Care Cost and Quality
1068
JAMA
September 13, 2016
Volume 316, Number 10
(Reprinted)
jama.com
Copyright 2016 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/02/2019
 Copyright 2016 American Medical Association. All rights reserved.
therapists to ensure same-day mobility, the mean (SD) length
of stay declined from 3.50 (1.53) days during the baseline year
to 3.17 (1.21) days during the first evaluation year (reduction,
0.33 days; 95% CI, 0.20-0.47 days; P < .001) and to 2.88 (1.16)
days during the second evaluation year (reduction, 0.63 days;
95% CI, 0.50-0.76 days; P < .001).
This decrease in facility utilization and length of stay ac-
counted for 34% of the cost reduction between the baseline
year and the postimplementation year (second evaluation
year). Given widely varying costs despite comparable out-
comesacrosssimilarimplants,contractswererenegotiatedand
lower supply pricing was responsible for 41% of the overall cost
savings between the baseline and postimplementation years.
Hospitalist Laboratory Utilization
In February 2013, hospitalists launched a quality improve-
ment project to reduce unnecessary inpatient laboratory test-
ing. The project included (1) clinician education, (2) a round-
ingchecklistincludingdiscussionofalllaboratorytestingplans,
(3) monthly value-driven outcomes feedback via in-person
group review of current and year-to-date comparative indi-
vidual and peer laboratory utilization data, and (4) a financial
incentiveprogramthatshared50%ofhospitalcostsavingswith
the department to support future quality improvement
projects.22
The mean (SD) cost per day for laboratory testing on the
hospitalist service was $138 ($233) (median, $113; IQR, $79-
$160) during the baseline period and $123 ($213) (median,
$99; IQR, $66-$147) during the multifaceted intervention
(mean difference, −$15; 95% CI, −$19 to −$11; P < .001). The
number of basic metabolic panels, complete metabolic pan-
els, and complete blood count tests per day were reduced by
0.13 (95% CI, 0.10-0.16), 0.10 (95% CI, 0.07-0.13), and 0.28
(95% CI, 0.26-0.31) tests per day, respectively, from the base-
line mean (SD) of 0.75 (1.03), 0.32 (0.68), and 0.92 (0.79) tests
per day (all P < .001). The change in mean length of stay was
not statistically significant (mean [SD] length of stay, 4.48
[5.12] days [median, 3.17 days; IQR, 2.02-5.00 days] in base-
line period and 4.54 [4.67] days [median, 3.20 days; IQR,
2.10-5.14 days] in intervention period; mean difference, 0.06
days; 95% CI, −0.11 to 0.23 days; P = .48). The risk of 30-day
readmission was reduced from 14% (280 of 2034) at baseline
to 11% (491 of 4276) during the intervention (difference, −2%;
95% CI, −4% to −1%; P = .01). In contrast, for nonhospitalist
admissions that excluded obstetrics, rehabilitation, and psy-
chiatry visits, the mean (SD) cost per day for laboratory test-
ing was $130 ($432) in the baseline period and $132 ($420) in
the evaluation period.22 The annual cost savings associated
with this project were greater than $250 000 per year.
Sepsis
Sepsis was identified as one of the highest-volume MS-DRGs
withhighlyvariablecosts(CV = 1.37;Table4).Sepsisisalsoone
of the top 3 causes of inpatient mortality at the University of
Utah and nationwide.23 Early recognition and timely admin-
istration of anti-infective agents are important factors in sep-
sis management.23 A retrospective review of 157 patients with
sepsis during a 6-month interval showed that anti-infective
agents were administered a median of 3.7 hours (IQR, 1.2-7.8
hours) and a mean (SD) of 8.1 (14.4) hours after patients met
SIRS criteria. For the 29 patients in the baseline period on the
acute internal medicine service, the median time to anti-
infective agent administration was 3.4 hours (IQR, 0.8-7.8
hours) and the mean (SD) was 7.8 (11.0) hours.
Toreducetimetoanti-infectiveagentadministrationinpa-
tients with sepsis, a multifaceted educational campaign tar-
geting improved recognition and treatment of sepsis was de-
veloped and implemented for all clinical staff. A notification
system based on Modified Early Warning System triggers24,25
was also embedded in the electronic health record, along with
corresponding sepsis order sets and real-time Modified Early
Warning System scores on patient lists. Progress was tracked
using the value-driven outcomes tool.
After 4 months of implementation (November 2, 2015,
to February 29, 2016) on the acute internal medicine service,
the time from meeting SIRS criteria to administration of anti-
infective agents for 76 patients was reduced to a median time
of 2.2 hours (IQR, 1.0-4.5 hours) and a mean (SD) time of
Figure. Perfect Care Indexes During a 3-Year Interval for the Total Joint
Replacement Initiative
100
90
80
70
60
50
40
30
April
2012
January
2013
Perfect Care Index, %
Baseline year
First evaluation year
Second evaluation year
January
2015
January
2014
Perfect care baseline period
Perfect care definition 1
Perfect care definition 2
Perfect care postimplementation
Perfect care definition 1
Perfect care definition 2
Monthly results from quality improvement, using 2 different but overlapping
definitions of perfect care, are highlighted. Thick line segments indicate the
4-month baseline and measurement periods used to assess statistical
significance of the process redesign. Perfect care index is reported as the
percentage of perfect care encounters per period of measurement. For perfect
care definition 1, the perfect care index comprised 6 nationally and locally
defined quality indicators: (1) 30-day readmission; (2) Surgical Care
Improvement Project composite16; (3) 35 Hospital Acquired Condition/Patient
Safety Indicator measures17,18; (4) admission to the orthopedic acute care unit
during hospitalization; (5) early mobility (out of bed on day of surgery);
and (6) emergency department visit within 90 days of discharge. Early mobility
was identified as a key exposure for improving outcomes and decreasing length
of stay and facility costs.19,20 For perfect care definition 2, the perfect care
index was defined as the following: (1) 35 Hospital Acquired Condition/Patient
Safety Indicator measures17,18; (2) admission to the orthopedic acute care unit
during hospitalization; (3) emergency department visit within 90 days of
discharge; and (4) discharge to home with home health services. First
evaluation year corresponds to the implementation year, while second
evaluation year was the postimplementation year.
Value-Driven Outcomes Program and Health Care Cost and Quality
Original Investigation Research
jama.com
(Reprinted)
JAMA
September 13, 2016
Volume 316, Number 10
1069
Copyright 2016 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/02/2019
 Copyright 2016 American Medical Association. All rights reserved.
3.6 (4.7) hours (mean difference from baseline to implemen-
tation, −4.1 hours; 95% CI, −9.9 to −1.0 hours; P = .02). Addi-
tionaldetailsontimetoanti-infectiveagentadministrationand
secondary measures are provided in Table 5, both in compari-
son with the whole-hospital baseline audit sample and a sub-
set of this sample restricted to the acute internal medicine ser-
vice. There was no significant change in the use of anti-
infective agents for nosocomial and multidrug-resistant
infections within 24 hours of SIRS criteria being met, and there
was no significant difference in mortality.
Discussion
Implementing an analytic tool that allocates clinical care costs
and quality measures to individual patient encounters was as-
sociated with significant improvements in value of care de-
livered across 3 clinical conditions that showed high cost varia-
tionatbaseline.Fortotaljointreplacement,acompositequality
index increased during the 2-year intervention period, and
mean direct costs were 7% to 11% lower. The initiative to re-
duce hospitalist laboratory testing was associated with 11%
lower costs, with no significant change in length of stay and a
lower 30-day readmission rate. A sepsis intervention was as-
sociated with reduced mean times to anti-infective adminis-
tration following fulfillment of SIRS criteria in patients with
infection.
As identified by an Institute of Medicine report,2 variabil-
ity in the delivery of health care is one of the greatest oppor-
tunities to improve quality and reduce costs through process
improvementandstandardization.Withcomponentcostanaly-
ses, the underlying drivers of cost variability can be identi-
fied and allow targeted interventions, such as supply negotia-
tions or staff management in the case of the total joint
replacementinitiative.Thecapacitytomeasurethequalityand
cost implications of interventions in real time facilitates phy-
sician engagement and assurance that cost-reduction initia-
tives can lead to quality improvement and vice versa.
The value-driven outcomes tool can quantify quality in
terms of blended indexes that incorporate both nationally en-
dorsed and validated measures as well as local physician- and
patient-defined outcome measures. Clinician-defined qual-
ity indexes have the advantage of securing greater physician
engagement in quality improvement processes, leveraging lo-
cal drivers of quality,26 and providing a simple framework that
canbemodifiedovertimeandacrosspracticesites.Thisframe-
work also allows efficient incorporation of new standardized
measurement sets and tailored risk adjustment. For ex-
ample, 8 patient satisfaction survey instruments and 39 pa-
tient-reportedoutcomesurveyinstrumentshaverecentlybeen
incorporated into the value-driven outcomes program. These
measures play an increasing role in the assessment of value
of clinical care from patients’perspectives. Ongoing efforts in-
clude risk adjustment in patient quality and outcome mea-
sures and broadening the definition of outcome measures to
include patient experience and patient-reported outcomes.
Health systems and individual physicians are increas-
inglyheldaccountableforboththequalityandcostofcarethey
provide as is evident by the recent Medicare Access and CHIP
Reauthorization Act of 2015 (MACRA),27 but recent research
on cost reform primarily focuses on cost from the payer’
s per-
spective. Charge transparency is embraced by payers as a strat-
egy to drive cost reduction through informed consumer choice
and price competition. For example, ProMedica28 posts de-
tailed price sheets online for each of their hospitals and clin-
ics for most services. Other efforts, such as those ongoing in
Maryland, require public and private payers to pay the same
rates, leading to reduced costs for private payers and success-
ful cost containment.29 However, without quality and out-
come transparency, such as that championed by the Centers
for Medicare & Medicaid Services,18 patients are not able to
make truly informed health care choices.
While patients as consumers can create market forces to
reduce health care costs, clinicians and health care systems
have the greatest opportunity, the most knowledge, and the
responsibility to improve value.30-32 A study of 696 trauma ad-
missions to the University of Michigan concluded that 35% of
the total costs per patient were under the immediate control
of physicians.33 Alternative payment models shift the focus
from charges to the cost of care delivery. Within this context,
there is an alternative, complementary strategy to managing
costs while also attending to quality: transparency of cost and
outcome data to physicians at the level of individual encoun-
ters and conditions.
This work to measure and improve care value builds on
others’work on the use of data and performance feedback to
improve clinical practice.34 Regular feedback through the
value-driven outcomes tool is critical to monitoring status; de-
finingcleartargets,actionplans,andsupportivetools;andpro-
viding peer comparison data (eFigure 1 and eFigure 2 in the
Supplement).
Thisworkalsobuildsonothers’effortstoimprovecarevalue
at the enterprise level.2,35 Best practices in value improvement
that have been adopted include top-level leadership focus on
value improvement; a culture of continuous improvement; le-
veraginginformationtechnologytoidentifyopportunities,track
progress, and support evidence-based care; and engaging mul-
tidisciplinary teams to redesign care processes, reduce unwar-
ranted variation, and improve care value.
The tools needed to understand variation in costs and out-
comes at a unit of analysis that is actionable (individual pa-
tients with specific clinical conditions) have not been gener-
ally available to date. The value-driven outcomes costing
method relies on a combination of actual costs measured from
sources such as the supply management system, time-based
allocations (per minute or per hour in the intensive care unit,
operating room, or emergency department, for example), and
wRVU-based allocations (physician costs).7 By creating peer-
to-peer physician comparisons and by targeting areas with the
highest variability across the enterprise, we create opportu-
nities to systematically deliver more affordable, higher-
quality care.
There are alternative, more precise, and also more labor-
intensive costing methods. With time-driven activity-based
costing,6 process mapping is undertaken for specific clinical
conditions, and costing is determined by an average capacity
Research Original Investigation
Value-Driven Outcomes Program and Health Care Cost and Quality
1070
JAMA
September 13, 2016
Volume 316, Number 10
(Reprinted)
jama.com
Copyright 2016 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/02/2019
 Copyright 2016 American Medical Association. All rights reserved.
cost rate (dollars per minute) for each clinical resource and per-
sonnel, multiplied by the time spent by each resource in-
volved in the process. Unlike time-driven activity-based cost-
ing wherein costs are determined individually for each
clinical condition, the value-driven outcomes approach pro-
vides a scalable measurement solution across diagnoses and
the entire health care enterprise. Moreover, with the value-
driven outcomes tool, all allocated costs for a given period rec-
oncile to the actual hospital accounting expenses (general led-
ger) for that same period. Our costing method, like most cost
accounting systems,36 also enables assessment of system-
wide resource allocations and facilitates analysis of trends in
service demand.
However, this approach and this study have several limi-
tations. First, the data and approach lack insight into care pro-
vided outside the health care organization, particularly for
pharmacy, laboratory, and imaging services. Based on pa-
tients within the University of Utah health insurance plan, an
estimated 40% of laboratory services and 30% of imaging ser-
vices are provided outside the health care organization. Sec-
ond, Utah has unique population characteristics—the popu-
lation is younger and more physically active compared with
the national average,37 so the findings may not be completely
generalizable to health systems in other states. Third, the clini-
cal improvement studies used pre-post designs generally
without concurrent control groups or statistical adjustment for
potential confounding factors, so causality cannot be estab-
lished. Fourth, continuous quality improvement includes a
package of changes that can be adapted over time. As such, the
discrete component that contributes most to change cannot
be isolated.
Fifth,physicianswerenotblindedtotheinterventions,but
rather were aware of the outcomes being assessed as part of
the process. For example, the orthopedic surgeons and physi-
cal therapists knew that early mobility was a key component
of perfect care following total joint replacement. This compo-
nent of the quality improvement process likely influenced the
observed outcomes. Sixth, exposing outcomes and costs pub-
licly could lead to unintended consequences, such as clini-
cians shifting away from providing care to higher-cost, higher-
riskpatients.Riskadjustmentinqualityandoutcomemeasures
may mitigate these effects. The analytic framework currently
haslimitedriskadjustment;consequently,changesincostsand
outcomes may be confounded by unaccounted changes in pa-
tient risk profiles. To date, the overall case mix index at the
University of Utah has remained relatively stable, although on-
going evaluation will be needed.
Seventh, the value-driven outcomes tool includes only di-
rect costs. Indirect overhead costs such as information tech-
nology, administrative staff, hospital operations, and mainte-
nance are generally estimated to represent almost half of total
hospital costs, increasing more rapidly than medical infla-
tion during the past decade.38 Similar tools are needed to as-
sesstherelationshipofindirectcostswithqualityandcare.Fur-
thermore, direct costs per admission or per outpatient visit are
not reported owing to the sensitive business nature of these
data. Finally, there is also a need to further demonstrate the
generalizability and scalability of the value-driven outcomes
approach across many more conditions and units, both at the
University of Utah and at other health care systems.
These limitations reflect the complexity of transforming
a health care system from one based on volume to one based
on value. Health care systems and their related hospitals are
complex organizations, particularly those in academic medi-
cal centers where clinical care encounters competing agen-
das such as research and education. The variable distribution
of costs of clinical services (as shown in Table 3 and Table 4)
reflects the University of Utah experience and most likely will
varyaccordingtoinstitution.Thegoalsofthevalue-drivenout-
comes program were to estimate and increase awareness of
this variation across units, departments, and clinicians; at-
tempt to reduce that variation; and thereby reduce costs and
improve quality.
Conclusions
Implementation of a multifaceted value-driven outcomes tool
to identify high variability in costs and outcomes in a large
single health care system was associated with reduced costs
andimprovedqualityfor3selectedclinicalprojects.Theremay
be benefit for physicians to understand actual care costs (not
charges) and outcomes achieved for individual patients with
defined clinical conditions.
ARTICLE INFORMATION
Author Contributions: Dr Lee and Mr Park had full
access to all of the data in the study and take
responsibility for the integrity of the data and the
accuracy of the data analysis.
Concept and design: Lee, Kawamoto, Johnson, Pelt,
Pendleton.
Acquisition, analysis, or interpretation of data:
Kawamoto, Hess, Park, Young, Hunter, Johnson,
Gulbransen, Pelt, Horton, Graves, Greene, Anzai,
Pendleton.
Drafting of the manuscript: Lee, Kawamoto, Hess,
Hunter, Johnson, Gulbransen, Pelt, Horton, Greene,
Pendleton.
Critical revision of the manuscript for important
intellectual content: Lee, Kawamoto, Hess, Park,
Young, Johnson, Gulbransen, Pelt, Horton, Graves,
Anzai, Pendleton.
Statistical analysis: Kawamoto, Young, Greene.
Administrative, technical, or material support: Lee,
Kawamoto, Park, Young, Hunter, Johnson,
Gulbransen, Anzai, Pendleton.
Study supervision: Park, Pelt, Pendleton.
Conflict of Interest Disclosures: All authors have
completed and submitted the ICMJE Form for
Disclosure of Potential Conflicts of Interest. The
University of Utah Health Sciences Center is
currently exploring potential options for
maximizing the adoption and effects of the value-
driven outcomes analytical tool, including
potentially the provision of commercial products
and services based on the tool; Drs Lee and
Kawamoto, Messrs Park and Young, and Ms Hunter
were codevelopers of the tool. Messrs Park and
Young reported being a nonequity coinventor of
technologies for delivering health care data
applications using multitenant clouds and software
agents and having patents pending for
“Multi-tenant Cloud for Healthcare Data Application
Delivery” and “Agent for Healthcare Data
Application Delivery.” Dr Pelt reported receiving
personal fees and research support outside the
submitted work related to consulting, speaker’
s
bureaus, and unrelated research from Zimmer
Biomet. No other disclosures were reported.
Funding/Support: The statistical analyses were
supported by the University of Utah Study Design
and Biostatistics Center, with funding in part from
the National Center for Research Resources and the
National Center for Advancing Translational
Sciences, National Institutes of Health, through
grant 5UL1TR001067-02.
Value-Driven Outcomes Program and Health Care Cost and Quality
Original Investigation Research
jama.com
(Reprinted)
JAMA
September 13, 2016
Volume 316, Number 10
1071
Copyright 2016 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/02/2019
 Copyright 2016 American Medical Association. All rights reserved.
Role of the Funder/Sponsor: The funders had no
role in the design and conduct of the study;
collection, management, analysis, and
interpretation of the data; preparation, review, or
approval of the manuscript; and decision to submit
the manuscript for publication.
Additional Contributions: We thank the teams
from the University of Utah Enterprise Data
Warehouse, Decision Support, Department of
Biomedical Informatics, administrative staff,
physicians, and care teams who contributed to the
development of the value-driven outcomes tool
and its implementation. Angela Presson, PhD,
University of Utah, Salt Lake City, assisted with
statistical analyses for sepsis quality improvement;
Polina Kukhareva, MPH, MS, University of Utah,
Salt Lake City, assisted with statistical analyses
for laboratory testing improvement; and Danielle
Sample, MPH, and Joe Borgenicht, University of
Utah, Salt Lake City, provided editorial assistance;
they received no additional compensation
for this work.
REFERENCES
1. Conway PH. Value-driven health care:
implications for hospitals and hospitalists. J Hosp Med.
2009;4(8):507-511.
2. Institute of Medicine. Best care at lower cost:
the path to continuously learning health care in
America. http://www.nationalacademies.org/hmd
/Reports/2012/Best-Care-at-Lower-Cost-The
-Path-to-Continuously-Learning-Health-Care-in
-America.aspx. Published September 6, 2012.
Accessed February 19, 2016.
3. Keehan SP, Cuckler GA, Sisko AM, et al. National
health expenditure projections, 2014-24: spending
growth faster than recent trends. Health Aff
(Millwood). 2015;34(8):1407-1417.
4. Alternative Payment Model Framework and
Progress Tracking (APM FPT) Work Group.
Alternative Payment Model (APM) Framework.
https://hcp-lan.org/groups/alternative-payment
-model-apm-framework-and-progress-tracking-
work-group/. Accessed February 12, 2016.
5. Mandigo M, O’
Neill K, Mistry B, et al.
A time-driven activity-based costing model to
improve health-care resource use in Mirebalais,
Haiti. Lancet. 2015;385(suppl 2):S22.
6. Kaplan RS, Witkowski M, Abbott M, et al. Using
time-driven activity-based costing to identify value
improvement opportunities in healthcare. J Healthc
Manag. 2014;59(6):399-412.
7. Kawamoto K, Martin CJ, Williams K, et al. Value
Driven Outcomes (VDO): a pragmatic, modular, and
extensible software framework for understanding
and improving health care costs and outcomes.
J Am Med Inform Assoc. 2015;22(1):223-235.
8. Porter ME, Teisberg EO. Redefining Health Care:
Creating Value-Based Competition on Results. Boston,
MA: Harvard Business School Press; 2006.
9. University HealthSystem Consortium. Mortality
risk adjustment methodology for University Health
System’
s Clinical Data Base. http://archive.ahrq.gov
/professionals/quality-patient-safety/quality
-resources/tools/mortality/Meurer.pdf. Accessed
February 18, 2016.
10. Lee VS, Miller T, Daniels C, Paine M, Gresh B,
Betz AL. Creating the exceptional patient
experience in one academic health system. Acad Med.
2016;91(3):338-344.
11. Cella D, Yount S, Rothrock N, et al; PROMIS
Cooperative Group. The Patient-Reported
Outcomes Measurement Information System
(PROMIS): progress of an NIH Roadmap
cooperative group during its first two years. Med
Care. 2007;45(5)(suppl 1):S3-S11.
12. ABIM Foundation. Society of Hospital Medicine:
adult hospital medicine. http://www
.choosingwisely.org/societies/society-of-hospital
-medicine-adult/. Accessed January 29, 2016.
13. Bone RC, Balk RA, Cerra FB, et al. Definitions for
sepsis and organ failure and guidelines for the use
of innovative therapies in sepsis. Chest. 1992;101
(6):1644-1655.
14. McCullagh P, Nelder JA. Generalized Linear
Models. 2nd ed. London, England: Chapman &
Hall/CRC; 1989.
15. DiCiccio TJ, Efron B. Bootstrap confidence
intervals. Stat Sci. 1996;11(3):189-228. doi:10.1214
/ss/1032280214.
16. The Joint Commission. Surgical Care
Improvement Project. https://www
.jointcommission.org/surgical_care_improvement
_project/. Accessed January 10, 2016.
17. Agency for Healthcare Research and Quality.
Patient Safety Indicators Technical Specifications
Updates, Version 5.0, March 2015. http://www
.qualityindicators.ahrq.gov/modules/PSI_TechSpec
.aspx. Accessed January 10, 2016.
18. Centers for Medicare & Medicaid Services.
Hospital Compare. https://www.medicare.gov
/hospitalcompare/Data/Hospital-Acquired
-Conditions.html?AspxAutoDetectCookieSupport=1.
Accessed January 10, 2016.
19. Munin MC, Rudy TE, Glynn NW, Crossett LS,
Rubash HE. Early inpatient rehabilitation after
elective hip and knee arthroplasty. JAMA. 1998;279
(11):847-852.
20. Tayrose G, Newman D, Slover J, Jaffe F, Hunter
T, Bosco J III. Rapid mobilization decreases
length-of-stay in joint replacement patients. Bull
Hosp Jt Dis (2013). 2013;71(3):222-226.
21. Pelt CE, Anderson MB, Pendleton R, Foulks M,
Peters CL, Gililland JM. Improving value in primary
total joint arthroplasty care pathways: changes in
inpatient physical therapy staffing [published
online March 23, 2016]. Arthroplasty Today.
doi:10.1016/j.artd.2016.02.003.
22. Yarbrough PM, Kukhareva PV, Horton D,
Edholm K, Kawamoto K. Multifaceted intervention
including education, rounding checklist
implementation, cost feedback, and financial
incentives reduces inpatient laboratory costs.
J Hosp Med. 2016;11(5):348-354.
23. Dellinger RP, Levy MM, Rhodes A, et al;
Surviving Sepsis Campaign Guidelines Committee
Including the Pediatric Subgroup. Surviving sepsis
campaign: international guidelines for management
of severe sepsis and septic shock: 2012. Crit Care Med.
2013;41(2):580-637.
24. Prytherch DR, Smith GB, Schmidt PE,
Featherstone PI. ViEWS—towards a national early
warning score for detecting adult inpatient
deterioration. Resuscitation. 2010;81(8):932-937.
25. Subbe CP, Kruger M, Rutherford P, Gemmel L.
Validation of a modified Early Warning Score in
medical admissions. QJM. 2001;94(10):521-526.
26. Berwick DM, Feeley D, Loehrer S. Change from
the inside out: health care leaders taking the helm.
JAMA. 2015;313(17):1707-1708.
27. Burwell SM. Setting value-based payment
goals: HHS efforts to improve U.S. health care.
N Engl J Med. 2015;372(10):897-899.
28. ProMedica. Patient pricing request. https://www
.promedica.org/Pages/patient-pricing-request.aspx.
Accessed December 4, 2015.
29. Murray R. Setting hospital rates to control costs
and boost quality: the Maryland experience. Health
Aff (Millwood). 2009;28(5):1395-1405.
30. Eisenberg JM, Rosoff AJ. Physician
responsibility for the cost of unnecessary medical
services. N Engl J Med. 1978;299(2):76-80.
31. Eisenberg JM. Physician utilization: the state of
research about physicians’practice patterns. Med
Care. 1985;23(5):461-483.
32. Lowet PF, Eisenberg JM. Can information on
cost improve clinicians’behavior? lessons from
health care trials and management theory. Int J
Technol Assess Health Care. 1997;13(4):553-561.
33. Taheri PA, Butz D, Griffes LC, Morlock DR,
Greenfield LJ. Physician impact on the total cost of
care. Ann Surg. 2000;231(3):432-435.
34. Kiefe CI, Allison JJ, Williams OD, Person SD,
Weaver MT, Weissman NW. Improving quality
improvement using achievable benchmarks for
physician feedback: a randomized controlled trial.
JAMA. 2001;285(22):2871-2879.
35. Cosgrove DM, Fisher M, Gabow P, et al.
Ten strategies to lower costs, improve quality, and
engage patients: the view from leading health
system CEOs. Health Aff (Millwood). 2013;32(2):
321-327.
36. Shepard DS, Hodgkin D, Anthony YE. Analysis
of hospital costs: a manual for managers.
http://apps.who.int/iris/bitstream/10665/42197/1
/9241545283.pdf. Accessed February 14, 2016.
37. Utah Department of Health. Public Health
Indicator Based Information System (IBIS).
http://ibis.health.utah.gov/indicator/index
/alphabetical.html. Accessed May 20, 2016.
38. Kalman NS, Hammill BG, Schulman KA,
Shah BR. Hospital overhead costs: the neglected
driver of health care spending? J Health Care Finance.
2015;41(4):1-15.
Research Original Investigation
Value-Driven Outcomes Program and Health Care Cost and Quality
1072
JAMA
September 13, 2016
Volume 316, Number 10
(Reprinted)
jama.com
Copyright 2016 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/02/2019
