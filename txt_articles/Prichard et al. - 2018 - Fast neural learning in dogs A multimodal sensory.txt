 1
SCienTifiC REPORTS |  (2018) 8:14614  | DOI:10.1038/s41598-018-32990-2
www.nature.com/scientificreports
Fast neural learning in dogs: A 
multimodal sensory fMRI study
Ashley Prichard1, Raveena Chhibber1, Kate Athanassiades1, Mark Spivak2 & Gregory S. Berns1
Dogs may follow their nose, but they learn associations to many types of sensory stimuli. Are 
some modalities learned better than others? We used awake fMRI in 19 dogs over a series of three 
experiments to measure reward-related learning of visual, olfactory, and verbal stimuli. Neurobiological 
learning curves were generated for individual dogs by measuring activation over time within three 
regions of interest: the caudate nucleus, amygdala, and parietotemporal cortex. The learning curves 
showed that dogs formed stimulus-reward associations in as little as 22 trials. Consistent with 
neuroimaging studies of associative learning, the caudate showed a main effect for reward-related 
stimuli, but not a significant interaction with modality. However, there were significant differences in 
the time courses, suggesting that although multiple modalities are represented in the caudate, the 
rates of acquisition and habituation are modality-dependent and are potentially gated by their salience 
in the amygdala. Visual and olfactory modalities resulted in the fastest learning, while verbal stimuli 
were least effective, suggesting that verbal commands may be the least efficient way to train dogs.
It is well known that dogs have keen sensory abilities, but are some modalities learned better than others? For 
example, a dog’s behavior is popularly considered to be driven by their noses1. On the other hand, dogs have 
superior hearing to humans and readily form visual associations – even being able to discriminate human facial 
expressions2–4. The experimental literature has shown that dogs can learn associations to almost any stimulus, but 
demonstrating that certain modalities are innately preferred over others has been difficult5. Apart from the basic 
question of how different sensory modalities impact associative learning in dogs, the answer could affect how 
dogs are trained in an optimal manner.
While behavioral mechanisms underlying associative learning are well-described, there has been increasing 
sophistication in neural methods to understand how these associations are formed in the brain. In humans, 
functional magnetic resonance imaging (fMRI) has become the preferred neuroscience tool because of its nonin-
vasiveness. Coupled with computational models, this approach has been successful in parsing the contributions 
of different brain structures to reinforcement learning. Several fMRI studies have demonstrated that the striatum 
“learns” the value of visual stimuli in a manner consistent with reward-prediction error models, regardless of 
whether the reward is a primary taste reward or money6–10. Similar results have been obtained for visual cues 
that predict pleasant and unpleasant odors, although the time courses varied by the nature of the odor and brain 
region (e.g. striatum, orbitofrontal cortex, or amygdala)11. More generally, the amygdala has been hypothesized 
to interact with the reward-learning process by gating attention to salient stimuli12,13.
Like humans, dogs can be trained for non-invasive fMRI studies14. Early dog-fMRI studies demonstrated 
the replicability and reliability of caudate activation in response to hand signals predictive of food reward15. 
Later studies extended these results and showed that caudate and amygdala activation were correlated with spe-
cific aspects of a dog’s temperament and could even be used as part of a biometric predictor for suitability as a 
service-dog16. Although initial studies relied on visual signals, later work suggested that both olfactory and verbal 
cues (e.g. social praise) could also elicit activity in the caudate17,18.
Here, we used fMRI to measure the neural rates of associative learning in dogs to three modalities: visual, 
olfactory, and verbal. In three separate scanning sessions, each devoted to one modality, dogs were presented with 
two stimuli they had never encountered before. During each scan session, one of the stimuli (the conditioned 
stimulus) was always followed by a food reward, and the other (the control stimulus) nothing. If dogs formed 
modality-independent associations between the conditioned stimuli and reward, activity in the caudate nucleus 
should increase over time in response to the conditioned reward stimulus relative to the control stimulus, regard-
less of the modality. Similarly, if the amygdala functions as an attentional gate to learning, stimuli that are most 
salient to a dog (e.g. odorants) would result in greater activation in this structure. Lastly, if dogs preferentially 
1Psychology Department, Emory University, Atlanta, GA, 30322, USA. 2Comprehensive Pet Therapy, Atlanta, GA, 
30328, USA. Correspondence and requests for materials should be addressed to G.S.B. (email: gberns@emory.edu)
Received: 19 July 2018
Accepted: 19 September 2018
Published: xx xx xxxx
OPEN
 www.nature.com/scientificreports/
2
SCienTifiC REPORTS |  (2018) 8:14614  | DOI:10.1038/s41598-018-32990-2
process learning associations in one stimulus modality over another, then there will be a difference in the neural 
rate of learning between the three modalities.
Materials and Methods
Participants. 
Participants were 19 pet dogs volunteered by their Atlanta owners for fMRI training and fMRI 
studies14,15,18,19. All dogs had previously completed one or more scans for the project and had demonstrated the 
ability to participate in awake fMRI scans. The study utilized previously neutral stimuli and no physical or chem-
ical restraint was implemented. This study was performed in accordance with the recommendations in the Guide 
for the Care and Use of Laboratory Animals of the National Institutes of Health. The study was approved by the 
Emory University IACUC (Protocols DAR-2002879-091817BA and DAR-4000079-ENTPR-A), and all owners 
gave written consent for their dog’s participation in the study.
Experimental Design. 
Dogs entered and stationed themselves in custom chin rests in the scanner bore. All 
scans took place in the presence of the dog’s primary owner, who stood throughout the scan at the opening of the 
magnet bore, directly in front of the dogs, and delivered all rewards (hot dogs) to the dog. The owner was present 
to minimize any anxiety that the dog may experience due to separation, consistent with studies involving pets 
or human infants. An experimenter was stationed next to the owner, out of view of the dog. The experimenter 
controlled the timing and presentation of stimuli to the owners and the dogs via a four-button MRI-compatible 
button box. Onset of each stimulus was timestamped by the simultaneous press of the button box by the experi-
menter. Manual control of the stimuli by the experimenter was necessary, as opposed to a scripted presentation, 
because of the variable time it takes dogs to consume food rewards.
In three separate scanning sessions on different days, each devoted to one modality, dogs were presented with 
two stimuli they had never encountered before. In each session dogs were presented with either two objects, two 
odors, or two spoken words. All dogs completed the scan sessions in the same order (objects, odors, words), and 
all data collection for one modality was completed for all dogs prior to any data collection with the next modal-
ity. An event-based design was used, consisting of reward or no-reward trial types, where one stimulus within a 
modality was associated with the receipt of reward and the other stimulus with no-reward. On reward trials, the 
selected stimulus was presented for a fixed duration, which was followed by the delivery of a food reward. During 
no-reward trials, the second stimulus was presented for the same fixed duration and was followed by nothing. 
Trials were separated by an inter-trial interval specific to each modality as described below, and each dog received 
the same trial sequence.
Each scan session consisted of 4 runs, lasting approximately 9 minutes per run. Each run consisted of 22 trials 
(11 reward, 11 no-reward) with a semi-randomized presentation order, for a total of 88 trials per scan session. 
No trial type was repeated more than 4 times sequentially, as dogs could habituate to the stimulus, or may have a 
higher probability of exiting the scanner if a reward had not been issued recently. Following each run, dogs would 
exit the scanner and relax, drink water, or stay in the scanner to complete the next run.
Scanning was conducted with a Siemens 3 T Trio whole-body scanner using procedures described previ-
ously14,15. During the first of the three scans sessions, a T2-weighted structural image of the whole brain was 
acquired using a turbo spin-echo sequence (25–36 2 mm slices, TR = 3940 ms, TE = 8.9 ms, flip angle = 131°, 
26 echo trains, 128 ×
 128 matrix, FOV = 192 mm). The functional scans used a single-shot echo-planar imaging 
(EPI) sequence to acquire volumes of 22 sequential 2.5 mm slices with a 20% gap (TE = 25 ms, TR = 1200 ms, flip 
angle = 70°, 64 ×
 64 matrix, 3 mm in-plane voxel size, FOV = 192 mm). Slices were oriented dorsally to the dog’s 
brain (coronal to the magnet, as in the sphinx position the dogs’ heads were positioned 90 degrees from the prone 
human orientation) with the phase-encoding direction right-to-left. Sequential slices were used to minimize 
between-plane offsets from participant movement, while the 20% slice gap minimized the “crosstalk” that can 
occur with sequential scan sequences. Four runs of up to 400 functional volumes were acquired for each subject, 
with each run lasting about 9 minutes.
Visual Stimuli. 
A plastic pineapple and an inflatable flamingo were used (Fig. 1A). Based on owner responses, 
no dog had experience with the objects prior to the scan. One object was presented at a time, held at the dog’s eye 
level directly at the opening of the bore for 8 s, followed by delivery of a reward (hot dog) or nothing. Trials were 
separated by a 7 s inter trial interval. Dogs were semi-randomly assigned the pineapple or the flamingo as the 
reward stimulus such that roughly half of the dogs were assigned to each group (see Table 1).
Olfactory Stimuli. 
Olfactory stimuli were aqueous solutions of isoamyl acetate (IA) and hexanol (Hex) cal-
culated to result in approximately 5 ppm in the headspace of the container. Partial vapor pressures were calculated 
based on the molecular weight and reported vapor pressures of 4 mmHg and 0.9 mmHg respectively, obtained 
from PubChem (pubchem.ncbi.nlm.nih.gov). The odorants were miscible with water and the partial pressure of 
the odorant was the product of the pure odorant vapor pressure and the mole fraction of the odorant. The final 
dilutions in water were 0.15 mL/L for IA and 0.55 mL/L for Hex.
Odorants were delivered via a stream of air from an aquarium grade air pump (EcoPlus Commercial Air 
Pump 1030 GPH) through a Drierite filter (drierite.com), and afterwards through a 3-way plastic splitter to two 
plastic 100 mL jars containing 50 ml of odorant solutions and one jar containing 50 ml of water to serve as a 
control. Each solution mixed with a continuous air stream. Plastic valves were used to control directional flow 
of odorized air through 10′
 of 1/8″
 ID Teflon tube, where the mixture (air dilution of the odorant) exited a PVC 
tube with a 1″
 diameter opening positioned in the MRI bore 12″
 from the dog’s snout (Fig. 1B). The third tube 
carrying air from the control jar remained open throughout the presentations of odorized air, maintaining a 
steady air stream presented to the dog and assisting in the clearing of lingering odor within the magnet bore. 
Dogs were presented an odor for an initial 3.6 s during a span of 7.2 s, followed by a reward (hot dog) or nothing, 
 www.nature.com/scientificreports/
3
SCienTifiC REPORTS |  (2018) 8:14614  | DOI:10.1038/s41598-018-32990-2
with a 9.6 s inter trial interval between odor presentations. The inter trial interval was increased compared to the 
visual stimulus scans to ensure that the odorant within the magnet bore had cleared prior to the next trial. Dogs 
were semi-randomly assigned IA or Hex as the reward stimulus such that roughly half of the dogs were assigned 
to each group (see Table 1).
Verbal Stimuli. 
Verbal stimuli were the words “Callooh” and “Frabjous” from the Lewis Carroll poem, 
“Jabberwocky.” The words were chosen as novel pseudowords to the dog. The words were spoken by the dog’s 
primary owner, who was positioned in front of the dog at the opening of the magnet bore. Both owners and dogs 
wore ear plugs, reducing scanner noise by 30 decibels, but allowing for intelligible speech over the scanner noise. 
The words were intelligible to the experimenters, who also wore ear plugs while next to the MRI during scanning, 
as well as the human operators in the control room through the intercom. At the start of each trial, a word was 
Figure 1. Experimental design with conditioned stimuli. Two novel stimuli were repeatedly presented during 
three scanning sessions, each devoted to one stimulus modality. One stimulus was associated with food 
(Reward), one associated with nothing (No Reward). (A) Presentation of pineapple object by owner to dog in 
MRI bore during visual modality session. (B) Presentation of odorants to dog in MRI bore via experimenter-
controlled olfactometer during olfactory modality session. The owner remained in front of the dog. (C) 
Presentation of pseudoword Frabjous to owner projected above MRI bore opening during verbal modality 
session. The owner spoke the projected word five times per trial.
Dog
Breed
Sex
Reward Object
Reward Odor
Reward Word
BhuBo
Boxer mix
M
Pineapple
hexanol
Callooh
Caylin
Border collie
F
Pineapple
hexanol
Frabjous
Daisy
Pitbull mix
F
Flamingo
hexanol
Callooh
Eddie
Labrador Golden mix
M
Pineapple
isoamyl acetate
Callooh
Kady
Labrador
F
Flamingo
hexanol
Frabjous
Koda
Pitbull mix
F
Flamingo
isoamyl acetate
Callooh
Libby
Pitbull mix
F
Pineapple
hexanol
Callooh
Mauja
Cattle dog mix
F
Pineapple
hexanol
N/A
Ninja
Cattle dog mix
F
Flamingo
isoamyl acetate
Frabjous
Ohana
Golden Retriever
F
Pineapple
hexanol
Frabjous
Ollie
Border collie Beagle mix
M
Flamingo
isoamyl acetate
Frabjous
Ozzie
Bichon-Yorkie mix
M
Flamingo
isoamyl acetate
Frabjous
Pearl
Golden Retriever
F
Pineapple
hexanol
Frabjous
Tallulah
Cattle Dog mix
F
Flamingo
hexanol
Callooh
Truffles
Pointer mix
F
Pineapple
isoamyl acetate
Frabjous
Tug
Portuguese Water dog
M
Flamingo
hexanol
Callooh
Velcro
Viszla
M
Pineapple
isoamyl acetate
Frabjous
Wil
Australian Shepherd
M
Pineapple
isoamyl acetate
Callooh
Zen
Labrador Golden mix
M
Flamingo
isoamyl acetate
Callooh
Table 1. Dogs (N = 19) and stimuli paired with reward. Dog’s names, breed, sex, and stimuli (S+) are listed.
 www.nature.com/scientificreports/
4
SCienTifiC REPORTS |  (2018) 8:14614  | DOI:10.1038/s41598-018-32990-2
presented to the owners via a mirror relay system that projected the words onto the surface of the scanner, directly 
over the owner’s head (Fig. 1C). Owners were positioned in front of the dog and repeated the words five times for 
an average duration of 6 s. Words were repeated to ensure the dogs heard them. Words associated with reward 
were followed by a 4 s delay, then the delivery of a food reward, and words not associated with a reward were fol-
lowed by nothing. The words were followed by a delay after their presentation for three reasons. First, a previous 
imaging study by our lab where dogs were presented with spoken words by their owners in the MRI showed that 
dogs may move initially upon hearing words, likely due to their familiarity with verbal commands, resulting in 
loss of data for those instances. This was also the reasoning behind the repetition of the verbal stimuli. Second, the 
verbal stimuli could be delivered at a much faster rate than the presentation of the objects. The rate of the delivery 
of the odor stimuli through the olfactometer was also dependent on the manual operation of the olfactometer by 
the experimenter and the length of the tube carrying scented air from the olfactometer jar to the dog’s nose. Third, 
if there was no delay, the timing of the BOLD response following the verbal stimuli would peak at the moment 
that the reward or nothing was delivered following the last repetition, resulting in additional loss of data due to 
movement. Trials were separated by an 8.4 s inter trial interval. Dogs were semi-randomly assigned “Frabjous” or 
“Callooh” as the reward stimulus such that roughly half of the dogs were assigned to each group (see Table 1). Dog 
Mauja was deaf, and so did not participate in the verbal stimuli experiment. Dog Libby had excessive motion in 
this experiment and was not included in the analysis for this stimulus modality.
Statistical Analyses. 
Preprocessing. Preprocessing of the fMRI data included motion correction, cen-
soring, and normalization using AFNI (NIH) and its associated functions. Two-pass, six-parameter rigid-body 
motion correction was used based on a hand-selected reference volume for each dog that corresponded to their 
average position within the magnet bore across runs. Aggressive censoring removed unusable volumes from 
the fMRI time sequence because dogs can move between trials, when interacting with the object, smelling an 
odor, hearing a word, and when consuming rewards. Data were censored when estimated motion was greater 
than 1 mm displacement scan-to-scan and based on outlier voxel signal intensities. Smoothing, normaliza-
tion, and motion correction parameters were identical to those described in previous studies18. The Advanced 
Normalization Tools (ANTs) software was used to spatially normalize the mean of the motion-corrected func-
tional images20 to the individual dog’s structural image.
General Linear Model. Each subject’s motion-corrected, censored, smoothed images were analyzed within a 
general linear model (GLM) for each voxel in the brain using 3dDeconvolve (part of the AFNI suite). Motion 
time courses were generated through motion correction, and constant, linear, quadratic, cubic, and quartic drift 
terms were included as nuisance regressors. Drift terms were included for each run to account for baseline shifts 
between runs as well as slow drifts unrelated to the experiment. Task related regressors for each experiment were 
modeled using AFNI’s dmUBLOCK and stim_times_IM functions and were as follows: (1) reward stimulus; (2) 
no-reward stimulus. The function creates a column in the design matrix for each of the 88 trials, allowing for the 
estimation of beta values for each trial. The reason for this approach was that even though the motion censoring 
flagged problematic volumes, it is possible that spin-history effects could result in spurious levels of activation 
in specific regions of interest that, when averaged over an entire run, could still affect beta estimates. Trials with 
beta values greater than an absolute three percent signal change were removed prior to analyses (assuming that 
these were beyond the physiologic range of the BOLD signal). As described next, we used the trial-by-trial betas 
to estimate trimmed-means from the remaining beta values.
Region of Interest (ROI) Analysis. As our interest was based on the dog’s changing response to novel visual, 
olfactory, or verbal stimuli, all quantitative analyses based on the imaging results used activation values in the 
canine brain area previously observed to be responsive to visual18, olfactory17,21, and verbal22 stimuli. Anatomical 
ROIs of the left and right caudate nuclei, and the left and right amygdala were defined structurally using each 
dog’s T2-weighted structural image of the whole brain. A parietotemporal region was also included because of 
its known involvement with verbal and visual stimuli in dog fMRI studies but no reported involvement with 
stimulus valuation22. The parietotemporal region of interest was defined using a high-resolution canine brain 
atlas23 and applyANTSTransformation (part of the ANTS suite) to transform the left and right parietotemporal 
ROIs from template to individual space (Fig. 2). Thereafter, all analyses were performed in individual, rather than 
group space.
Beta values for each presentation of reward stimuli (44 trials) and no-reward stimuli (44 trials) were extracted 
from and averaged over the ROIs in the left and right hemispheres. Beta values were used to construct a learning 
curve across presentations of the stimuli by ROI, run, and modality, as well as to test for any hemispheric differ-
ences. We used the mixed-model procedure in SPSS 24 (IBM) with fixed-effects for the intercept, run number, 
type (reward or no-reward), modality (visual, olfactory, & verbal), ROI (amygdala, caudate, & parietotemporal), 
and hemisphere (left or right), identity covariance structure, and maximum-likelihood estimation. Run was mod-
eled as a fixed effect because it made no assumptions about the time course. As hemisphere did not account for a 
significant amount of variance, all analyses removed hemisphere as a factor.
Results
We found neural evidence for differentiation of the reward and no-reward stimuli in all modalities (p < 0.001) 
(Table 2). Although the amplitude of this difference varied by ROI (p = 0.014), there was only a marginally signif-
icant interaction with modality (p = 0.045). However, the modality significantly affected the temporal pattern of 
the difference between reward and no-reward stimuli across Run (p = 0.006).
As there was differentiation of the reward and no-reward stimuli in all modalities, we used post-hoc analyses 
to examine whether these differences remained when segregated by ROI and a Bonferroni correction for multiple 
 www.nature.com/scientificreports/
5
SCienTifiC REPORTS |  (2018) 8:14614  | DOI:10.1038/s41598-018-32990-2
comparisons. In the caudate (Fig. 3A), there was a significant main effect of [Reward – No Reward] (p = 0.013) 
but not the interaction with modality (p = 0.081), consistent with general reward processing. There was no inter-
action with [Reward – No Reward] and Run, but the interaction of [Reward – No Reward] x Run x Modality was 
significant (p = 0.018), indicating that the time course of the differentiation of value varied by modality. For the 
caudate, both the visual and olfactory stimuli showed a rising differentiation by Runs 2 & 3, with some decrement 
by run 4 for olfaction.
Figure 2. Regions of interest (ROIs) defined a priori. ROIs were drawn in individual anatomical space, example 
ROIs shown in template space here in transverse and dorsal views. (A) Caudate nuclei have been shown to 
differentially respond to stimuli associated with reward and no-reward. (B) Amygdalae have shown differential 
responding to stimuli associated with reward and no-reward, as well as arousal. (C) Parietotemporal regions 
including primary auditory cortex respond to verbal stimuli, including nonwords. ROI is shown here in sagittal 
and dorsal views in template space.
Fixed Effects
Numerator df
Denominator df
F
Sig.
Intercept
1
17.757
11.105
0.004
Run
3
23706.431
4.801
0.002
Rew_NoRew
1
23696.466
35.034
0.000
Modality
2
23192.742
10.798
0.000
ROI
2
23704.765
33.667
0.000
Run * Rew_NoRew
3
23692.763
3.359
0.018
Run * Modality
6
23703.114
2.794
0.010
Run * ROI
6
23690.984
2.072
0.053
Rew_NoRew * Modality
2
23695.363
3.102
0.045
Rew_NoRew * ROI
2
23690.649
4.284
0.014
Modality * ROI
4
23701.672
5.389
0.000
Run * Rew_NoRew * Modality
6
23693.671
3.039
0.006
Run * Rew_NoRew * ROI
6
23690.457
0.423
0.864
Run * Modality * ROI
12
23691.077
0.827
0.623
Rew_NoRew * Modality * ROI
4
23690.700
0.537
0.709
Run * Rew_NoRew * Modality * ROI
12
23690.415
0.461
0.938
Table 2. Model results for Reward vs. No Reward, Run, Modality, and ROI.
 www.nature.com/scientificreports/
6
SCienTifiC REPORTS |  (2018) 8:14614  | DOI:10.1038/s41598-018-32990-2
A similar, more pronounced, pattern was observed in the amygdala (Fig. 3B). Like the caudate, the amyg-
dala displayed a significant main effect of [Reward – No Reward] (p < 0.001) but no interaction with modal-
ity (p = 0.238). There was not a significant interaction of Run x [Reward – No Reward] (p = 0.584), indicating 
that the amygdala “learned” the differential values of the stimuli in Run 1 and maintained them throughout 
each experiment. Unlike the caudate, there was not a significant interaction of [Reward – No Reward] x Run x 
Modality (p = 0.707), indicating that the modality did not affect the rate of learning or habituation.
Finally, the parietotemporal cortex (Fig. 3C) also showed a main effect for [Reward – No Reward] (p = 0.021), 
but this was of marginal significance and would not survive Bonferroni correction for three separate analyses.
In sum, the neural learning curves showed that dogs formed stimulus-reward associations in as little as 22 
trials. However, there were significant differences in the time courses, suggesting that the rates of acquisition 
and habituation were modality-dependent, with visual and olfactory modalities resulting in the fastest learning 
(Fig. 3D), while verbal stimuli were least effective.
Discussion
In three experiments, we demonstrated the use of fMRI in dogs to compare associative reward-learning in the 
brain across visual, olfactory, and verbal modalities. Consistent with reward learning in neuroimaging studies, the 
caudate showed main effects for reward-related stimuli but not a significant interaction with modality. However, 
there were significant differences in the time courses, suggesting that although multiple modalities are repre-
sented in these structures, the rates of acquisition and habituation are modality-dependent. Further, we demon-
strate that dogs have neural mechanisms that support a bias for learning conditioned visual and olfactory stimuli 
more rapidly than verbal stimuli.
While many fMRI studies have shown that the striatum differentially responds to conditioned stimuli associ-
ated with reward, this is the first fMRI study that directly compares reward learning across three modalities in the 
same participants. The significant differential effect for reward versus no-reward across multiple ROIs suggests 
that reward regions of the canine brain such as the striatum process the value of conditioned stimuli regardless 
of modality. Post-hoc analyses revealed that the primary structures associated with the differentiation of value 
between conditioned stimuli were the caudate and amygdala, not the parietotemporal region. Moreover, the dif-
ferentiation of value was more pronounced for visual and olfactory stimuli. Interestingly, the parietotemporal 
cortex, which was originally selected because of its known involvement with visual and auditory stimuli, turned 
Figure 3. Percent signal change by ROI for the contrast of stimuli predicting Reward vs. No Reward. 
Unadjusted mean values across dogs by run and by modality (blue = visual, red = olfactory, green = verbal). 
Error bars denote the standard error of the mean across dogs for each modality and run. Lines denote second-
order polynomial trend lines across all runs for each modality and ROI. Consistent with studies of reward 
learning, there were main effects of [Reward-No Reward] across all ROIs (p < 0.001), which was only marginally 
significantly different by modality (p = 0.045). There was a significant interaction between [Reward—No 
Reward] and ROI (p = 0.014), suggesting the magnitude of the effect was different in each region. All ROIs 
showed evidence of varying time course (p = 0.018), which differed by modality (p = 0.006), consistent with 
different rates of learning and habituation by modality. (A) Averaged beta values in the caudate show marked 
learning curves for visual and olfactory stimuli. (B) Averaged beta values in the amygdala show learning curves 
across all stimulus modalities, but verbal stimuli peak later than visual and verbal stimuli. (C) Averaged beta 
values in the parietotemporal area show weak learning effects for all modalities. (D) Comparison of initial 
learning rates for each modality for Run 1. Bars denote the temporal derivative (d/dt) of the polynomial fit 
for [Reward—No Reward] by modality and ROI. Across all three ROIs, percent signal change to visual and 
olfactory stimuli occur at a faster rate than verbal stimuli, and is evident in the first few exposures.
 www.nature.com/scientificreports/
7
SCienTifiC REPORTS |  (2018) 8:14614  | DOI:10.1038/s41598-018-32990-2
out to have the strongest effect for visual and olfactory stimuli. This multimodal activation can be attributed to 
inclusion of both primary auditory and parietal cortices within the defined region.
Although it is debatable whether the amygdala should be considered part of the “reward” circuit, its role in 
associative learning is well-established. One recent model suggests that the amygdala computes the surprising-
ness of stimuli while the striatum computes reward prediction errors12. A hallmark of this model is that surprise 
declines with repeated exposure while prediction errors remain constant as long as the stimuli themselves are 
unpredictable. This is exactly the pattern we observed in the caudate and the amygdala (Fig. 3), which appeared 
largely independent of modality. Within this framework, the amygdala activation can be interpreted as an atten-
tional “gate” that signals the salience of a stimulus, setting up the reward system to compute its value. Further 
insight is gained by examining the time courses of activation in these regions.
Our results show that dogs acquired the reward associations with odors and visual stimuli at a different time 
course than verbal stimuli. The neural activation for visual and olfactory stimuli within the caudate and amygdala 
peaked by the second run, indicating the conditioned associations were formed within 22 trials. This is inconsist-
ent with dog behavioral studies, which require days to form the stimulus-reward associations of visual or odor 
stimuli to reach a behavioral criterion24–26. However, our findings are consistent with human fMRI studies, where 
word learning was reported to occur at a slower rate during associative learning than visual learning27.
The effects of stimulus modality on differential neural time courses highlight the potential implications for 
training dogs. Most training protocols for dogs use gestural and verbal commands. While optimal for humans, 
these protocols may not be the most effective for learning from a dog’s perspective. Our results are consistent with 
previous behavioral findings that suggest dogs prioritize gestures over verbal commands when presented with 
conflicting signals5,28. Effective processing of visual information is essential to the social success and safety of the 
dog. Dogs frequently use body language as a principal mode of dog-dog communication. Tail wagging, facial 
expressions, and body postures are obvious examples29–34. In addition to visual cues, dogs use odors as a means for 
gaining social information from both humans and dogs35,36. When olfactory information is present and relevant, 
the dog may consider olfactory sensory information prepotent over visual information37. Although dogs may 
attend to verbal stimuli, olfactory and visual stimuli likely have greater importance in the dog’s assessment of its 
physical and social environment and when interacting within such environments. Our results, showing greater 
salience for olfactory and visual stimuli in the amygdala, are concordant with the dogs’ behavioral preferences in 
their natural surroundings.
There are several limitations to our study. First, although we isolated the salient modality in three separate 
experiments, the presence of the human owner was constant. Because the human was not blind to the nature of 
the stimuli, they could have inadvertently influenced the associative process through body language. However, 
because the olfactory modality was the most effective in eliciting reward-associations across all ROIs, and the 
olfactory stimuli were least likely to be picked up by the humans and were not saliently communicated by human 
owners, as were the display of the visual objects or the vocalization of the auditory stimulus, so-called ‘Clever 
Hans’ effects are unlikely to explain these results. Second, although the verbal stimuli were the least effective in 
forming reward-associations, this may have more to do with the discriminability of words in the scanner envi-
ronment. Although the words were distinguishable to the experimenters over the scanner noise, it may have been 
more difficult for the dogs. There is some evidence that dogs can discriminate between spoken words during an 
fMRI scan, as a previous study where owners spoke trained words and pseudowords to their dogs during scan-
ning showed neurobiological evidence that dogs were differentiating between the words in primary auditory 
cortices and the parietotemporal cortex38. This and previous results suggest some mechanistic similarity between 
humans and dogs for the rate of associative learning of verbal stimuli relative to other modalities. Third, we found 
only a marginally significant interaction between reward and modality (p = 0.045). Given the large sample size 
and high number of observations, we conclude that this is probably not a significant effect, especially since the 
other effects had markedly smaller p-values. Even so, a non-significant result does not mean that the effect doesn’t 
exist. It is possible that the modality of the conditioned stimuli affected the magnitude of the representation in 
reward-related structures like the caudate and amygdala. Undoubtedly the differential value of stimuli would be 
influenced by their discriminability, and as already noted, verbal cues were at a disadvantage. Fourth, the effects of 
habituation counteract those of learning. Habituation was perhaps most evident in the amygdala, which displayed 
a generally declining response with run, regardless of the modality. There is ample evidence that the amygdala 
habituates to repeated presentations of the same stimuli39–41. It would not be surprising that repeated presentation 
of the stimuli could lead to decreased physiological response, especially to odors. Most dogs included in the study 
also had experience from previous fMRI studies with conditioned object-reward associations, and some with con-
ditioned word-object associations, such that odors within the scanner environment may have been more novel 
than other stimulus modalities. Finally, the stimulus-reward associations were acquired through a passive task in 
the scanner. No behavioral tests were conducted to test acquisition of the learned associations or to compare to 
the neural activations.
In summary, our results show that associative learning may be measured across multiple modalities in the 
caudate and that stimulus salience is denoted by the amygdala. However, certain modalities – notably visual 
and olfactory – were more effective in eliciting reward-related responses, especially in the rate at which they 
were acquired. Our results suggest that the human inclination for verbal communication appears to be based on 
human preferences, rather than the dog’s innate aptitude. Consequently, pet and working dog training programs 
would likely become more productive, with accelerated learning rates for the dog, if commands were introduced 
via hand signals or other physical modes of communication.
 www.nature.com/scientificreports/
8
SCienTifiC REPORTS |  (2018) 8:14614  | DOI:10.1038/s41598-018-32990-2
References
 1. Horowitz, A., Hecht, J. & Dedriek, A. Smelling more or less: Investigating the olfactory experience of the domestic dog. Learning and 
Motivation 44, 207–217, https://doi.org/10.1016/j.lmot.2013.02.002 (2013).
 2. Huber, L., Racca, A., Scaf, B., Virányi, Z. & Range, F. Discrimination of familiar human faces in dogs (Canis familiaris). Learning and 
Motivation 44, 258–269, https://doi.org/10.1016/j.lmot.2013.04.005 (2013).
 3. Müller, C. A., Schmitt, K., Barber, A. L. A. & Huber, L. Dogs can discriminate emotional expressions of human faces. Current Biology 
25, 601–605, https://doi.org/10.1016/j.cub.2014.12.055 (2015).
 4. Barber, A. L. A., Randi, D., Muller, C. A. & Huber, L. The processing of human emotional faces by pet and lab dogs: Evidence for 
lateralization and experience effects. PLoS ONE 11, 1–22, https://doi.org/10.1371/journal.pone.0152393 (2016).
 5. D’Aniello, B., Scandurra, A., Alterisio, A., Valsecchi, P. & Prato-Previde, E. The importance of gestural communication: a study of 
human-dog communication using incongruent information. Anim Cogn 19, 1231–1235, https://doi.org/10.1007/s10071-016-1010-
5 (2016).
 6. Schultz, W. & Dayan, P. & Montague, P. R. A neural substrate of prediction and reward. Science 275, 1593–1599, https://doi.
org/10.1126/science.275.5306.1593 (1997).
 7. McClure, S. M. & Berns, G. S. & Montague, P. R. Temporal prediction errors in a passive learning task activate human striatum. 
Neuron 38, 339–346, https://doi.org/10.1016/S0896-6273(03)00154-5 (2003).
 8. O’Doherty, J. P., Dayan, P., Friston, K., Critchley, H. & Dolan, R. J. Temporal difference models and reward-related learning in the 
human brain. Neuron 38, 329–337, https://doi.org/10.1016/S0896-6273(03)00169-7 (2003).
 9. O’Doherty, J. P., Buchanan, T. W., Seymour, B. & Dolan, R. J. Predictive neural coding of reward preference involves dissociable 
responses in human ventral midbrain and ventral striatum. Neuron 49, 157–166, https://doi.org/10.1016/j.neuron.2005.11.014 (2006).
 
10. Haber, S. N. & Knutson, B. The reward circuit: linking primate anatomy and human imaging. Neuropsychopharmacology 35, 4–26, 
https://doi.org/10.1038/npp.2009.129 (2010).
 
11. Gottfried, J. A., O’Doherty, J. & Dolan, R. J. Appetitive and aversive olfactory learning in humans studied using event-related 
functional magnetic resonance imaging. Journal of Neuroscience 22, 10829–10837, 22/24/10829 [pii] (2002).
 
12. Li, J., Schiller, D., Schoenbaum, G., Phelps, E. A. & Daw, N. D. Differential roles of human striatum and amygdala in associative 
learning. Nature Neuroscience 14, 1250–1252, https://doi.org/10.1038/nn.2904.Differential (2012).
 
13. Anderson, B. A. The attention habit: how reward learning shapes attentional selection. Ann N Y Acad Sci 1369, 24–39, https://doi.
org/10.1111/nyas.12957 (2016).
 
14. Berns, G. S., Brooks, A. M. & Spivak, M. Functional MRI in awake unrestrained dogs. PLoS One 7, e38027, https://doi.org/10.1371/
journal.pone.0038027 (2012).
 
15. Berns, G. S., Brooks, A. & Spivak, M. Replicability and heterogeneity of awake unrestrained canine FMRI responses. PLoS One 8, 
e81698, https://doi.org/10.1371/journal.pone.0081698 (2013).
 
16. Berns, G. S., Brooks, A. M., Spivak, M. & Levy, K. Functional MRI in awake dogs predicts suitability for assistance work. Sci Rep 7, 
43704, https://doi.org/10.1038/srep43704 (2017).
 
17. Berns, G. S., Brooks, A. M. & Spivak, M. Scent of the familiar: An fMRI study of canine brain responses to familiar and unfamiliar 
human and dog odors. Behav Processes 110, 37–46, https://doi.org/10.1016/j.beproc.2014.02.011 (2015).
 
18. Cook, P. F., Prichard, A., Spivak, M. & Berns, G. S. Awake canine fMRI predicts dogs’ preference for praise vs food. Soc Cogn Affect 
Neurosci 11, 1853–1862, https://doi.org/10.1093/scan/nsw102 (2016).
 
19. Berns, G. S. & Cook, P. F. Why did the dog walk into the MRI? Current Directions in Psychological Science 25, 363–369, https://doi.
org/10.1177/0963721416665006 (2016).
 
20. Avants, B. B. et al. A reproducible evaluation of ANTs similarity metric performance in brain image registration. Neuroimage 54, 
2033–2044, https://doi.org/10.1016/j.neuroimage.2010.09.025 (2011).
 
21. Jia, H. et al. Functional MRI of the olfactory system in conscious dogs. PLoS One 9, e86362, https://doi.org/10.1371/journal.
pone.0086362 (2014).
 
22. Andics, A., Gacsi, M., Farago, T., Kis, A. & Miklosi, A. Voice-sensitive regions in the dog and human brain are revealed by 
comparative fMRI. Curr Biol 24, 574–578, https://doi.org/10.1016/j.cub.2014.01.058 (2014).
 
23. Datta, R. et al. A digital atlas of the dog brain. PLoS One 7, e52140, https://doi.org/10.1371/journal.pone.0052140 (2012).
 
24. Hall, N. J., Smith, D. W. & Wynne, C. D. L. Training domestic dogs (Canis lupus familiaris) on a novel discrete trials odor-detection 
task. Learning and Motivation 44, 218–228, https://doi.org/10.1016/j.lmot.2013.02.004 (2013).
 
25. Lazarowski, L. et al. Acquisition of a visual discrimination and reversal learning task by Labrador retrievers. Anim Cogn 17, 787–792, 
https://doi.org/10.1007/s10071-013-0712-1 (2014).
 
26. Protopopova, A. & Wynne, C. D. Improving in-kennel presentation of shelter dogs through response-dependent and response-
independent treat delivery. J Appl Behav Anal 48, 590–601, https://doi.org/10.1002/jaba.217 (2015).
 
27. McMurray, B., Horst, J. S. & Samuelson, L. K. Word learning emerges from the interaction of online referent selection and slow 
associative learning. Psychol Rev 119, 831–877, https://doi.org/10.1037/a0029872 (2012).
 
28. Kaminski, J., Tempelmann, S., Call, J. & Tomasello, M. Domestic dogs comprehend human communication with iconic signs. Dev 
Sci 12, 831–837, https://doi.org/10.1111/j.1467-7687.2009.00815.x (2009).
 
29. Siniscalchi, M., Lusito, R., Vallortigara, G. & Quaranta, A. Seeing left- or right-asymmetric tail wagging produces different emotional 
responses in dogs. Curr Biol 23, 2279–2282, https://doi.org/10.1016/j.cub.2013.09.027 (2013).
 
30. Firnkes, A., Bartels, A., Bidoli, E. & Erhard, M. Appeasement signals used by dogs during dog–human communication. Journal of 
Veterinary Behavior: Clinical Applications and Research 19, 35–44, https://doi.org/10.1016/j.jveb.2016.12.012 (2017).
 
31. Mariti, C., Falaschi, C., Zilocchi, M., Carlone, B. & Gazzano, A. Analysis of calming signals in domestic dogs: Are they signals and 
are they calming? Journal of Veterinary Behavior: Clinical Applications and Research 9, e1–e2, https://doi.org/10.1016/j.
jveb.2014.09.008 (2014).
 
32. Rugaas, T. On talking terms with dogs: calming signals. 2nd edn, (Dogwise Publishing, 2006).
 
33. Somppi, S. et al. Dogs evaluate threatening facial expressions by their biological validity-Evidence from gazing patterns. PLoS One 
11, e0143047, https://doi.org/10.1371/journal.pone.0143047 (2016).
 
34. van der Borg, J. A., Schilder, M. B., Vinke, C. M. & de Vries, H. Dominance in domestic dogs: A quantitative analysis of its 
behavioural measures. PLoS One 10, e0133978, https://doi.org/10.1371/journal.pone.0133978 (2015).
 
35. Sherman, P., Reeve, H. & Pfennig, D. Recognition systems. (Oxford: Blackwell Science, 1997).
 
36. Sommerville, B. A. & Broom, D. M. Olfactory communication between man and other animals. (Springer US, 2001).
 
37. Gazit, I. & Terkel, J. Domination of olfaction over vision in explosives detection by dogs. Applied Animal Behaviour Science 82, 
65–73, https://doi.org/10.1016/S0168-1591(03)00051-0 (2003).
 
38. Prichard, A., Cook, P. F., Spivak, M., Chhibber, R. & Berns, G. Awake fMRI reveals brain regions for novel word detection in dogs. 
bioRxiv 178186, https://doi.org/10.1101/178186 (2018).
 
39. Wright, C. I. et al. Differential prefrontal cortex and amygdala habituation to repeatedly presented emotional stimuli. Neuroreport 
12, 379–383, https://doi.org/10.1097/00001756-200102120-00039 (2001).
 
40. Plichta, M. M. et al. Amygdala habituation: A reliable fMRI phenotype. Neuroimage 103, 383–390, https://doi.org/10.1016/j.
neuroimage.2014.09.059 (2014).
 
41. Poellinger, A. et al. Activation and habituation in olfaction-an fMRI study. Neuroimage 13, 547–560, https://doi.org/10.1006/
nimg.2000.0713 (2001).
 www.nature.com/scientificreports/
9
SCienTifiC REPORTS |  (2018) 8:14614  | DOI:10.1038/s41598-018-32990-2
Acknowledgements
Thanks to Dr. Kate Revill for advice about language processing. Thank you to all of the owners who trained their 
dogs over the course of one year for three studies: Lorrie Backer, Rebecca Beasley, Emily Chapman, Darlene 
Coyne, Vicki D’Amico, Diana Delatour, Jessa Fagan, Marianne Ferraro, Anna & Cory Inman, Patricia King, 
Cecilia Kurland, Claire & Josh Mancebo, Patti Rudi, Cathy Siler, Lisa Tallant, Nicole & Sairina Merino Tsui, 
Ashwin Sakhardande, & Yusuf Uddin. This work was supported by the Office of Naval Research (N00014-16-1-
2276). M.S. is the owner of Comprehensive Pet Therapy (CPT). ONR provided support in the form of salaries for 
authors [MS & GSB], scan time, and volunteer payment, but did not have any additional role in the study design, 
data collection and analysis, decision to publish, or preparation of the manuscript.
Author Contributions
A.P., M.S. and G.B. designed the research; A.P., R.C., K.A. and G.B. collected the data; A.P., R.C., K.A. and G.B. 
analyzed data; A.P., M.S. and G.B. trained dogs; and A.P., M.S. and G.B. wrote the paper.
Additional Information
Competing Interests: G.B. and M.S. own equity in Dog Star Technologies and developed technology used in 
some of the research described in this paper. The terms of this arrangement have been reviewed and approved 
by Emory University in accordance with its conflict of interest policies. M.S. is the owner of Comprehensive Pet 
Therapy (CPT) but no CPT technology or IP was used in this research.
Publisher's note: Springer Nature remains neutral with regard to jurisdictional claims in published maps and 
institutional affiliations.
Open Access This article is licensed under a Creative Commons Attribution 4.0 International 
License, which permits use, sharing, adaptation, distribution and reproduction in any medium or 
format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Cre-
ative Commons license, and indicate if changes were made. The images or other third party material in this 
article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the 
material. If material is not included in the article’s Creative Commons license and your intended use is not per-
mitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the 
copyright holder. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/.
 
© The Author(s) 2018
