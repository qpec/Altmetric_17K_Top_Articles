 DRAFT: 31 March 2017 
 
Effects of the Informed Health Choices podcast on the ability of parents 
of primary school children in Uganda to assess claims about treatment 
effects: a randomised trial 
 
 
Authors:   
Daniel Semakula, Allen Nsangi, Andrew D. Oxman, Matt Oxman, Astrid Austvoll-Dahlgren, 
Sarah Rosenbaum, Angela Morelli, Claire Glenton, Simon Lewin, Margaret Kaseje, Iain 
Chalmers, Atle Fretheim, Doris Tove Kristoffersen, Nelson K. Sewankambo 
 
College of Health Sciences, Makerere University, Kampala, Uganda (D Semakula MD, A 
Nsangi MSc, Prof N K Sewankambo MD) 
Informed Health Choices Research Centre, Norwegian Institute of Public Health, Oslo, 
Norway (A D Oxman MD, M Oxman BJ, A Austvoll-Dahlgren PhD, S Rosenbaum PhD, A 
Morelli MA, C Glenton Dr.philos, S Lewin PhD, Prof A Fretheim PhD, Doris Tove Kristoffersen 
MSc)  
University of Oslo, Oslo, Norway (D Semakula, A Nsangi, A Fretheim)  
Infodesignlab, Oslo, Norway (A Morelli)  
Health Systems Research Unit, South African Medical Research Council, Cape Town, South 
Africa (S Lewin) 
Great Lakes University of Kisumu, Kisumu, Kenya (M Kaseje PhD)  
James Lind Initiative, Oxford, UK (Sir I Chalmers DSc) 
 
Address for correspondence: 
Andy Oxman  
Informed Health Choices Research Centre 
Norwegian Institute of Public Health  
PO Box 4404, Nydalen 
N-0403 Oslo, Norway 
Email: oxman@online.no  
Telephone: +47 4825 4924 
 
Word count 
Abstract: 336 words 
Text: 4849 words 
 
 DRAFT: 31 March 2017 
2 
 
Summary 
Background 
As part of the Informed Health Choices project, we developed a podcast called The Health Choices 
Programme, to help improve people’s ability to assess claims about the benefits and harms of 
treatments. The target audience was parents of primary school children in Uganda. We evaluated the 
effects of the podcast on their ability to assess claims about the effects of treatments (any action 
intended to maintain or improve health).  
Methods 
We included parents of children participating in a linked trial of the Informed Health Choices primary 
school resources. We randomly allocated consenting parents to listen to a podcast or to typical 
public service announcements about health issues. The eight main podcast episodes included a story 
about a treatment claim, a concept essential to assessing claims about treatment effects, an 
explanation of how that concept applied to the claim, and a second example illustrating the concept. 
One of the episodes covered two concepts. The primary outcome, measured after listening to the 
entire podcast, was the mean score and the proportion of parents with passing scores on a test with 
two multiple-choice questions for each of the nine concepts (18 questions in total). 
Results 
The mean score for parents in the podcast group was 67.8% correct answers, compared to 52.4% in 
the public service announcements (control) group - an adjusted mean difference of 15.5% (95% CI 
12.5% to 18.6%). In the podcast group, 70.5% of 288 parents had a predetermined passing score (> 
11 out of 18 correct answers), compared to 37.7% of 273 parents in the control group - an adjusted 
difference of 34.0% more parents with a passing score (95% CI 26.2% to 40.7%). In the podcast 
group, 31.6% of parents mastered the concepts (> 15 out of 18 correct answers), compared to 6.2% 
of parents in the control group - an adjusted difference of 26.0% more parents (95% CI 15.2% to 
39.1%). 
Interpretation 
Listening to the Informed Health Choices podcast led to a large improvement in the ability of parents 
to assess claims about the effects of treatments. 
Funding 
The trial was funded by the Research Council of Norway, Project number 220603/H10. 
Trial registration   
The trial was registered in the Pan African Clinical Trial Registry (www.pactr.org), 
PACTR201606001676150.  
 
 
 
 DRAFT: 31 March 2017 
3 
 
Introduction 
The ability to obtain, process, and understand basic health information is crucial to making 
sound health choices.1 Many people lack this ability, and commonly overestimate the 
benefits and underestimate the harms of treatments (any action intended to maintain or 
improve the health of individuals or communities).2-7 This can result in inappropriate use of 
health services and poor health outcomes.6  
Providing reliable health information in mass media - including the Internet, radio, TV and 
print media – has the potential to affect health behaviours and healthcare use.8-11 However, 
there are substantial barriers that prevent journalists from improving the scientific quality of 
their reports,12 and evaluations have found major shortcomings of health stories in the 
media.13-23 Therefore, audiences must be able to appraise the reliability of claims about 
treatment effects in the mass media, as elsewhere. This includes claims about the effects of 
drugs, surgery and other types of “modern medicine”; claims about lifestyle changes, such as 
changes to what you eat or how you exercise; claims about herbal remedies and other types 
of “traditional” or “alternative medicine”; claims about public health and environmental 
interventions; and claims about changes in how healthcare is delivered, financed and 
governed. 
Sound health choices are especially important in low-income countries; the less people have, 
the less they can afford to waste. However, few studies have evaluated the effects of 
interventions to teach critical appraisal skills to patients or the public in any country.24,25 As 
part of the Informed Health Choices project, we developed a podcast called The Health 
Choices Programme to help fill this gap.  
We began by identifying key concepts that people must understand and apply when 
assessing claims about treatments.26 Together with journalists in Uganda, we assessed which 
of the concepts it is most important for the public to understand.27 We prototyped, user-
tested and piloted various mass media resources for facilitating critical appraisal of claims 
about treatment effects. We ended up with an educational podcast for teaching nine of the 
concepts to parents of primary school children.28 The aim of this study was to test the 
effects of the podcast on the ability of listeners to apply those concepts.29-31 The podcast 
complements learning resources that we developed to teach 12 of the key concepts to 
children in the fifth year of primary school in Uganda.32 All of the key concepts included in 
the podcast were included in the primary school resources, except for one (the third concept 
in Table 1). 
We developed versions of the podcast in English and Luganda, two of the three official 
languages in Uganda, the third being Swahili. While direct translations of some terms were 
impossible, the structure and content of each version were the same. Luganda is the 
language of the Baganda, Uganda’s largest ethnic group.33 
The podcast is available online here. We also gave them a checklist summarising the key 
messages in the podcast and a song (the Informed Health Choices theme song) to reinforce 
the messages of the podcast. The podcast had 13 episodes: an introduction to the series; 
eight main episodes; three short recap episodes, each of which summarised two of the first 
 DRAFT: 31 March 2017 
4 
 
six main episodes; and a conclusion. Each of the eight main episodes included a short story 
with an example of a treatment claim, an explanation of a key concept applied to the claim, 
and another example within the same story illustrating the concept. One of the episodes 
covered two key concepts. 
The examples of claims were identified from scanning recent mass media reports and 
interviewing parents.28 The eight main episodes introduced the concepts (Table 2). Each of 
the main episodes lasted about five to ten minutes. The first main episode covered two 
closely related concepts. The final structure, content, and presentation was informed by an 
iterative, user-centred design process.28 This process involved user testing and consultation 
with stakeholders, including people in our target audience, and journalists. 
 
Methods 
Study design 
We conducted a parallel group randomised trial comparing the Informed Health Choices 
podcast to a series of typical public service announcements about health issues. Ethics 
approval was obtained from the School of Medicine’s institutional review board at Makerere 
University College of Health Sciences and the Uganda National Council for Science and 
Technology. The trial protocol is available online.34 
 
Participants 
The study was conducted in central Uganda. We recruited parents (or guardians) of children 
in the fifth year of primary school who were participating in a linked cluster-randomised trial 
of the Informed Health Choices primary school resources, which are designed to teach 
children to assess claims about treatment effects.32 Parents were recruited from both 
intervention and control schools. To be included they had to understand English or Luganda 
and consent to participate in the study. Parents were excluded if they were: 
 unable to hear, 
 not contactable by telephone, 
 health researchers, 
 participants in the development of the podcast,28 or 
 parents of children who participated in the development of the primary school 
resources.35 
We recruited a convenience sample of participants at parent meetings held at 20 
intervention schools and 15 control schools between late August and early November 2016. 
Three additional meetings at control schools were cancelled due to parents being unable to 
attend at short notice. At the meetings, we (DS and AN) provided parents with information 
about the podcast trial and sought their consent to participate. This information was also 
included in consent forms in both English and Luganda. Parents who agreed to participate 
 DRAFT: 31 March 2017 
5 
 
were asked to sign a consent form before we randomly allocated them to the podcast or 
control group.  
 
Randomisation and masking 
We stratified the parents by highest level of formal education attained (primary school, 
secondary school, or tertiary education) and the allocation of their children’s school in the 
trial of the primary school resources (intervention or control). We generated randomisation 
sequences with block sizes of four and six with equal allocation ratios within each block, 
using www.sealedenvelope.com. A statistician who was not a member of the research team 
generated the allocation sequence and, together with his team, prepared six randomisation 
lists (one for each combination of the two stratification variables) with unique codes. They 
labelled opaque envelopes with the unique codes, inserted slips of paper with the study 
group allocated to each code, and sealed them. 
Because parents were recruited in groups (from parents’ meetings) we allocated groups of 
participants at the end of each day on which a meeting was held. Upon return to the trial 
management office, the research assistant responsible for allocation opened the next 
available envelope in the stratum corresponding to each parent’s education level and 
whether the child of that parent went to a school in the intervention or control arm of the 
primary school resources trial.32 
Due to the nature of the intervention, the research assistants who delivered the podcast, 
the principal investigators supervising them (DS and AN), and the study participants all knew 
whether the participants received the Informed Health Choices podcast or to the public 
service announcements. The statistician who analysed the study results also knew which 
study group had been assigned to the podcast and which to the public service 
announcements. 
To ensure uniform performance in delivery of the podcast and the public service 
announcements, and in the assessment of outcomes, all study staff were trained before the 
start of the trial and received refresher training during the trial. We had standard operating 
procedures to guide interactions with participants.34  
 
Procedures 
Participants in the podcast group listened to a series of episodes about how to assess claims 
about treatment effects. A description of the intervention using the GREET TIDieR checklist is 
attached as Appendix 1.36  
Participants in the control group listened to typical public service announcements about the 
same conditions that were used in the podcast (Appendix 2). We designed the 
announcements to be like typical ones heard on Ugandan radio. Participants could choose 
whether they wanted to listen to the podcast or the announcements in English or Luganda. 
 DRAFT: 31 March 2017 
6 
 
The podcast and the public service announcements were produced in collaboration with a 
Ugandan radio producer and actors. 
Research assistants helped with recruitment, delivery of the podcast, follow-up, and 
administration of the test used as the outcome measure. They delivered episodes of the 
podcast or the public service announcements to the participants over a period of seven to 
ten weeks. Each research assistant was allocated about 25 participants to follow up through 
the duration of the study. To ensure that the participants listened to each episode (or 
announcement), the research assistants visited each participant once per week, delivering 
two episodes on portable media players.  
Based on findings from developing the podcast, we thought that only one episode for each 
concept would be insufficient, so the research assistants played a recap of the previous two 
episodes at each visit before playing the new episodes. In addition to listening to the 
episodes delivered by the research assistants, we provided participants with the complete 
podcast and the song on MP3 players, so that they could replay them, as well as the theme 
song, at their convenience.  
 
Outcomes  
The primary outcome was measured as: 
1. the mean score (percent of correct answers) on the test taken after listening to the 
entire podcast or all the public service announcements 
2. the proportion of participants with a passing score  
Secondary outcomes were: 
1. the proportion of participants with a score indicating mastery of the concepts 
2. for each key concept, the proportion of participants answering both questions correctly 
3. intended behaviours and self-efficacy  
The test included 18 multiple-choice questions from the Claim Evaluation Tools database - 
two for each of the nine key concepts (Appendix 3). The questions had between two and 
four response options, with an overall probability of answering 37% of the questions 
correctly by chance alone. We developed the questions based on extensive feedback from 
methodological experts, health professionals, teachers and members of the public.29 We 
conducted two Rasch analyses to validate the test.30,31 Because many parents did not have 
English as their first language and many had poor reading skills, we developed a Luganda 
version of the test to be administered orally.31 We were careful to ensure that the examples 
used in the questions were different from what was used in the podcast, and that 
participants would be able to understand the language that was used without having 
listened to the podcast. 
Eight additional multiple-choice questions were included, making 26 questions in total. 
These questions addressed four key concepts not covered by the podcast. They were 
included because the same test was used in the linked randomised trial evaluating the 
 DRAFT: 31 March 2017 
7 
 
primary school resources, and those key concepts were covered in the primary school 
resources.32 Responses to these eight questions were not included in the primary analyses of 
the podcast trial, since the podcast did not cover the concepts they address. 
The test also included questions that assessed intended behaviours and self-efficacy 
(Appendix 3). In the podcast group, the test included questions that assessed satisfaction 
with the podcast.  
We used an absolute (criterion-referenced) standard to set a passing score. Participants 
were counted as “passing” or “failing” depending on whether they met this pre-specified 
criterion. We used a combination of Nedelsky’s and Angoff’s methods to determine the cut-
off for a passing score.37 In addition, we determined a second cut-off for a score that 
indicated mastery of the nine concepts, using the same methods. The criterion for passing 
was a minimum of 11 out of 18 questions answered correctly. The criterion for mastery was 
a minimum of 15 out of 18 questions answered correctly. 
The participants completed the tests individually after listening to all the podcast episodes 
or public service announcements. We will evaluate the effects of the podcast again after one 
year, using the same outcome measure. We will also attempt to measure effects on actual 
decisions, based on self-report. 
The research assistants kept logs, including reasons for dropping out, and they recorded any 
unexpected adverse events.38 In a process evaluation that will be reported separately, we 
have collected in-depth qualitative data from interviews and focus group discussions 
regarding potential adverse effects, as well as other potential benefits of the podcast.38 
 
Statistical analysis 
We used the method described by Donner to calculate the sample size, based on calculation 
of odds ratios.39 The smallest difference between the podcast and control groups that we 
wanted to be able to detect in the proportion of respondents with a passing score was 10 
percentage points. Assuming 10% of the control group would achieve a passing score (based 
on data from a pilot study),28 statistical power of 0.90, and a 2-sided P value of 0.05, we 
estimated that 397 participants were needed to detect an improvement of 10% in the 
podcast group. Studies of the effects of drug fact boxes and a primer to help people 
understand risk suggested that this was likely to be an adequate sample size.11,40 Allowing 
for a 20% loss to follow-up we estimated that we would need a sample size of 497 
participants. 
For the primary and secondary outcomes, we used fixed effect models with the stratification 
variables (education and allocation in the Informed Health Choices primary school trial) 
modelled as a fixed effect, using logistic regression for dichotomous outcomes and linear 
regression for continuous outcomes.  Missing values were counted as wrong answers.  
 DRAFT: 31 March 2017 
8 
 
For intended behaviours and self-efficacy (Appendix 3), we dichotomized each outcome by 
combining, for example, ‘very unlikely’ with ‘unlikely’ and as ‘likely’ with ‘very likely’; and we 
reported the proportion in each category. 
We explored whether there were differences in the effects of the podcast for parents 
depending on whether they had a primary, secondary, or tertiary education level. We also 
explored whether there were differences in the effects of the podcast for parents who had a 
child in a school that received the Informed Health Choices primary school resources and 
those whose children were in a control school. These analyses adjusted for whether the 
child was in an intervention school and the parent’s level of formal education respectively.  
We conducted stepwise backward regression of the full model comprising all main effects 
and second order terms of the explanatory variables - the parent’s allocation (podcast or 
control), formal education level, and whether the child was in an intervention school - 
removing and adding one variable at a time. This resulted in a simple model with the main 
effects (explanatory variables) and without interactions (which were not statistically 
significant). Odds ratios from the logistic regression analyses were converted to risk 
differences using the control group odds as the reference, multiplying that times the odds 
ratio to estimate the intervention group odds, and converting the control and intervention 
group odds to proportions to calculate difference. 
We calculated the adjusted standardised mean difference (Hedges’ g) for comparison to 
effect sizes reported in meta-analyses of the effectiveness of other interventions to improve 
critical thinking.41,42  
The statistical analyses were performed with R (R Core Team, Vienna, Austria; version 3.3.2; 
using packages doBy, xlsx, tables, lme4, glm2, lsmeans, and sjstats). 
There was no data monitoring committee. The trial was registered on 12 June 2016 in the 
Pan African Clinical Trial Registry (www.pactr.org): Trial identifier PACTR201606001676150. 
The data files for the study are provided in Appendix 4. 
 
Role of the funding source 
This trial was funded by the Research Council of Norway, Project number 220603/H10. The 
funder had no role in the study design, data collection, data analysis, data interpretation, or 
writing of the report. The principal investigator had full access to all the data in the study 
and had final responsibility for the decision to submit for publication. 
 
Results 
Out of 868 parents who agreed to participate, 675 could be reached by phone, which was 
necessary for follow-up; 334 of the 675 were randomly allocated to listen to the podcast and 
341 were allocated to the public service announcements (control) group (Figure 1). In the 
podcast group, 288 parents (86.2%) completed the test after listening to the podcast, and in 
the control group, 273 (80.1%) completed the test after listening to the public service 
 DRAFT: 31 March 2017 
9 
 
announcements. The reasons for dropping out were similar in the podcast and control 
groups. The main reasons for dropping out of the study were: loss of interest, 18 (39.1%) 
and 28 (41.2%) in the podcast and control groups respectively); and not being able to 
contact the parents by phone, 21 (45.7%) and 25 (36.8%) respectively. Parents who dropped 
out were similar to the parents who completed the test with respect to education and sex. 
They were less likely to have said they had training in research (15.8% versus 32.1%). 
The podcast and control groups were similar with respect to their preferred language, level 
of formal education, previous exposure to research, sex, and where they commonly seek 
healthcare (Table 3). Overall 87.7% of participants elected Luganda rather than English. 
About half the participants had no more than primary school education. About one third 
reported some training in research and about one quarter reported having previously 
participated in research. However, this may not accurately reflect how many had training or 
experience that was relevant to the key concepts that the podcast addressed. About three 
quarters were women. The participants reported most commonly seeking healthcare at 
government or private for-profit facilities. There were minor differences in where they 
reported that they would seek healthcare advice. Parents in the podcast group were less 
likely to seek advice from friends or relatives (16.0% versus 28.2%) and more likely to seek 
advice from health workers (81.9% versus 67.0%). 
The mean score for parents in the podcast group was 67.8% compared to 52.4% in the 
control group. The adjusted mean difference (based on the regression analysis) was 15.5% 
(95% CI 12.5% to 18.6%; p<0.0001) higher in the podcast than in the control group. The 
distribution of test scores is shown in Web figure 1. In the podcast group, 70.5% of the 
parents had a passing score (> 11 out of 18 correct answers), compared to 37.7% in the 
control group (Table 4). The adjusted difference (based on the odds ratio from the logistic 
regression analysis) was 34.0% more parents who passed (95% CI 26.2% to 40.7%; p<0.0001) 
in the podcast than in the control group.  
In the podcast group, 31.6% of the parents had a score indicating mastery of the nine key 
concepts (> 15 out of 18 correct answers) compared to 6.2% of the parents in the control 
group. The adjusted difference was 26.0% more parents in the podcast group who mastered 
the concepts (95% CI 15.2% to 39.1%; p<0.0001). 
For each concept addressed in the podcast, the proportion of parents who answered both 
questions correctly was higher in the podcast group than in the control group (Figure 2). For 
three out of the four concepts that were taught in the primary school resources,31 but not in 
the podcast, we detected little if any difference between the podcast and the control 
groups. For the fourth concept - that small studies in which few outcome events occur are 
usually not informative and the results may be misleading - 50.7% of the parents in the 
podcast group compared to 38.5% in the control group answered both questions correctly 
(adjusted difference 12.8%; 95% CI 4.2% to 21.2%). 
We detected little if any difference between the podcast and control groups in how likely 
they would be to: find out the basis for a claim about treatment effects; find out if the claim 
was based on research; or agree to participate in research about an illness they might get 
 DRAFT: 31 March 2017 
10 
 
(Web table 5). Most (73% to 82% of both groups combined) responded likely or very likely to 
all three questions. However, more parents in the podcast group responded that they find it 
easy or very easy to assess: whether a claim is based on a research study (adjusted 
difference 15.5%; 95% CI 7.4% to 23.6%), where to find research-based information (15.4%; 
95% CI 7.6% to 23.3%), how sure they can be about the results of research comparing 
treatments (29.4%; 95% CI 21.6% to 37.3%), and how relevant research comparing 
treatments is likely to be (10.4%; 95% CI 3.0% to 17.8%) (Web table 6).  
The majority (76.4%) of parents who listened to the podcast found it ‘easy’ or ‘very easy’ to 
understand (Web table 7). Over 90% had positive views of the podcast with respect to how 
much they had liked it, how helpful they had found it, and how much they had trusted what 
they learned. 
The podcast was effective across all three levels of education: primary school, secondary 
school, and tertiary education (Web table 8). We did not detect a clear relationship between 
level of education and the size of effect. Neither did we detect a clear relationship between 
having a child in a school that used the primary school resources and the size of the effect of 
the podcast on parents’ scores (Web table 9). We found that having a child in a school that 
used the primary school resources had little if any effect on the parent’s test scores (Web 
table 10). 
The standardised mean difference (Hedges’ g) was 0.83 (95% CI 0.65 to 1.00). None of the 
parents or research assistants who delivered the podcasts reported any adverse effects.  
 
Discussion 
Listening to the Informed Health Choices podcast improved the ability of parents of primary 
school children in Uganda to assess claims about treatment effects (Panel). So far as we are 
aware, this is the first randomised trial of using a podcast for non-formal education or health 
education, other than a podcast to aid weight loss.42-53 Systematic reviews of educational 
podcasts,43 mobile learning,44,45 parental involvement in education,46,47 eHealth to improve 
health literacy,48 mobile health (mHealth),49-52 interactive media for parental education,53 
and narrative health promotion interventions54 have not found studies that are directly 
comparable to ours. Although several interventions to improve the ability of non-health 
professionals to think critically about treatments have been evaluated, most of these have 
focused on one concept: that treatments usually have beneficial and harmful effects that 
need to be considered (the last concept in Table 1).24 Other interventions designed to teach 
critical appraisal skills to non-health professionals include workshops, online courses, 
websites, books, and checklists. However, few of these have been formally evaluated.55 
A systematic review of strategies to teach people to think critically more broadly, which 
included 308 studies, found an average effect size (Hedges’ g) of 0.33.42 The average effect 
size for interventions that were targeted at graduate and adult students was 0.21, as was 
the average effect size for interventions in health or medical education. The effect size for 
our intervention (0.83) is large in comparison. However, comparisons such as these must be 
 DRAFT: 31 March 2017 
11 
 
made cautiously due to differences in the interventions that were compared in these 
studies, the outcome measures, and the methods that were used.  
In Figure 3, we compare the effects of the podcast on parents’ abilities to assess claims 
about treatment effects to the effects of the Informed Health Choices primary school 
resources on their children’s abilities and the children’s teachers’ abilities.32 The relative 
effects (odds ratios) were larger for the primary school resources than for the podcast. We 
expected this, given that the primary school intervention was multifaceted, interactive, and 
used more time (9 lessons totalling 12 hours) compared to the podcast (10 episodes totalling 
about 1.5 hours of listening). For passing scores, the absolute effect was largest for children 
and smallest for teachers, whereas for mastery scores it was largest for teachers and 
smallest for children. The absolute effect for parents was in the middle both for passing and 
mastery scores. Following the intervention, the proportion of parents and children in the 
intervention groups with a passing score in the two trials was similar (70.5% and 69.0% 
respectively). 
The same test was used in both trials, but four concepts included in the test were not 
included in the main results for this trial. This was because they were addressed by the 
primary school resources, but not by the podcast. For three of those four concepts, the 
podcast had little if any effect, as would be expected (Figure 2). For the fourth concept - that 
small studies may be misleading - an effect was detected. Although we did not include this 
concept in the podcast, it ended up being explained in episodes about closely related 
concepts: that apart from the treatments being compared, the comparison groups need to 
be similar, and that the results of a single study can be misleading (Table 1).  
Another difference between this trial and the trial of the primary school resources, and a 
limitation of this trial, is that the trial of the primary school resources was designed to be 
more pragmatic while the trial of the podcast was more explanatory.56 To ensure that the 
parents listened to the podcasts, research assistants visited the parents six times and played 
all the episodes for the parents, in addition to giving the podcast to them on MP3 players. 
Furthermore, the parents in the podcast trial volunteered to participate, whereas all the 
children in a representative sample of schools were included in the trial of the primary 
school resources. Consequently, the effect estimates from this trial indicate the potential 
effects of the podcast amongst parents who choose to listen to them, not the effect of 
simply offering the podcast to a group of parents. 
Another difference between this trial and the trial of the primary school resources is that we 
randomised individuals in this trial and schools in that trial. We did not measure the extent 
to which parents in the podcast group talked with parents in the control group or shared the 
podcast with them. However, to the extent that there was contamination, this would mean 
that the effect estimates are under-estimates.  
Another limitation of this trial is that we both developed and evaluated the podcast. 
Independent evaluation in more pragmatic trials of this and similar interventions is 
warranted.57 
 DRAFT: 31 March 2017 
12 
 
It is uncertain what the long-term impacts of listening to the podcast will be, whether it will 
have an impact on actual health choices and health outcomes, and how transferable the 
findings of this study are to other countries. We will measure outcomes again after one year, 
including impacts on actual decisions, based on self-report. We will user-test the podcast in 
Kenya and Rwanda in 2017, and we are developing a manual for adapting the podcast for 
other audiences.  
The language, structure, stories and examples of the podcast were tailored to a specific 
target audience - parents of primary school children in Uganda. Nonetheless, we have shown 
that it is possible for adults in a low-income country, with a primary school education, to 
improve their ability to assess claims about treatment effects by listening to a podcast. More 
broadly, we have demonstrated the potential of a strategy that could be delivered through 
primary schools to improve the critical health literacy of parents, in conjunction with 
teaching the same essential life skills to their children.  
We believe this study is widely relevant for two reasons. First, critical health literacy is 
essential for informed health choices, even if it is not sufficient for behavioural change. 
There is evidence that understanding of concepts can lead to improvements in health 
behaviours, although there have been few cognitive studies of conceptual change in health, 
especially in adults.58 More importantly, regardless of whether improvements in critical 
health literacy alone result in behavioural changes, these improvements are necessary for 
people to be able to make informed choices about their own or their children’s health and 
for effective public involvement and accountability in health policy decisions.  Similarly, even 
though passive dissemination of a single podcast would have a smaller effect than what we 
found among parents who volunteered to participate and who listened to the entire 
podcast, we have shown that it can improve the critical health literacy skills of some. 
Whether this effect is sustained or not, it would be desirable to reinforce and build upon 
what was learned. Thus, either way, the podcast is an important step towards addressing a 
major public health challenge. 
Second, although our study was conducted in a low-income country, we believe it is relevant 
for high-income countries. Unreliable claims about treatment effects are universal; they are 
not just a problem in low-income countries. For example, reviews of healthcare news stories 
have found major problems, including claims that are based on anecdotes, failing to 
differentiate association from causation, failing to distinguish surrogate outcomes from 
important outcomes, misleading reporting of relative effects, and failing to consider trade-
offs between benefits and harms.59 Health literacy is also a major problem in high-income 
countries,2-4 including the ability to assess information about the effects of treatments. For 
example, a survey of adults in Norway found that only one in five was able to differentiate 
association from causation, and health professionals did not perform better than non-health 
professionals.60 Unfortunately, few interventions for teaching these skills have been 
rigorously evaluated.55 Beyond showing the effectiveness of a podcast for teaching parents 
to assess treatment claims, we have demonstrated an approach to developing and 
evaluating learning resources that can and hopefully will be applied to other strategies for 
improving people’s ability to assess treatment claims and make informed health choices. 
 
 DRAFT: 31 March 2017 
13 
 
Contributors 
Daniel Semakula and Allen Nsangi are the principal investigators. They drafted the protocol 
with help of the other investigators and were responsible for the day-to-day management of 
the trial. Nelson Sewankambo and Andy Oxman had primary responsibility for overseeing 
the trial. All the investigators except for Doris Tove Kristoffersen reviewed the protocol, 
provided input, and agreed on this version. Matt Oxman together with Daniel Semakula had 
primary responsibility for developing the podcast. All the investigators contributed to the 
development. Astrid Austvoll-Dahlgren had primary responsibility for developing and 
validating the outcome measure. Daniel Semakula and Allen Nsangi had primary 
responsibility for data collection. Andy Oxman, Sarah Rosenbaum, Astrid Austvoll-Dahlgren, 
and Iain Chalmers were principal members of the coordinating group for the trial and, 
together with Nelson Sewankambo and the principal investigators, acted as the steering 
committee for the trial. They were responsible for final decisions about the protocol and 
reporting of the results.  
 
Declaration of interests 
All the authors declare that they have no competing interests. 
 
Acknowledgements 
We are grateful to the Global Health and Vaccination Research (GLOBVAC) programme of 
the Research Council of Norway for supporting the project, and to the English National 
Institute for Health Research for supporting Iain Chalmers and the James Lind Initiative. Alun 
Davies, Lena Nordheim, Peter O. Okebukola, Newton Opiyo, Jonathan Sharples, Helen 
Wilson, and Charles Shey Wiysonge determined the cut off scores for passing and mastery. 
We want to thank Margaret Nabatanzi, Martin Mutyaba, Esther Nakyejwe, and Solomon 
Segawa for their help with data management; and all the research assistants who helped 
with recruitment, delivering the podcast, data collection and entry. We would also like to 
thank the producers and the musicians who helped with the production of the Informed 
Health Choices theme song and the podcast, particularly Abraham Jjuko and Christopher 
Kiwanuka. We also thank the Informed Health Choices advisory group. We are especially 
grateful to all the parents and journalists who helped with the development of the Informed 
Health Choices podcast and those who participated in this trial.  
  
 
 
 DRAFT: 31 March 2017 
14 
 
References 
1. 
Institute of Medicine, Committee on Health Literacy. Health Literacy: A Prescription 
to End Confusion. Washington, DC: National Academy Press, 2004. 
2. 
Kutner M, Greenberg E, Jin Y, Paulsen C. The health literacy of America’s adults: 
results from the 2003 National Assessment of Adult Literacy (NCES 2006-483). 
Washington, DC: U.S. Department of Education, National Center For Education 
Statistics, 2006. 
3. 
Sørensen K, Pelikan JM, Röthlin F, et al. Health literacy in Europe: comparative results 
of the European health literacy survey (HLS-EU). Eur J Public Health 2015; 25: 1053-
58. 
4. 
Diviani N, Van Den Putte B, Giani S, Van Weert JC. Low health literacy and evaluation 
of online health information: a systematic review of the literature. J Med Internet 
Res 2015; 17: e112.  
5. 
Schrauben SJ, Wiebe DJ. Health literacy assessment in developing countries: a case 
study in Zambia. Health Promot Int 2015;  pii: dav108. 
6. 
Berkman ND, Sheridan SL, Donahue KE, Halpern DJ, Crotty K. Low health literacy and 
health outcomes: an updated systematic review. Ann Intern Med 2011; 155: 97-107. 
7. 
Hoffmann TC, Del Mar C. Patients' expectations of the benefits and harms of 
treatments, screening, and tests: a systematic review. JAMA Itern Med 2015; 175: 
274-86. 
8. 
Bala MM, Strzeszynski L, Topor-Madry R, Cahill K. Mass media interventions for 
smoking cessation in adults. Cochrane Database Syst Rev 2013; 6: CD004704.   
9. 
Vidanapathirana J, Abramson MJ, Forbes A, Fairley C. Mass media interventions for 
promoting HIV testing. Cochrane Database Syst Rev 2005; 3: CD004775. 
10. 
Grilli R, Ramsay C, Minozzi S. Mass media interventions: effects on health services 
utilisation. Cochrane Database Syst Rev 2002; 1: CD000389. 
11. 
Woloshin S, Schwartz LM. Communicating data about the benefits and harms of 
treatment: a randomized trial. Ann Intern Med 2011; 155: 87-96. 
12. 
Larsson A, Oxman AD, Carling C, Herrin J. Medical messages in the media - barriers 
and solutions to improving medical journalism. Health Expect 2003; 6: 323-31. 
13. 
Walsh-Childers K, Braddock J, Rabaza C, Schwitzer G. One step forward, one step 
back: changes in news coverage of medical interventions. Health Commun 2016; DOI: 
10.1080/10410236.2016.1250706. 
14. 
Sumner P, Vivian-Griffiths S, Bolvin J, et al. Exaggerations and caveats in press 
releases and health-related science news. PLoS One 2016; 11: e0168217. 
 DRAFT: 31 March 2017 
15 
 
15. 
Wang MTM, Grey A, Bolland MJ. Conflicts of interest and expertise of independent 
commenters in news stories about medical research. CMAJ 2016; 
DOI:10.1503/cmaj.160538. 
16. 
Schwartz LM, Woloshin S, Andrews A, Stukel TA. Influence of medical journal press 
releases on the quality of associated newspaper coverage: retrospective cohort 
study. BMJ 2012; 344: d8164. doi:10.1136/bmj.d8164 
17. 
Lewis M, Orrock P, Myers S. Uncritical reverence in CM reporting: assessing the 
scientific quality of Australian news media reports. Health Sociol Rev 2010; 19: 57-72. 
18. 
Oliveira MS, Paiva LHC, Costa JV, Pinto-Neto AM. Women's health in the Brazilian 
press: analysis of scientific quality in weekly magazines. Interface (Botucatu). 2009; 
13: 7-16. 
19. 
Schwitzer G. How Do US Journalists Cover Treatments, Tests, Products, and 
Procedures? An Evaluation of 500 Stories. PLoS Med 2008; 5: e95 
20. 
Glenton C, Paulsen E, Oxman AD. Portals to Wonderland? Health portals lead 
confusing information about the effects of health care. BMC Medical Informatics and 
Decision Making. 2005; 5: 7. 
21. 
Biondo E, Khoury MC. [Validation of a questionnaire to assess the quality of health 
information in Argentinian newspapers]. Biomédica 2005; 25: 366-76. 
22. 
Moynihan R, Bero L, Ross-Degnan D, et al. Coverage by the news media of the 
benefits and risks of medications. N Engl J Med 2000; 342: 1645-50. 
23. 
Johansen LW, Bjørndal A, Flottorp S, et al. Evaluation of health information in 
newspapers and brochures. What can we believe?].Tidsskr Nor Laegeforen 1996; 
116: 260-64. 
24. 
Austvoll-Dahlgren A, Nsangi A, Semakula D. Measuring peoples’ understanding of the 
effects of treatments: a review of outcome measures. Syst Rev 2016; 5: 215. 
25. 
Cusack L, Del Mar CB, Chalmers I, Hoffmann TC. Educational interventions to improve 
people’s understanding of key concepts in assessing the effects of health 
interventions: a systematic review protocol. Syst Rev 2015; 5: 37.  
26. 
Austvoll-Dahlgren A, Oxman AD, Chalmers I, et al. Key concepts that people need to 
understand to assess claims about treatment effects. J Evid Based Med 2015; 8: 112-
25. 
27. 
Semakula D, Nsangi A, Oxman AD, Sewankambo N. Priority setting for resources to 
improve information about claims of treatment effects in the mass media. J Evid 
Based Med 2015; 8: 84-90. 
28. 
Semakula D, Nsangi A, Oxman M, et al. Development of the Informed Health Choices 
podcast to improve the ability of parents of primary school children in Uganda to 
assess claims about treatment effects. IHC Working Paper, in press. 
 DRAFT: 31 March 2017 
16 
 
29. 
Austvoll-Dahlgren A, Semakula D, Nsangi A, et al. The development of the “Claim 
Evaluation Tools”: assessing critical thinking about effects. BMJ Open, in press. 
30. 
Austvoll-Dahlgren A, Guttersrud Ø, Semakula D, et al. Measuring ability to assess 
claims about treatment effects: A latent trait analysis of the Claim Evaluation Tools 
using Rasch modelling. BMJ Open, in press. 
31. 
Semakula D, Nsangi A, Øystein G, Oxman AD, Sewankambo NK, Austvoll-Dahlgren A. 
Measuring ability to assess claims about treatment effects in English and Luganda: 
evaluation of multiple-choice questions from the “Claim Evaluation Tools” database 
using Rasch modelling. IHC Working Paper, 2017. 
32. 
Nsangi A, Semakula D, Oxman AD, et al. Effects of using the Informed Health Choices 
primary school resources on the ability of children in Uganda to assess the reliability 
of claims about treatment effects: a cluster-randomised trial. Submitted. 
33. 
Uganda Bureau of Statistics. The National Population and Housing Census 2014 – 
Main Report. Kampala: Uganda Bureau of Statistics, 2016. 
34. 
Semakula D, Nsangi A, Oxman M, et al. Can an educational podcast improve the 
ability of parents of primary school children to assess the reliability of claims made 
about the benefits and harms of treatments: study protocol for a randomised 
controlled trial. Trials 2017; 18: 31. 
35. 
Nsangi A, Semakula D, Oxman M, et al. Development of the Informed Health Choices 
resources to teach primary school children to assess claims about treatment effects. 
IHC Working Paper, in press. 
36. 
Phillips AC, Lewis LK,, McEvoy MP, et al. Development and validation of the guideline 
for reporting evidence-based practice educational interventions and teaching 
(GREET). BMC Med Educ 2016; 16: 237. 
37. 
Davies A, Gerrity M, Nordheim L, et al. Measuring ability to assess claims about 
treatment effects: establishment of a standard for passing and mastery. IHC Working 
Paper 2017; ISBN 978-82-8082-802-6. 
38. 
Semakula D, Nsangi A, Glenton C, et al. An educational podcast to improve the ability 
of parents of primary school children in Uganda to assess claims about treatment 
effects: process evaluation protocol. IHC Working Paper 2017. ISBN 978-82-8082-
804-0. 
39. 
Donner A. Sample size requirements for stratified cluster randomized designs. Stat 
Med 1992; 11: 743-50. 
40. 
Woloshin S, Schwartz LM, Welch HG. The effectiveness of a primer to help people 
understand risk: two randomized trials in distinct populations. Ann Intern Med 2007; 
146: 256-65. 
 DRAFT: 31 March 2017 
17 
 
41. 
White IR, Thomas J. Standardized mean differences in individually-randomized and 
cluster-randomized trials, with applications to meta-analysis. Clin Trials 2005; 2: 141-
51. 
42. 
Abrami PC, Bernard RM, Borokhovski E, et al. Strategies for teaching students to 
think critically a meta-analysis. Rev Educ Res 2015; 85: 275-314. 
43. 
Hew KF. Use of audio podcast in K-12 and higher education: a review of research 
topics and methodologies. Educ Technol Res Dev 2009; 57: 333-57. 
44. 
Crompton H, Burke D, Gregory KH, Gräbe C. The use of mobile learning in science: a 
systematic review. J Sci Educ Technol 2016; 25: 149-60. 
45. 
Wu W-H, Wu Y-C J, Chen C-Y, et al. Review of trends from mobile learning studies: a 
meta-analysis. Comput Educ 2012; 59: 817-27. 
46. 
Higgins S, Katsipataki M. Evidence from meta-analysis about parental involvement in 
education which supports their children’s learning. J Child Serv 2015; 10:280-90. 
47. 
Spier E, Britto P, Pigot, T, et al. Parental, community and familial support 
interventions to improve children’s literacy in developing countries: a systematic 
review, 3ie Systematic Review 26. London: International Initiative for Impact 
Evaluation (3ie), 2016. 
48. 
Jacobs RJ, Lou JQ, Ownby RL, Caballero J. A systematic review of eHealth 
interventions to improve health literacy. Health Inform J 2016; 22: 81-98. 
49. 
Sondaal SF, Browne JL, Amoakoh-Coleman M, et al Assessing the effect of mHealth 
interventions in improving maternal and neonatal care in low- and middle-income 
countries: a systematic review. PloS one 2016; 11: e0154664. 
50. 
Aranda-Jan CB, Mohutysiwa-Dibe N, Loukanova S. Systematic review on what works, 
what does not work and why of implementation of mobile health (mHealth) projects 
in Africa. BMC Public Health 2014; 14:188. 
51. 
Peiris D, Praveen D, Johnson C, Mogulluru K. Use of mHealth systems and tools for 
non-communicable diseases in low- and middle-income countries: a systematic 
review. J Cardiovasc Transl Res 2014; 7: 677-91. 
52. 
Free C, Phillips G, Galli L, et al. The effectiveness of mobile-health technology-based 
health behaviour change or disease management interventions for health care 
consumers: a systematic review. PLoS Med 2013; 10: e1001362. 
53. 
Annaim A, Lassiter M, Viera AJ, et al. Interactive media for parental education on 
managing children chronic condition: a systematic review of the literature. BMC 
Pediatr 2015; 15: 201. 
54. 
Perrier MJ, Ginis KAM. Changing health-promoting behaviours through narrative 
interventions: a systematic review. J Health Psychol 2016; DOI: 
10.1177/1359105316656243. 
 DRAFT: 31 March 2017 
18 
 
55. 
Castle JC, Chalmers I, Atkinson P, et al. Establishing a library of resources to help 
people understand Key Concepts in assessing treatment claims - The Critical thinking 
and Appraisal Resource Library (CARL). Submitted. 
56. 
Thorpe KE, Zwarenstein M, Oxman AD, et al. A pragmatic-explanatory continuum 
indicator summary (PRECIS): a tool to help trial designers. J Clin Epidemiol 2009; 62: 
464-75. 
57. 
Sharples J, Oxman AD, Mahtani KR, et al. What can evidence-based education and 
healthcare learn from each other? IHC Working Paper, 2017. 
58. 
Kaufman DR, Keselman A, Patel VL. Conceptual understanding in the domain of 
health. In: Vosniadou S. International handbook of research on conceptual change. 
2nd edition. Oxford: Routledge, 2013. 
59. 
Schwitzer G. A guide to reading health care news stories. JAMA Intern Med 2014; 
174: 1183-6. 
60. 
Oxman AD, Austvoll-Dahlgren A, Garratt A, Rosenbaum S. Understanding of key 
concepts relevant to assessing claims about treatment effects: a survey of Norwegian 
adults. IHC Working Paper, 2017. ISBN 978-82-8082-819-4.  
 
