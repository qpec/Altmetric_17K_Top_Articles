 Original Investigation
The Mass Production of Redundant,
Misleading, and Conflicted Systematic
Reviews and Meta-analyses
JOHN P.A. IOANNIDIS
Stanford University School of Medicine; Stanford University School of
Humanities and Sciences; Meta-Research Innovation Center at Stanford
(METRICS), Stanford University
Policy Points:
r Currently, there is massive production of unnecessary, misleading, and
conflicted systematic reviews and meta-analyses. Instead of promoting
evidence-based medicine and health care, these instruments often serve
mostly as easily produced publishable units or marketing tools.
r Suboptimal systematic reviews and meta-analyses can be harmful given
the major prestige and influence these types of studies have acquired.
r The publication of systematic reviews and meta-analyses should be
realigned to remove biases and vested interests and to integrate them
better with the primary production of evidence.
Context: Currently, most systematic reviews and meta-analyses are done retro-
spectively with fragmented published information. This article aims to explore
the growth of published systematic reviews and meta-analyses and to estimate
how often they are redundant, misleading, or serving conflicted interests.
Methods: Data included information from PubMed surveys and from empirical
evaluations of meta-analyses.
Findings: Publication of systematic reviews and meta-analyses has increased
rapidly. In the period January 1, 1986, to December 4, 2015, PubMed tags
266,782 items as “systematic reviews” and 58,611 as “meta-analyses.” An-
nual publications between 1991 and 2014 increased 2,728% for systematic
reviews and 2,635% for meta-analyses versus only 153% for all PubMed-
indexed items. Currently, probably more systematic reviews of trials than new
The Milbank Quarterly, Vol. 94, No. 3, 2016 (pp. 485-514)
c
� 2016 Milbank Memorial Fund. Published by Wiley Periodicals Inc.
485
 486
J.P.A. Ioannidis
randomized trials are published annually. Most topics addressed by meta-
analyses of randomized trials have overlapping, redundant meta-analyses; same-
topic meta-analyses may exceed 20 sometimes. Some fields produce massive
numbers of meta-analyses; for example, 185 meta-analyses of antidepressants
for depression were published between 2007 and 2014. These meta-analyses are
often produced either by industry employees or by authors with industry ties
and results are aligned with sponsor interests. China has rapidly become the
most prolific producer of English-language, PubMed-indexed meta-analyses.
The most massive presence of Chinese meta-analyses is on genetic associations
(63% of global production in 2014), where almost all results are misleading
since they combine fragmented information from mostly abandoned era of can-
didate genes. Furthermore, many contracting companies working on evidence
synthesis receive industry contracts to produce meta-analyses, many of which
probably remain unpublished. Many other meta-analyses have serious flaws.
Of the remaining, most have weak or insufficient evidence to inform decision
making. Few systematic reviews and meta-analyses are both non-misleading
and useful.
Conclusions: The production of systematic reviews and meta-analyses has
reached epidemic proportions. Possibly, the large majority of produced system-
atic reviews and meta-analyses are unnecessary, misleading, and/or conflicted.
Keywords: systematic reviews, meta-analyses, bias, conflicts of interest, China,
evidence-based medicine, industry.
S
ystematic reviews and meta-analyses are indispensable
components in the chain of scientific information and key tools for
evidence-based medicine. Evidence-based medicine and these key
reviewing tools have become very popular but have also attracted criti-
cism, even from their proponents.1-4 Information from multiple studies
can be synthesized either prospectively or retrospectively. Ideally, meta-
analyses should be primary research efforts where investigators collabo-
rate preemptively in consortia with embedded replication across teams
and joint analyses. This paradigm has already been successful in some
fields; for example, large consortia conduct prospective meta-analyses of
genome data.5 However, teamwork, collaboration, and replication are
uncommon in most fields due to lack of incentives. The preference to
fund single investigators has not allowed these paradigms to thrive. For
randomized trials, examples of collaborative, prospective meta-analyses
are rare.6,7 In most fields in biomedicine and beyond, systematic re-
views and meta-analyses remain retrospective exercises that try to piece
 Mass Production of Systematic Reviews and Meta-analyses
487
together fragmented and selectively reported published information.
Even so, these efforts can have value for assessing existing evidence and
for informing new research. In other words, it is irrational not to sys-
tematically review what is already known before deciding to perform
any new study.8 Moreover, once a new study is completed, it is useful to
update the cumulative evidence.9 Therefore, meta-analyses can be useful
either as primary or as secondary research.
This article will argue that a large number—possibly the large
majority—of systematic reviews and meta-analyses produced to date
are not useful. The aim of this article is to demonstrate with empirical
data that, currently, on many (not all) topics, systematic reviews and
meta-analyses are overproduced and that, instead of clarifying the evi-
dence, too many of these reviews often suffer from extensive redundancy,
little value, misleading claims, and/or vested interests.
Increase in Published Systematic
Reviews and Meta-analyses
An examination of PubMed-indexed articles between January 1, 1986,
and December 4, 2015, shows 266,782 items tagged as “systematic
reviews” and 58,611 items tagged as “meta-analyses” (Figure 1). The
ascribed PubMed tags for type of publication are not fully accurate and
some articles may be misclassified. The problem of poor classification
in PubMed tags is relatively more prominent before 1990. However,
these tags are accurate enough to show the extensive growth in the
publication of these types of articles. Only 1,024 and 334 articles pub-
lished in 1991 were classified as systematic reviews and meta-analyses,
respectively. For articles published in 2014, the respective numbers were
28,959 systematic reviews and 9,135 meta-analyses. This corresponds
to an increase in the publication rate of 2,728% for systematic reviews
and 2,635% for meta-analyses. When all PubMed-indexed items are
considered, 410,093 were published in 1991 and 1,039,145 in 2014,
amounting to an increase of only 153% in the publication rate.
One may argue that this pattern reflects the effort of systematic re-
viewers to catch up with reviewing the existing published literature that
had accumulated over time. Systematic reviews only started becoming
popular in the late 1980s after a pivotal article by Cynthia Mulrow
showed that among 50 review articles published in 1985–1986 in 4
 488
J.P.A. Ioannidis
Figure 1. Number of PubMed-Indexed Articles Published Each Year
Between 1986 and 2014 That Carry the Tag “Systematic Review” or
“Meta-analysis” for Type of Publication
0
5,000
10,000
15,000
20,000
25,000
30,000
1986
1987
1988
1989
1990
1991
1992
1993
1994
1995
1996
1997
1998
1999
2000
2001
2002
2003
2004
2005
2006
2007
2008
2009
2010
2011
2012
2013
2014
Systema�c reviews
Meta-analyses
 Mass Production of Systematic Reviews and Meta-analyses
489
major medical journals, nonsystematic information synthesis was very
suboptimal.10 Meta-analysis methods have been available for almost a
century, but their use in biomedicine was infrequent until the 1990s,11
perhaps due to limited knowledge of them by physicians and lack of
popular software to perform them in massive scale. Currently, system-
atic reviews have essentially caught up with the need to synthesize the
old literature. Nevertheless, the accelerated publication of systematic
reviews and meta-analyses continues to be impressive, corresponding
to 67% and 132% increases, respectively, between 2010 and 2014, as
compared to only a 27% increase for all PubMed-indexed items.
Of note, items tagged as “reviews” also continue to be produced on a
large scale, even more so than “systematic reviews” (106,110 “reviews”
published in 2014 versus 82,530 in 2010, a 29% increase). The major,
frequent problems with nonsystematic reviews have been highlighted
repeatedly.10,12,13 Any criticism of systematic reviews and meta-analyses
in this article should not be seen as a suggestion to revert to nonsystem-
atic reviews.
Current Coverage of the Literature by
Systematic Reviews and Meta-analyses
Despite the geometric growth of systematic reviews and meta-analyses,
only a small fraction of data from empirical biomedical studies are in-
cluded in such efforts. In a random sample of 259 articles with empirical
data from PubMed (2000-2014),14 only 19 (7%) have had their data
considered for inclusion in a systematic review and 16 of these 19 have
had their data eventually incorporated in data syntheses. However, these
estimates pertain to a mixture of very different types of data, from cell
biology to randomized trials. Usually for each study, there is no other
study to review it together with for comparison. Most investigators in
most fields loathe performing a replica of a previous study. This is proba-
bly a consequence of the requirement to promise novelty and innovation
imposed on researchers by funding agencies and promotion commit-
tees. Only a tiny fraction of biomedical articles are truly disruptively
innovative.15 The vast majority of articles are neither innovative nor
identical to previous work. Studies may be similar, but they are made
deliberately different in one or more aspects. For example, in an em-
pirical evaluation of 60 published studies on risk factors for pterygium
 490
J.P.A. Ioannidis
(a very common eye condition), no pair of studies considered the exact
same factors or used identical adjustments for “known” risk factors.16
In that same random sample of 259 articles with empirical data from
PubMed (2000-2014),14 only 8 (3%) claimed to be replications relating
to previous studies and only 8 (3%) were cited by subsequent studies
claiming to be replications addressing the same question. Investigators
generally do not admit that they examine the same questions as pre-
vious work, most likely because they do not want to be thought of as
producing what is commonly derided as “me too” articles. The reality is
that almost all of these articles address questions that have been largely
previously investigated. Yet the masquerade is so well done that a sys-
tematic reviewer may be at a loss as to whether these studies can be
put together in a systematic review that will not depend on multiple
subjective, and thus questionable, selection choices. The shallow quest
for “innovation” creates articles that exhibit an idiosyncrasy more typical
of artistic endeavors (“my creation is unique, or sui generis”) rather than
the sciences, which cherish universalism, communalism,17 and, above
all, reproducibility.
Meta-analyses of Experimental Animal
Studies
While much “basic” research is in this state of pseudo-innovative mas-
querade in the quest for making a questionable case for novelty, exper-
imental studies, in particular randomized trials, are more difficult to
make so different from one another so as to be non-amenable to system-
atic review and meta-analysis. Even for preclinical research, randomized
trials of animal experiments can be grouped together and meta-analyzed.
In fact, several initiatives in the last decade, in particular the compilation
of animal experimental studies by the CAMARADES coalition,18,19 have
allowed the efficient practice of systematic reviews and meta-analyses
of all trials in this field. The conclusions of these initiatives are that
animal-based experimental research is largely unreliable not because
animals cannot inform us about human diseases but because this re-
search is affected by major quality deficits, selective reporting, and
other biases.18-21 One evaluation of such research found that main qual-
ity features such as proper randomization and blinding of investigators
assessing outcomes are rarely adhered to.22 Other efforts have addressed
 Mass Production of Systematic Reviews and Meta-analyses
491
biases in animal studies of experimental treatments or toxicology as-
sessments of chemicals.23-26 Instead of performing more such animal
studies and retrospective meta-analyses thereof that highlight more of
these same biases, research in these fields should be recast with better
study methods, and a prospective design of meta-analyses that includes
all the studies launched. Probably for similar quality reasons, repro-
ducibility is also low for other types of preclinical research (eg, drug
target research on in vivo and cell culture models).27,28 The discovery
pipeline for interventions with large impact on health outcomes and
health policies will continue to suffer from this bottleneck.29
Meta-analyses of Randomized Trials
of Humans
For meta-analyses of clinical research, especially randomized controlled
trials of interventions, the situation is also discouraging. The main de-
ficiency 25 years ago was that there were very few meta-analyses of ran-
domized trials of humans. The Cochrane Collaboration was launched30
in 1992 at a time when a meta-analysis of randomized trials (or any
meta-analysis) was still a rare event. The Cochrane Collaboration at-
tracted many volunteers and innovative methodologists in an effort to
systematically integrate evidence on all medical and health care–related
interventions.31 It set high standards, and Cochrane reviews systemat-
ically scored higher in quality assessments than other reviews.32-34 As
of December 4, 2015, the Cochrane Database of Systematic Reviews
included 9,170 entries of systematic reviews, which was close to the
original anticipation that 10,000 reviews would be needed to cover the
entire evidence base of medicine and health care.35 However, Cochrane
is currently the source of only a small minority of the systematic reviews
and meta-analyses produced about the effects of medical interventions.36
At present, for the majority of topics there is more than simply 1
meta-analysis of randomized trials. An empirical evaluation37 examined
73 meta-analyses that had been published in 2010. Of those, 49 (67%)
had at least 1 more meta-analysis published on the same topic by the
end of 2012. The median was 2 meta-analyses, but the maximum was
up to 13 meta-analyses on the same topic.
One may argue that some redundancy is useful.38 There may be some
benefit in having several independent authors look at the same data to
 492
J.P.A. Ioannidis
see whether they reach the same results and conclusions. Others may
argue that if an original meta-analysis did not look at all the outcomes
of interest, then other meta-analyses are needed to examine the different
outcomes that were not included in the original study. The above-
mentioned empirical survey37 suggests that these excuses can go only
so far: 23% of the subsequent meta-analyses included 1 or more authors
of the original meta-analyses, and 65% of the subsequent meta-analyses
did not include any additional outcomes. Even when published meta-
analyses on the same topic examine different outcomes, the practice
of presenting these outcomes in different articles is suboptimal and
confusing. Decision making requires a thorough examination of all the
main outcomes of interest, including both benefits and harms,39 and it
makes sense to have those presented in the same place.
Since 2010 (the index year for the above-mentioned survey37 of over-
lapping meta-analyses), the number of systematic reviews and meta-
analyses of randomized trials of humans produced and published has
continued to escalate at the same pace as presented in Figure 1 for all
systematic reviews and meta-analyses in general. Apparently, about half
of the published systematic reviews pertain to reviews of trials: a search
with “trial* OR randomi* OR treatment*” gives 9,628 systematic re-
views in 2010 and 15,284 in 2014, representing 56% and 53% of all
systematic reviews in these years, respectively. The proportion of trial-
related articles is similarly high among meta-analyses. For comparison,
the number of full-text articles classified in PubMed as “randomized
controlled trials” has remained stable over these years, and it was 23,133
in 2014. Given that many randomized controlled trials have multiple
publications to present their data (eg, of 191 primary trials published
in high-impact journals in 2009, 88 [46%] had a total of 475 secondary
publications published by February 2014)40 and that several of the arti-
cles tagged as “randomized controlled trials” in PubMed are not actually
publications of randomized trials, it is possible that nowadays there are
more systematic reviews of randomized trials being published than new
randomized trials.
Yet it is important to note that overlapping meta-analyses can often
be confusing because they may reach different conclusions. Several au-
thors have previously tried to offer some guidance on what to do when
different meta-analyses exist on the same topic, especially when their
conclusions are different.1,41-44 However, navigating through these dis-
crepancies can be demanding even for investigators who are well trained
 Mass Production of Systematic Reviews and Meta-analyses
493
in evidence-based medicine and highly conversant on these methods.
One is often left with a taste of powerful subjectivity pervading what
should seemingly have been objective, quantitative methods. The fram-
ing of the question, the choice of eligible studies, the selection of compar-
isons, populations, and outcomes of interest, the types of data extracted,
and the statistical methods used, along with many other factors, allow
for substantial diversity in the final results. More importantly, the in-
terpretation of even the same results can differ across systematic reviews
and meta-analyses on the same topic, especially when the authors have
strong motivations to reach specific conclusions. The next section dis-
cusses potential financial conflicts of interest, but conflicts and opinions
may not be based on financial factors. Academic opinions and conflicts
can also be very strong.45 When data are selected and synthesized retro-
spectively, the selection and synthesis may be made to fit to the strong
opinions and expectations of the editors and reviewers.46
For some topics, the extent of redundancy in meta-analyses of ran-
domized trials has reached epidemic proportions. For example, the em-
pirical evaluation of overlapping meta-analyses37 identified 11 such
meta-analyses of statins for prevention of atrial fibrillation after cardiac
surgery published over 4 years. The first one, published in February
2008, had a non–statistically significant summary effect, but the second
one, published in June 2008 and including more trials, already showed a
highly statistically significant and clinically sizeable benefit from statins
in this setting. This did not change materially in the subsequent 9
meta-analyses published through late 2012. Some of those even had
practically identical results. Of note, subsequent meta-analyses did not
cite systematically among their references the prior meta-analyses on the
same topic.37 An extension of the search for any additional meta-analyses
published on this same topic from January 1, 2013, through Decem-
ber 4, 2015, identified another 10 potentially eligible meta-analyses. In
total, 21 meta-analyses have addressed statins for prevention of atrial
fibrillation after cardiac surgery. Two, perhaps three, such meta-analyses
would be reasonable to have. The rationale for the others is unclear.
Given that the data for a meta-analysis of the published literature are
readily available in public, it is not even clear to what extent a meta-
analysis may even “copy” data from previous meta-analyses done on
the same topic (see some examples of such “copycat” behavior hover-
ing on plagiarism at http://www.scientificamerican.com/article/for-sale-
your-name-here-in-a-prestigious-science-journal/). Another possibility
 494
J.P.A. Ioannidis
is that massive production of redundant meta-analyses of industry prod-
ucts serves as a marketing tool, some sort of petty advertisement, much
like seeding randomized trials47 or like reprints of pivotal trials dis-
tributed by pharmaceutical company representatives to physicians.48
Massive Production of Conflicted
Meta-analyses: Antidepressants
as a Case Study
Antidepressants offer a case study of the confusing effects of having re-
dundant meta-analyses with different conclusions and of the transforma-
tion of meta-analyses into marketing advertisements. Clinical research
on antidepressants exemplifies some of the major problems facing clinical
trials. Multiple small trials are conducted, most of them with industry
support, with meaninglessly short follow-up, with outcomes that can be
measured in a variety of scales of only modest clinical relevance, with
“creative” analyses of the data, and with extensive publication bias and
other selective outcome reporting.49 Meta-analysis is a natural choice to
try to understand which are the best drugs and how much different they
are in terms of effectiveness and tolerability from their competitors.
Some of these efforts have evaluated multiple antidepressants as part
of the same analysis. However, a comparison50 of the results of several
meta-analytic evaluations that addressed the effectiveness of and/or tol-
erability for diverse antidepressants51-53 showed that their ranking of
antidepressants was markedly different. These studies had been con-
ducted by some of the best meta-analysts in the world, all of them
researchers with major contributions in the methods of meta-analysis
and extremely experienced in its conduct. However, among 12 con-
sidered drugs, paroxetine ranked anywhere from first to tenth best and
sertraline ranked anywhere from second to tenth best. This does not even
account for the fact that some of these trials’ data were not trustworthy
to start with, as has been exemplified by a number of reanalyses of the
raw data from the clinical trials. For example, the recent reanalysis54
by independent investigators of Study 329, a pivotal trial of paroxetine
and imipramine versus placebo, reached entirely opposite conclusions
to those published originally. Paroxetine had been originally claimed to
be effective and safe. Upon reanalysis, it was found to be ineffective and
to carry unacceptably high rates of adverse events with major harms.54
 Mass Production of Systematic Reviews and Meta-analyses
495
Many other reanalyses of the same raw data from the same trials have
reached different results and conclusions than those of the original pub-
lications in diverse fields beyond antidepressants.55-58 However, even
if available trial results are perfectly accurate, how can it be that the
best meta-analysts in the world can reach such different conclusions in
the case of antidepressants? The answer seemed to be that diverse trials
and outcomes were considered because of different eligibility criteria. A
critical question to ask then is, who decides on whether the eligibility
criteria are good, better, excellent, or optimal?
Ideally, people who have no stake in the results should perform sys-
tematic reviews and meta-analyses,46 excluding not only those with
financial conflicts of interest but even those who are content experts
in the field. According to this line of argument,46 content experts can
and should be consulted, but they should not be authors. The debate
remains open about who else should participate as consultants or authors
in systematic reviews. For example, patients may be more relevant than
experts in prioritizing outcome measures.
Independence of systematic reviews is rare in meta-analyses of antide-
pressants. The market of antidepressants is worth many tens of billions
of dollars per year. In the United States, about 10% of people currently
take antidepressants, and the use of these drugs has increased fourfold
over the last 15 years. Given that evidence-based medicine has become
so successful, an increasing number of physicians and even patients want
to see a systematic review and meta-analysis to be convinced that a
treatment is worth adopting. For antidepressants, the supply of meta-
analyses is astonishing. An empirical evaluation59 searched PubMed for
meta-analyses assessing antidepressants for depression published from
January 2007 through March 2014. The search period started after the
big debate about whether antidepressants might increase the risk of sui-
cides and suicide-related death.60 The search59 identified 185 eligible
meta-analyses published over these 7 years, representing a high-output
factory of such studies. Of the 185 meta-analyses, 54 (29%) had authors
who were employees of the assessed drug’s manufacturer, and 147 (79%)
had some industry link (sponsorship or authors who were industry em-
ployees and/or had conflicts of interest). The survey did not examine how
many of the remaining 38 meta-analyses had content experts as authors.
This is a clear example of an area where meta-analyses are emerging
as a powerful marketing tool. Only 58 (31%) of the 185 meta-analyses
of antidepressants for depression had any negative statements about
 496
J.P.A. Ioannidis
antidepressants (eg, any caveat about their efficacy or safety) in the con-
cluding statement of their abstract. Meta-analyses including an author
who was an employee of the manufacturer of the assessed drug were 22
times less likely to have negative statements about the drug than other
meta-analyses (1/54 [2%] vs 57/131 [44%], p < 0.001).59
There are 2 types of meta-analyses that contribute particularly to the
multitude of favorable meta-analyses. The first type is pooled analy-
ses conducted by industry employees. These analyses usually mobilize
the raw, individual-level data and typically combine information from
several trials on a single agent or multiple agents produced by a sin-
gle manufacturer. This methodology provides a very narrow view of
evidence because for most diseases and indications, the available con-
testing treatment options are multiple.61 Despite the advantage of using
individual-level information, these pooled analyses may be among the
most inbred and conflicted type of research. Not surprisingly, almost all
the published articles of this type reached favorable conclusions about
the assessed drug.59 The second type is meta-analyses where the indus-
try has supported the authors directly (for the particular meta-analysis)
or indirectly by promoting their careers in various ways (eg, research
grants, speaker bureau membership, paid advisory board positions). This
approach does not provide the best setting to perform an objective meta-
analysis. These authors may consciously or subconsciously pay their due
tribute to their current or former sponsors.
The differential conclusions and adoption of industry-partisan views
in systematic reviews and meta-analyses sponsored by the industry have
also been seen in several other empirical evaluations by investigators
in other fields on various topics.62-67 These empirical evaluations have
highlighted that industry-sponsored systematic reviews often reach more
favorable conclusions than other systematic reviews, even though they
use the same primary data.62,64 Differential use of selection criteria for
eligible studies or choice of data or of synthesis methods may also serve to
create favorable final inferences.62-67 Some prominent examples include
neuraminidase inhibitors,65 menopausal hormone treatment,66 and hy-
droxyethyl starch.67 Systematic reviews and meta-analyses can become
partisan tools for expressing biased opinion sprinkled with evidence,
almost like biased editorials68 or biased expert guidelines.69,70 In fact,
conflicted expert guidelines often use conflicted systematic reviews and
meta-analyses, and the messages are further propagated by conflicted ex-
pert editorials. Meta-analyses, guidelines, and editorials may all become
 Mass Production of Systematic Reviews and Meta-analyses
497
instruments spreading the same bias to different readers who are more
influenced by one or another type of article.
Chinese Meta-analyses, Especially
of Genetic Associations
Another way to look at the increase of systematic reviews and meta-
analyses is to examine their geographic provenance to understand which
countries are mostly responsible for the rapid growth of this factory.
In 2014, of the 9,135 articles classified as “meta-analyses” in PubMed,
over a third (n = 3,150, 34%) have author affiliations from China,
making China the most prolific producer of English-language, PubMed-
indexed meta-analyses. The United States is a remote second with only
822 meta-analyses (9%). A dramatic change in the geography of meta-
analysis happened in a very short period of time. In 2005, meta-analyses
from China were rare, and meta-analyses from the United States were
more than 15 times more common (n = 539 from the United States vs
n = 33 from China). By 2012 China had surpassed the United States in
production. Currently, China is publishing 4 times more meta-analyses
than the United States, and the gap continues to widen. This is a change
of epidemic proportions (Figure 2).
An empirical evaluation published in 2013 tried to understand what
was driving this rapid growth.71 The rise of meta-analyses from China
pertains to all types of meta-analyses, including those of randomized tri-
als, epidemiological studies, diagnostic test studies, and any other kind of
design. This trend has continued in the time since that empirical evalua-
tion; for example, in 2014, among meta-analyses of trials and treatments
(those identified with the search string “trial* OR randomi* OR treat-
ment*”), 27% of the total come from China. The strong impetus of China
to become a major power in biomedical research (and beyond), the in-
centives to publish in English-language and PubMed-indexed journals,
and the large numbers of emerging Chinese authors have buttressed
this epidemic growth. The share of China in meta-analyses has been
growing much faster than in other types of publications, for example,
trials, epidemiological studies, or bench research.71 Perhaps the reasons
for this are that meta-analyses can be done with little or no money;
they have acquired large impact and importance for biomedicine and
health care as the top of the pyramid in most hierarchies of evidence72;
 498
J.P.A. Ioannidis
Figure 2. Number of PubMed-Indexed Articles Published Each Year Between 2005 and 2014 That Carry the Tag
“Meta-analysis” for Type of Publication and Have Author Affiliations From China or From the United States (USA)
0
500
1000
1500
2000
2500
3000
3500
2005
2006
2007
2008
2009
2010
2011
2012
2013
2014
Meta-analyses from China
Meta-analyses from USA
 Mass Production of Systematic Reviews and Meta-analyses
499
they can be published in prestigious journals; and they are often heavily
cited.73
Interestingly, the most spectacular rise of Chinese meta-analyses has
occurred in the field of genetics.71 The search string “gene OR genetic
OR polymorphism OR genome OR mutation OR haplotype” was used
to identify such articles. By mid-2012, China was already producing
about half of all such meta-analyses.71 In 2014, China published 1,210
such genetic meta-analysis articles out of a global total of 1,910, that is,
63% of the global production, while the United States published only
136 (7%) (Figure 3).
The empirical evaluation71 examined more closely these articles from
China. At face value they looked excellent; that is, their reporting was
done appropriately, with careful tabulations, and publication venues
were respectable English-language journals. However, almost all of them
are likely to have reached misleading conclusions. The reason is that they
used the same recipe (now mostly abandoned) that led to many thousands
of articles with misleading results by American and European teams in
the 1990s and early 2000s: candidate gene studies with single or a few
genes and variants addressed one at a time, by single teams, with small
sample sizes, and with fragmented reporting of the literature subject
to publication bias. Meta-analyses collating such studies almost always
give nominally statistically significant results at p < 0.05, but this
means very little based on what is known in the current era of genomics.
In fact, almost 99% of these claimed associations were not validated
when tested in very large consortia with very large sample sizes and no
selective reporting, where the entire genome was assessed.74
Production of Meta-analyses
by Contractors
Another group that is apparently involved in massive production of
meta-analyses is contractors. Many contracting companies have emerged
in the last 15 years operating in the domain of evidence synthesis.
Some examples of such contractors include the Mapi Group, Abacus
International, Evidera, and Precision for Value. These companies are
contracted mostly by pharmaceutical and medical device industries to
run meta-analyses for them. These industries are highly interested in
such evidence synthesis tools for the reasons described above but also
 500
J.P.A. Ioannidis
Figure 3. Number of PubMed-Indexed Articles Published Each Year Between 2005 and 2014 That Carry the Tag “Meta-
analysis” for Type of Publication, Have Author Affiliations From China or From the United States, and Are Identified by the
Search String “gene OR genetic OR polymorphism OR genome OR mutation OR haplotype”a
0
200
400
600
800
1000
1200
1400
2005
2006
2007
2008
2009
2010
2011
2012
2013
2014
Gene�c meta-analyses from China
Gene�c meta-analyses from the United States
aSame search strategy as in Ioannidis and colleagues.71
 Mass Production of Systematic Reviews and Meta-analyses
501
as a means to obtain extra insights about the relative merits of their
products and of those manufactured by competitors. The contracts
pay very well, and the meta-analyses are done professionally and at
high efficiency, often using advanced techniques, for example, network
meta-analysis.75
In contrast to Chinese genetic meta-analyses, much of the time there is
little or no incentive to publish the results of contractor-produced meta-
analyses. Publication takes time and effort to prepare the manuscript
and then go through painful reviews and revisions, while contractors
can instead spend their time working on other contracts. Moreover,
pharmaceutical and medical device corporations may not wish to dis-
close the results of some meta-analyses, especially if the results are not
favorable for their sponsored products. Some contractors may take pride
that they have done and published numerous meta-analyses, a proof of
professional skill. However, others may not place emphasis on their pub-
lication record. To my knowledge, there are no contractors that claim
that they must publish all the meta-analyses they perform. To do oth-
erwise might easily discourage many, if not all, industry clients. The
extent to which these practices may introduce publication bias in meta-
analyses, specifically in meta-analyses addressing the effectiveness and
safety of interventions, is unknown and requires more empirical study.
Flawed Meta-analyses and Correct
but Noninformative Meta-analyses
Numerous empirical evaluations have addressed the prevalence of flaws
in the design, conduct, analysis, and reporting of published systematic
reviews and meta-analyses in diverse disciplines.76-82 Their discussion
goes beyond the goals of this article, but overall, the results of these
empirical assessments suggest that low quality and major flaws are very
common. Preregistration of full protocols has been proposed as a means
to improve transparency and perhaps also to help increase the quality
of these studies. However, only a small fraction of systematic reviews
(perhaps 10%-20%) are recorded in registers such as PROSPERO before
they start.83-85 Moreover, given that published data are already available,
it is questionable whether a retrospective systematic review can really
ever be truly preregistered as the studies and data to be reviewed and
combined are already in public view. Furthermore, systematic review
 502
J.P.A. Ioannidis
Figure 4. A Summary Overview of Currently Produced Meta-analyses
Unpublished
Redundant and 
unnecessary
Decent, but not 
useful
Misleading, 
abandoned 
gene�cs
Flawed beyond 
repair
20%
Decent and 
clinically useful
3%
20%
27%
 17%
13%
preregistration does not guarantee that the protocol is complete, let alone
that the methods used are appropriate and that the conduct, analyses,
and reporting are not flawed, even if the protocol is correct.
Finally, even when systematic reviews and meta-analyses are well done
and have none of the problems mentioned above, most may still not be
informative. A very common conclusion, in particular for meta-analyses
of randomized trials, is that the evidence is weak or insufficient; thus,
the review is not informative on what the best interventions are in terms
of patient care or health policy.86-88
Conclusion
Figure 4 summarizes the current production of meta-analyses in
biomedicine and compiles data from PubMed searches and the other
evidence presented above in this article.
 Mass Production of Systematic Reviews and Meta-analyses
503
As mentioned above, 9,135 meta-analyses were published and in-
dexed in PubMed in 2014. The numbers for systematic reviews are
probably more than threefold (n = 28,959 in 2014 using the “system-
atic review” search tag in PubMed). One may debate whether all of
these articles are really systematic reviews since the extent to which
they follow systematic methods for searching and integrating evidence
can vary. For example, Moher and colleagues89 estimated the number
of stringently defined systematic reviews published in 2004 as approx-
imately 2,500, while the PubMed search tag for “systematic review”
gives 8,989 items for the same year. Meta-analyses can be defined and
counted with more consistency; for example, the PubMed search tag
for “meta-analysis” gives 1,594 published meta-analyses in 2004, as
opposed to approximately 1,300 estimated by Moher and colleagues,89
who excluded articles without systematic literature searches (eg, pooled
analyses of individual-level data on some drug[s] by the pharmaceutical
industry). In an updated evaluation by Page et al.,90 published while the
current paper was copyedited, an estimated 8,000 systematic reviews
and more than 5,000 meta-analyses published in 2014 using the same
criteria as in the 2004 evaluation. The following estimates presented
here thus focus on meta-analyses.
The number of unpublished meta-analyses is unknown. In theory,
as discussed, meta-analyses are attractive to publish, but even large
randomized trials (which are also very attractive to publish) have non-
publication rates exceeding 30%.91,92 Moreover, as mentioned above,
there is a large number of contractors performing meta-analyses without
any incentive to publish. Therefore, a minimum 20% nonpublication
rate for produced meta-analyses may be speculated. The rate may be
higher for systematic reviews that lack the quantitative attraction of
meta-analyses. Analyses of registry data may offer insights into non-
publication rates for systematic reviews and meta-analyses but may still
be biased (registered protocols are more likely to be pursued for pub-
lication). At least 1 survey of authors suggested that non-publication
of systematic reviews was common,93 and another empirical evaluation
showed that even for Cochrane systematic reviews, 19% remained un-
published 8 years after their protocol had been drafted.94
Of the published meta-analyses, as discussed above, about 1 in 6 are
largely misleading meta-analyses of genetics literature (mostly published
by China); probably another 1 in 3 are redundant, unnecessary meta-
analyses of other research types. Of the remaining, about half have
 504
J.P.A. Ioannidis
serious methodological flaws, and many others are decent but have
noninformative evidence. Good and truly informative meta-analyses are
a small minority (see Figure 4).
Despite the unfavorable evidence presented above, systematic reviews
and meta-analyses can still have major value. Actually, their credibility
and utility are probably better than almost any other type of biomedi-
cal article published (other than large randomized trials).95 Under ideal
circumstances, these systematic tools can inform about what is known
and what is not known with appropriate representation of the accompa-
nying uncertainty. Under non-ideal circumstances, the main utility of
systematic reviews and meta-analyses, conversely, has been to reveal how
unreliable published evidence is. This is still an important mission, and
these tools have been repeatedly put to good use to probe various biases in
single topics and across many topics of interest in meta-epidemiological
studies.96,97
The pervasive documentation of bias suggests that more should be
done to improve the quality of the primary evidence rather than ex-
pect systematic reviews to correct deficiencies after the fact. Systematic
reviews have currently become a high-output factory where very dif-
ferent stakeholders with various motives are involved: methodologists,
academics, scholars, policymakers, health care professionals, altruistic
volunteers, eager authorship-seekers, serious business professionals, and
many others who may see systematic reviews as marketing tools. Some
methodologists are working on how to make this factory even more
prolific, for example, by creating software and automata that stream-
line the meta-analysis production process.98 This technological facili-
tation may be a nice contribution for those interested in performing
rigorous reviews, but it may also make things worse in the hands of
those who are not concerned about high quality. The process of con-
ducting poor-quality systematic reviews is already easy enough to sub-
vert evidence synthesis in massive scale. Moreover, many clinicians,
researchers, and editors who read these reviews are not knowledgeable
as to how to differentiate between high- and low-quality systematic
reviews, and some biases may evade the attention of even experienced
methodologists.
A major overhaul is needed on the generation of biomedical evi-
dence and its credible synthesis. Eventually, prospective meta-analyses
designed and conducted by nonconflicted investigators may need to
become the key type of primary research. Production of primary data,
 Mass Production of Systematic Reviews and Meta-analyses
505
teamwork, replication, and meta-analyses can be integrally connected,
as in the case of human genome epidemiology consortia.5 Simply
expecting fragments to be pieced together retrospectively with sub-
jective choices may not be the best option. However, it is unlikely that
all research agendas can be preemptively prespecified. Thus, the need for
well-done, reliable retrospective systematic reviews and meta-analyses as
secondary research is unlikely to disappear. More widespread availabil-
ity and sharing of individual-level data,58,99,100 better enforcement of
study preregistration and accessibility of study results (eg, for random-
ized trials),101,102 transparent and complete reporting of analyses and
of all major (core) outcomes,103-105 and increased funding and promo-
tion incentives to improve reproducible research practices106 may reduce
biases in the available information that is synthesized by systematic re-
views and meta-analyses. The question of who should be the authors
and sponsors of systematic reviews and meta-analyses also remains open.
The same applies to whether conflicts of interest can be tolerated (if they
are transparently reported) or should be avoided altogether, as has been
proposed for guidelines.70
A large number of stakeholders may influence some of these dis-
cussed policy changes. There have been several efforts that have tried
to set standards for systematic reviews and meta-analyses not only for
the reporting level of their results107,108 but also their protocols,109 and
overall design and conduct.110 While these standards may improve some
aspects of systematic reviews and meta-analyses, they do not yet cover
all their applications. Moreover, there is a need to move beyond single
systematic reviews and meta-analyses and to focus on the big picture
of the research agenda and the massive, often redundant and conflicted,
production of these influential articles. The culture of research-funding
bureaucracy in some countries may sometimes complicate matters fur-
ther, and elected officials who control funding agencies may have little
or no knowledge and understanding of the importance of and the is-
sues involved in systematic reviews and meta-analyses. It is difficult
to identify all the dishonest, or just greedy, or simply incompetent
people who can somehow corrupt the process of prioritizing and com-
missioning reviews. Major progress may require more concerted action
among key stakeholders such as journals, funders, elected officials con-
trolling funding agencies, institutions, scientists, physicians, and pa-
tients, who should appreciate the pivotal role of systematic reviews and
 506
J.P.A. Ioannidis
meta-analyses and not compromise for less quality, accountability, and
transparency.
References
1.
Ioannidis JP. Meta-research: the art of getting it wrong. Res Synth
Methods. 2010;1(3-4):169-184.
2.
Greenhalgh T, Howick J, Maskrey N; Evidence Based Medicine
Renaissance Group. Evidence based medicine: a movement in
crisis? BMJ. 2014;348:g3725.
3.
Every-Palmer S, Howick J. How evidence-based medicine is fail-
ing due to biased trials and selective publication. J Eval Clin
Pract. 2014;20(6):908-914.
4.
Finckh A, Tram`
er MR. Primer: strengths and weaknesses of meta-
analysis. Nat Clin Pract Rheumatol. 2008;4(3):146-152.
5.
Panagiotou OA, Willer CJ, Hirschhorn JN, Ioannidis JP. The
power of meta-analysis in genome-wide association studies. Annu
Rev Genomics Hum Genet. 2013;14:441-465.
6.
Margiti´
c SE, Morgan TM, Sager MA, Furberg CD. Lessons
learned from a prospective meta-analysis. J Am Geriatr Soc.
1995;43(4):435-439.
7.
Turok DK, Espey E, Edelman AB, et al. The methodology for
developing a prospective meta-analysis in the family planning
community. Trials. 2011;12:104.
8.
Clarke M, Alderson P, Chalmers I. Discussion sections in reports
of controlled trials published in general medical journals. JAMA.
2002;287(21):2799-2801.
9.
Macleod MR, Michie S, Roberts I, et al. Biomedical research:
increasing value, reducing waste. Lancet. 2014;383(9912):101-
104.
10.
Mulrow CD. The medical review article: state of the science. Ann
Intern Med. 1987;106(3):485-488.
11.
Olkin I. Meta-analysis: current issues in research synthesis. Stat
Med. 1996;15(12):1253-1257; discussion 1259-1262.
12.
Antman EM, Lau J, Kupelnick B, Mosteller F, Chalmers
TC. A comparison of results of meta-analyses of random-
ized control trials and recommendations of clinical experts.
Treatments for myocardial infarction. JAMA. 1992;268(2):240-
248.
13.
Lau J, Antman EM, Jimenez-Silva J, Kupelnick B, Mosteller F,
Chalmers TC. Cumulative meta-analysis of therapeutic trials for
myocardial infarction. N Engl J Med. 1992;327(4):248-254.
 Mass Production of Systematic Reviews and Meta-analyses
507
14.
Iqbal SA, Wallach JD, Khoury MJ, Schully SD, Ioannidis JP. Re-
producible research practices and transparency across the biomed-
ical literature. PLoS Biol. 2016;14(1):e1002333.
15.
Ioannidis JP, Boyack KW, Small H, Sorensen AA, Klavans
R. Bibliometrics: is your most cited work your best? Nature.
2014;514(7524):561-562.
16.
Serghiou S, Patel CJ, Tan YY, Koay P, Ioannidis JP.
Field-wide meta-analyses of observational associations can
map selective availability of risk factors and the impact of
model specifications. J Clin Epidemiol. September 25, 2015.
doi:10.1016/j.jclinepi.2015.09.004. [Epub ahead of print.]
17.
Merton RK. The Sociology of Science: Theoretical and Empirical Inves-
tigations. Chicago, IL: University of Chicago Press; 1973.
18.
Sena ES, van der Worp HB, Bath PM, Howells DW, Macleod
MR. Publication bias in reports of animal stroke studies leads to
major overstatement of efficacy. PLoS Biol. 2010;8(3):e1000344.
19.
Crossley NA, Sena E, Goehler J, et al. Empirical evidence of bias
in the design of experimental stroke studies: a metaepidemiologic
approach. Stroke. 2008;39(3):929-934.
20.
Tsilidis KK, Panagiotou OA, Sena ES, et al. Evaluation of excess
significance bias in animal studies of neurological diseases. PLoS
Biol. 2013;11(7):e1001609.
21.
Hirst JA, Howick J, Aronson JK, et al. The need for random-
ization in animal trials: an overview of systematic reviews. PLoS
One. 2014;9(6):e98856.
22.
Ioannidis JP, Greenland S, Hlatky MA, et al. Increasing value and
reducing waste in research design, conduct, and analysis. Lancet.
2014;383(9912):166-175.
23.
Woodruff TJ, Sutton P; Navigation Guide Work Group. An
evidence-based medicine methodology to bridge the gap between
clinical and environmental health sciences. Health Aff (Millwood).
2011;30(5):931-937.
24.
Krauth D, Woodruff TJ, Bero L. Instruments for assessing risk of
bias and other methodological criteria of published animal stud-
ies: a systematic review. Environ Health Perspect. 2013;121(9):985-
992.
25.
Mueller KF, Briel M, Strech D, et al. Dissemination bias in
systematic reviews of animal research: a systematic review. PLoS
One. 2014;9(12):e116016.
26.
van Luijk J, Bakker B, Rovers MM, Ritskes-Hoitinga M, de
Vries RB, Leenaars M. Systematic reviews of animal studies;
missing link in translational research? PLoS One. 2014;9(3):
e89981.
 508
J.P.A. Ioannidis
27.
Prinz F, Schlange T, Asadullah K. Believe it or not: how much
can we rely on published data on potential drug targets? Nat Rev
Drug Discov. 2011;10(9):712.
28.
Begley CG, Ellis LM. Drug development: raise standards for
preclinical cancer research. Nature. 2012;483(7391):531-533.
29.
Cuatrecasas P. Drug discovery in jeopardy. J Clin Invest.
2006;116(11):2837-2842.
30.
Chalmers I. The Cochrane Collaboration: preparing, maintaining,
and disseminating systematic reviews of the effects of health care.
Ann N Y Acad Sci. 1993;703:156-163; discussion 163-165.
31.
Levin A. The Cochrane Collaboration. Ann Intern Med. 2001;
135(4):309-312.
32.
Jadad AR, Cook DJ, Jones A, et al. Methodology and reports of
systematic reviews and meta-analyses: a comparison of Cochrane
reviews with articles published in paper-based journals. JAMA.
1998;280(3):278-280.
33.
Shea B, Moher D, Graham I, Pham B, Tugwell P. A comparison
of the quality of Cochrane reviews and systematic reviews pub-
lished in paper-based journals. Eval Health Prof. 2002;25(1):116-
129.
34.
Fleming PS, Seehra J, Polychronopoulou A, Fedorowicz Z, Pan-
dis N. Cochrane and non-Cochrane systematic reviews in lead-
ing orthodontic journals: a quality paradigm? Eur J Orthod.
2013;35(2):244-248.
35.
Mallett S, Clarke M. How many Cochrane reviews are needed to
cover existing evidence on the effects of health care interventions?
ACP J Club. 2003;139(1):A11.
36.
Bastian H, Glasziou P, Chalmers I. Seventy-five trials and eleven
systematic reviews a day: how will we ever keep up? PLoS Med.
2010;7(9):e1000326.
37.
Siontis KC, Hernandez-Boussard T, Ioannidis JP. Overlapping
meta-analyses on the same topic: survey of published studies.
BMJ. 2013;347:f4501.
38.
Krumholz H. The case for duplication of meta-analyses and sys-
tematic reviews. BMJ. 2013;347:f5506.
39.
Zorzela L, Golder S, Liu Y, et al. Quality of reporting in
systematic reviews of adverse events: systematic review. BMJ.
2014;348:f7668.
40.
Ebrahim S, Montoya L, el Din MK, et al. Secondary publications
from randomized controlled trials: a meta-epidemiological study.
J Clin Epidemiol. In press.
41.
Jadad AR, Cook DJ, Browman GP. A guide to interpreting
discordant systematic reviews. CMAJ. 1997;156(10):1411-1416.
 Mass Production of Systematic Reviews and Meta-analyses
509
42.
Cook DJ, Reeve BK, Guyatt GH, et al. Stress ulcer prophylaxis in
critically ill patients. Resolving discordant meta-analyses. JAMA.
1996;275(4):308-314.
43.
Druyts E, Thorlund K, Humphreys S, Lion M, Cooper CL, Mills
EJ. Interpreting discordant indirect and multiple treatment com-
parison meta-analyses: an evaluation of direct acting antivirals for
chronic hepatitis C infection. Clin Epidemiol. 2013;5:173-183.
44.
Vamvakas EC. Why have meta-analyses of randomized controlled
trials of the association between non-white-blood-cell-reduced
allogeneic blood transfusion and postoperative infection produced
discordant results? Vox Sang. 2007;93(3):196-207.
45.
Horrobin DF. Beyond conflict of interest. Non-financial con-
flicts of interest are more serious than financial conflicts. BMJ.
1999;318(7181):466.
46.
Gøtzsche PC, Ioannidis JP. Content area experts as authors: help-
ful or harmful for systematic reviews and meta-analyses? BMJ.
2012;345:e7031.
47.
Sox HC, Rennie D. Seeding trials: just say “no.” Ann Intern Med.
2008;149(4):279-280.
48.
Handel AE, Patel SV, Pakpoor J, Ebers GC, Goldacre B,
Ramagopalan SV. High reprint orders in medical journals
and pharmaceutical industry funding: case-control study. BMJ.
2012;344:e4212.
49.
Ioannidis JP. Effectiveness of antidepressants: an evidence myth
constructed from a thousand randomized trials? Philos Ethics Hu-
manit Med. 2008;3:14.
50.
Ioannidis JP. Ranking antidepressants. Lancet. 2009;373(9677):
1759-1760; author reply 1761-1762.
51.
Gartlehner G, Hansen RA, Morgan LC, et al. Comparative ben-
efits and harms of second-generation antidepressants for treating
major depressive disorder: an updated meta-analysis. Ann Intern
Med. 2011;155(11):772-785.
52.
Cipriani A, Furukawa TA, Salanti G, et al. Comparative effi-
cacy and acceptability of 12 new-generation antidepressants: a
multiple-treatments meta-analysis. Lancet. 2009;373(9665):746-
758.
53.
Turner EH, Matthews AM, Linardatos E, Tell RA, Rosenthal R.
Selective publication of antidepressant trials and its influence on
apparent efficacy. N Engl J Med. 2008;358(3):252-260.
54.
Le Noury J, Nardo JM, Healy D, et al. Restoring Study 329:
efficacy and harms of paroxetine and imipramine in treatment of
major depression in adolescence. BMJ. 2015;351:h4320.
 510
J.P.A. Ioannidis
55.
Ebrahim S, Sohani ZN, Montoya L, et al. Reanalyses of random-
ized clinical trial data. JAMA. 2014;312(10):1024-1032.
56.
Jefferson T, Jones M, Doshi P, Spencer EA, Onakpoya I,
Heneghan CJ. Oseltamivir for influenza in adults and children:
systematic review of clinical study reports and summary of regu-
latory comments. BMJ. 2014;348:g2545.
57.
Jefferson T, Doshi P. Multisystem failure: the story of anti-
influenza drugs. BMJ. 2014;348:g2263.
58.
Ross JS, Krumholz HM. Ushering in a new era of open sci-
ence through data sharing: the wall must come down. JAMA.
2013;309(13):1355-1356.
59.
Ebrahim S, Bance S, Athale A, Malachowski C, Ioannidis JP.
Meta-analyses with industry involvement are massively pub-
lished and report no caveats for antidepressants. J Clin Epidemiol.
September 20, 2015. doi:10.1016/j.jclinepi.2015.08.021. [Epub
ahead of print.]
60.
Antidepressants and suicide. The history of a controversy–and
where it stands today. Harv Ment Health Lett. 2007;24(1):1-4.
61.
Haidich AB, Pilalas D, Contopoulos-Ioannidis DG, Ioannidis JP.
Most meta-analyses of drug interventions have narrow scopes and
many focus on specific agents. J Clin Epidemiol. 2013;66(4):371-
378.
62.
Jørgensen AW, Maric KL, Tendal B, Faurschou A, Gøtzsche PC.
Industry-supported meta-analyses compared with meta-analyses
with non-profitorno support:differencesin methodological qual-
ity and conclusions. BMC Med Res Methodol. 2008;8:60.
63.
Jørgensen AW, Hilden J, Gøtzsche PC. Cochrane reviews com-
pared with industry supported meta-analyses and other meta-
analyses of the same drugs: systematic review. BMJ. 2006;
333:782.
64.
Yank V, Rennie D, Bero LA. Financial ties and concordance
between results and conclusions in meta-analyses: retrospective
cohort study. BMJ. 2007;335:1202-1205.
65.
Dunn AG, Arachi D, Hudgins J, Tsafnat G, Coiera E, Bour-
geois FT. Financial conflicts of interest and conclusions about
neuraminidase inhibitors for influenza: an analysis of systematic
reviews. Ann Intern Med. 2014;161:513-518.
66.
Fugh-Berman A, McDonald CP, Bell AM, Bethards EC, Scialli
AR. Promotional tone in reviews of menopausal hormone therapy
after the Women’s Health Initiative: an analysis of published
articles. PLoS Med. 2011;8:e1000425.
67.
Hartog CS, Skupin H, Natanson C, Sun J, Reinhart K. Systematic
analysis of hydroxyethyl starch (HES) reviews: proliferation of
 Mass Production of Systematic Reviews and Meta-analyses
511
low-quality reviews overwhelms the results of well-performed
meta-analyses. Intensive Care Med. 2012;38:1258-1271.
68.
Tatsioni A, Siontis GC, Ioannidis JP. Partisan perspectives in the
medical literature: a study of high frequency editorialists favoring
hormone replacement therapy. J Gen Intern Med. 2010;25:914-
919.
69.
Lenzer J, Hoffman JR, Furberg CD, Ioannidis JP; Guideline
Panel Review Working Group. Ensuring the integrity of clin-
ical practice guidelines: a tool for protecting patients. BMJ.
2013;347:f5535.
70.
Lenzer J. Why we can’t trust clinical guidelines. BMJ. 2013;
346:f3830.
71.
Ioannidis JP, Chang CQ, Lam TK, Schully SD, Khoury MJ. The
geometric increase in meta-analyses from China in the genomic
era. PLoS One. 2013;8(6):e65602.
72.
Owens DK, Lohr KN, Atkins D, et al. AHRQ Series Paper
5: grading the strength of a body of evidence when compar-
ing medical interventions—Agency for Healthcare Research and
Quality and the Effective Health-Care Program. J Clin Epidemiol.
2010;63(5):513-523.
73.
Patsopoulos NA, Analatos AA, Ioannidis JP. Relative citation
impact of various study designs in the health sciences. JAMA.
2005;293(19):2362-2366.
74.
Ioannidis JP, Tarone R, McLaughlin JK. The false-positive
to false-negative ratio in epidemiologic studies. Epidemiology.
2011;22(4):450-456.
75.
Salanti G, Del Giovane C, Chaimani A, Caldwell DM, Higgins
JP. Evaluating the quality of evidence from a network meta-
analysis. PLoS One. 2014;9(7):e99682.
76.
Dixon E, Hameed M, Sutherland F, Cook DJ, Doig C. Evalu-
ating meta-analyses in the general surgical literature: a critical
appraisal. Ann Surg. 2005;241(3):450-459.
77.
Delaney A, Bagshaw SM, Ferland A, Manns B, Laupland KB,
Doig CJ. A systematic evaluation of the quality of meta-analyses
in the critical care literature. Crit Care. 2005;9(5):R575-582.
78.
Rudmik LR, Walen SG, Dixon E, Dort J. Evaluation of meta-
analyses in the otolaryngological literature. Otolaryngol Head Neck
Surg. 2008;139(2):187-194.
79.
Dijkman BG, Abouali JA, Kooistra BW, et al. Twenty years of
meta-analyses in orthopaedic surgery: has quality kept up with
quantity? J Bone Joint Surg Am. 2010;92(1):48-57.
 512
J.P.A. Ioannidis
80.
Bhandari M, Morrow F, Kulkarni AV, Tornetta P III. Meta-
analyses in orthopaedic surgery. A systematic review of their
methodologies. J Bone Joint Surg Am. 2001;83-A(1):15-24.
81.
Jadad AR, Moher M, Browman GP, et al. Systematic reviews and
meta-analyses on treatment of asthma: critical evaluation. BMJ.
2000;320(7234):537-540.
82.
Jadad AR, McQuay HJ. Meta-analyses to evaluate analgesic in-
terventions: a systematic qualitative review of their methodology.
J Clin Epidemiol. 1996;49(2):235-243.
83.
Booth A, Stewart L. Trusting researchers to use open trial reg-
isters such as PROSPERO responsibly. BMJ. 2013;347:f5870.
doi:10.1136/bmj.f5870.
84.
Booth A, Clarke M, Dooley G, et al. The nuts and bolts of
PROSPERO: an international prospective register of systematic
reviews. Syst Rev. 2012;1:2.
85.
Booth A, Clarke M, Dooley G, et al. PROSPERO at one year: an
evaluation of its utility. Syst Rev. 2013;2:4.
86.
Wee B, Hadley G, Derry S. How useful are systematic reviews
for informing palliative care practice? Survey of 25 Cochrane
systematic reviews. BMC Palliat Care. 2008;7:13.
87.
Ezzo J, Bausell B, Moerman DE, Berman B, Hadhazy V. Re-
viewing the reviews. How strong is the evidence? How clear are
the conclusions? Int J Technol Assess Health Care. 2001;17(4):457-
466.
88.
Bader J, Ismail A; ADA Council on Scientific Affairs; Divi-
sion of Science; Journal of the American Dental Association.
Survey of systematic reviews in dentistry. J Am Dent Assoc.
2004;135(4):464-473.
89.
Moher D, Tetzlaff J, Tricco AC, Sampson M, Altman DG. Epi-
demiology and reporting characteristics of systematic reviews.
PLoS Med. 2007;4(3):e78.
90.
Page MJ, Shamseer L, Altman DG, et al. Epidemiology and
reporting characteristics of systematic reviews of biomedical re-
search: a cross-sectional study. PLoS Med. 2016;13(5):e1002028.
91.
Ross JS, Tse T, Zarin DA, Xu H, Zhou L, Krumholz HM. Publi-
cation of NIH funded trials registered in ClinicalTrials.gov: cross
sectional analysis. BMJ. 2012;344:d7292.
92.
Gordon D, Taddei-Peters W, Mascette A, Antman M, Kaufmann
PG, Lauer MS. Publication of trials funded by the National Heart,
Lung, and Blood Institute. N Engl J Med. 2013;369(20):1926-
1934.
 Mass Production of Systematic Reviews and Meta-analyses
513
93.
Tricco AC, Pham B, Brehaut J, et al. An international survey indi-
cated that unpublished systematic reviews exist. J Clin Epidemiol.
2009;62(6):617-623.e5.
94.
Tricco AC, Brehaut J, Chen MH, Moher D. Following 411
Cochrane protocols to completion: a retrospective cohort study.
PLoS One. 2008;3(11):e3684.
95.
Ioannidis JP. Why most published research findings are false.
PLoS Med. 2005;2(8):e124.
96.
Sterne JA, J¨
uni P, Schulz KF, Altman DG, Bartlett C, Egger M.
Statistical methods for assessing the influence of study charac-
teristics on treatment effects in ‘meta-epidemiological’ research.
Stat Med. 2002;21(11):1513-1524.
97.
Savovi´
c J, Harris RJ, Wood L, et al. Development of a combined
database for meta-epidemiological research. Res Synth Methods.
2010;1(3-4):212-225.
98.
Tsafnat G, Dunn A, Glasziou P, Coiera E. The automation of
systematic reviews. BMJ. 2013;346:f139.
99.
Krumholz HM. Why data sharing should be the expected norm.
BMJ. 2015;350:h599.
100.
Krumholz HM, Gross CP, Blount KL, et al. Sea change in open
science and data sharing: leadership by industry. Circ Cardiovasc
Qual Outcomes. 2014;7(4):499-504.
101.
Zarin DA, Tse T, Sheehan J. The proposed rule for U.S. clin-
ical trial registration and results submission. N Engl J Med.
2015;372(2):174-180.
102.
Zarin DA, Tse T. Trust but verify: trial registration and deter-
mining fidelity to the protocol. Ann Intern Med. 2013;159(1):
65-67.
103.
Gargon E, Williamson PR, Altman DG, Blazeby JM, Clarke M.
The COMET Initiative database: progress and activities update
(2014). Trials. 2015;16(1):515.
104.
Ioannidis JP, Horbar JD, Ovelman CM, et al. Completeness of
main outcomes across randomized trials in entire discipline: sur-
vey of chronic lung disease outcomes in preterm infants. BMJ.
2015;350:h72.
105.
Williamson P, Clarke M. The COMET (Core Outcome Measures
in Effectiveness Trials) Initiative: its role in improving Cochrane
reviews. Cochrane Database Syst Rev. 2012;5:ED000041.
106.
Ioannidis JP. How to make more published research true. PLoS
Med. 2014;11(10):e1001747.
107.
Liberati A, Altman DG, Tetzlaff J, et al. The PRISMA statement
for reporting systematic reviews and meta-analyses of studies that
 514
J.P.A. Ioannidis
evaluate health care interventions: explanation and elaboration.
Ann Intern Med. 2009;151(4):W65-94.
108.
Hutton B, Salanti G, Caldwell DM, et al. The PRISMA exten-
sion statement for reporting of systematic reviews incorporating
network meta-analyses of health care interventions: checklist and
explanations. Ann Intern Med. 2015;162(11):777-784.
109.
Shamseer L, Moher D, Clarke M, et al. Preferred Reporting Items
for Systematic Review and Meta-analysis Protocols (PRISMA-P)
2015: elaboration and explanation. BMJ. 2015;349:g7647.
110.
Institute of Medicine. Finding What Works in Health Care: Stan-
dards for Systematic Reviews. Washington, DC: National Academies
Press; 2011.
Funding/Support:
The work of John Ioannidis is supported by an unrestricted
gift from Sue and Bob O’Donnell. METRICS is supported by a grant from the
Laura and John Arnold Foundation.
Conflict of Interest Disclosures: The author completed and submitted the ICMJE
Form for Disclosure of Potential Conflicts of Interest. No disclosures were
reported.
Acknowledgments: This article was built using as the nidus a plenary talk at the
Cochrane Colloquium in Vienna, October 2015.
Address correspondence to: John P.A. Ioannidis, Meta-Research Innovation Cen-
ter at Stanford, 1265 Welch Rd, MSOB X306, Stanford, CA 94305 (email:
jioannid@stanford.edu).
