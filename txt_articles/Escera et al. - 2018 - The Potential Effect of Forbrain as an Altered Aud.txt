 JSLHR
Research Article
The Potential Effect of Forbrain as an
Altered Auditory Feedback Device
Carles Escera,a,b,c Fran López-Caballero,a,b and Natàlia Gorina-Caretaa,b,c
Purpose: The purpose of this study was to run a proof of
concept on a new commercially available device, Forbrain®
(Sound For Life Ltd/Soundev, Luxemburg, model UN38.3),
to test whether it can modulate the speech of its users.
Method: Participants were instructed to read aloud a text
of their choice during 3 experimental phases: baseline, test,
and posttest, while wearing a Forbrain® headset. Critically,
for half of the participants (Forbrain group), the device was
turned on during the test phase, whereas for the other half
(control group), the device was kept off. Voice recordings
were analyzed to derive 6 quantitative measures of voice
quality over each of the phases of the experiment.
Results: A significant Group × Phase interaction was
obtained for the smoothed cepstral peak prominence,
a measure of voice harmony, and for the trendline of
the long-term average spectrum, a measure of voice
robustness, this latter surviving Bonferroni correction for
multiple comparisons.
Conclusions: The results of this study indicate the
effectiveness of Forbrain® in modifying the speech of its
users. It is suggested that Forbrain® works as an altered
auditory feedback device. It may hence be used as a
clinical device in speech therapy clinics, yet further studies
are warranted to test its usefulness in clinical groups.
T
here is increasing evidence that a range of speech,
language, and communication disorders may
involve central auditory processing deficits. These
conditions include dyslexia (Ahissar, Lubin, Putter-Katz, &
Banai, 2006; Hämäläinen, Salminen, & Leppänen, 2013),
specific language impairment (Miller, 2011), speech sound
disorder (SSD; Iliadou, Chermak, & Bamiou, 2015; Murphy,
Pagan-Neves, Wertzner, & Schochat, 2015), and develop-
mental stuttering (Cai et al., 2012; Hampton & Weber-Fox,
2008), among others. Children suffering from these condi-
tions typically show difficulties for sound localization and
discrimination, auditory performance with degraded acoustic
stimuli, dealing with the temporal aspects of the sound
sequence, and generally with auditory discrimination (Miller,
2011). For example, several studies measuring event-related
brain potentials associated with acoustic sound discrimination
have revealed abnormal mismatch negativity (Näätänen,
Paavilainen, Rinne, & Alho, 2007) in dyslexia (Corbera,
Escera, & Artigas, 2006; Halliday, Barry, Hardiman, &
Bishop, 2014) and specific language impairment (Bishop,
Hardiman, & Barry, 2010; Rota-Donahue, Schwartz, Shafer,
& Sussman, 2016), and adults who stutter have been shown
to have abnormal speech sound representation, as revealed
also with the mismatch negativity brain potential (Corbera,
Corral, Escera, & Idiazábal, 2005) in speech-related cerebral
regions with atypical gyrification in these adults (Foundas
et al., 2004). For all these disorders, finding appropriate
treatments is urgent as their consequences span literacy
(Hayiou-Thomas, Carroll, Leavett, Hulme, & Snowling,
2017; Peterson, Pennington, Shriberg, & Boada, 2009),
educational attainment (Olofsson, Taube, & Ahl, 2015),
emotional adjustment (Alexander-Passe, 2008; Iverach &
Rapee, 2014), and social outcomes (Riddick, 2001; Roberts,
Solis, Ciullo, McKenna, & Vaughn, 2015).
It has been suggested that altered auditory feed-
back (AAF) in several of its different forms, such as
masked auditory feedback, delayed auditory feedback,
and frequency-altered feedback (Lincoln, Packman, &
Onslow, 2006), may play an important role in ameliorating
the symptoms of some of these disorders, for example,
in stuttering (Cai et al., 2012; Packman, 2012) and SSD
aBrainlab–Cognitive Neuroscience Research Group, Department
of Clinical Psychology and Psychobiology, University of Barcelona,
Catalonia, Spain
bThe Institute of Neurosciences, University of Barcelona,
Catalonia, Spain
cInstitut de Recerca Sant Joan de Déu (IRSJD), Catalonia, Spain
Correspondence to Carles Escera: cescera@ub.edu
Editor-in-Chief: Julie Liss
Editor: Jack Jiang
Received February 22, 2017
Revision received July 10, 2017
Accepted November 10, 2017
https://doi.org/10.1044/2017_JSLHR-S-17-0072
Disclosure: The present research was sponsored by Sound for Life Ltd (Soundev).
Sound for Life Ltd (Soundev) had, however, no role in the study design; in the
collection, analysis, and interpretation of the data; in the writing of the report; and
in the decision to submit the paper for publication. Solely, the authors had full access
to all data in this study, and the corresponding author takes complete responsibility
for the integrity of the data and the accuracy of the data analysis. None of the authors
has any private, including financial, interest in Soundev for Life Ltd (
Soundev
).
Journal of Speech, Language, and Hearing Research • Vol. 61 • 801–810 • April 2018 • Copyright © 2018 The Authors
This work is licensed under a Creative Commons Attribution 4.0 International License.
801
Downloaded from: https://pubs.asha.org 77.173.35.219 on 06/05/2019, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions 
 (Cummings & Barlow, 2011). Also, other less clinically
used forms of AAF, such as the Lombard effect (Arciuli,
Simpson, Vogel, & Ballard, 2013; Garnier, Henrich, &
Dubois, 2010; Stathopoulos et al., 2014), sidetone amplifi-
cation (Bauer, Mittal, Larson, & Hain, 2006; Garber, Siegel,
& Pick, 1976; Heinks-Maldonado & Houde, 2005), and the
so-called feedback filtering (Burzynski & Starr, 1985; Garber
et al., 1976; Garber, Siegel, & Pick, 1980, 1981), which alter
the speech input in the amplitude domain or in specific
frequency bands, have been shown to affect speech in fluent-
speaking adults and those who stutter (Martin, Siegel,
Johnson, & Haroldson, 1984) and in children with SSD
(Siegel & Kennard, 1984). AAF refers to a range of proce-
dures that, through electronic or digital manipulation, alter
the speaker’s voice so that it is perceived differently from
normal (Fairbanks, 1954; Yates, 1963). Recently, it has
been suggested that these AAF effects may reflect a com-
pensatory motor command on the perceived shift in the
acoustic input on the basis of a predictive internal model
of the expected output (Hahnloser & Narula, 2017; Ostry
& Gribble, 2016), and a candidate brain region to support
these interactions has been proposed, namely, Spt area in the
planum temporale of the left temporal lobe (Hickok, Houde,
& Rong, 2011). Such a compensatory motor command may
result in the retuning of the phono-articulatory loop (Eliades
& Wang, 2008; Keller & Hahnloser, 2009) and might have
consequences on the speaker’s voice (Houde & Jordan, 1998;
Jones & Munhall, 2000). Several commercial AAF devices
are currently available, such as SpeechEasy® by Janus
Development Group (Greenville, NC, USA; Foundas, Mock,
Corey, Golob, & Conture, 2013), SmallTalk® and Basic
Fluency System® from Casa Futura Technologies (Boulder,
CO, USA; Unger, Glück, & Cholewa, 2012) and VA601i
Fluency Enhancer by VoiceAmp Ltd. (Capetown, South
Africa; Unger et al., 2012). Evidence supporting the effects
in treating stuttering or SSD with AAF devices, however,
is equivocal (Foundas et al., 2013; Pollard, Ellis, Finan, &
Ramig, 2009; Ritto, Juste, Stuart, Kalinowksi, & de Andrade,
2016; Stuart, Kalinowski, Rastatter, Saltuklaroglu, & Dayalu,
2004; Stuart, Kalinowski, Saltuklaroglu, & Guntupalli,
2006).
A newly marketed device has become available
recently, which is Forbrain®, developed by Sound For
Life Limited (Soundev) in Luxemburg (model UN38.3;
Europe; http://www.forbrain.com). Forbrain® is a headset
equipped with a microphone and a pair of bone conductors,
which feeds the user back with his or her own voice during
natural speech through bone conduction. According to its
patent registration (Guajarengues & Lohmann, 2015),
Forbrain® implements a dynamic, two-band equalizer filter
(close to a Baxandall equalizer; Baxandall, 1952) that ap-
plies to the voice input either of two different settings. These
two settings are switched to by the user’s voice energy at
1 kHz over a time window of integration ranging 10–200 ms
(see technical description in Method section). The resulting
sound flow, which is altered in its frequency spectrum by
the dynamic equalizer, is then delivered through bone
conduction to the temporal bones, thus providing AAF,
presumably in the amplitude domain, as with, for example,
semitone amplification (Bauer et al., 2006: Garber et al.,
1976; Heinks-Maldonado & Houde, 2005) or feedback
filtering (Burzynski & Starr, 1985; Garber et al., 1976,
1980, 1981).
One advantage of Forbrain® over other commercially
available devices is its low cost, as it is offered by a fraction
of the cost of its competitors.1 However, no study has so
far tested whether Forbrain® provides any of the above-
mentioned effects (AAF) on the user’s voice quality and
speech. Before attempting an effortful and costly study on
a clinical population, the present experiment was, hence,
run as a proof of concept to test whether the speaker’s voice
of a sample of fluent speakers would be altered during the
use of this device. Voice quality over other fluency parame-
ters (e.g., speech rate and so forth) was preferred as it offers
quantitative and objective measures of the fine-grained
articulatory loop. It is hypothesized that, by providing
AAF, the use of Forbrain® will affect the user’s voice
during natural speech. Should our results confirm the
departing hypothesis, this study should set the grounds
to test the potential utility of Forbrain® in all clinical
conditions in which central auditory processing deficits
may be involved.
Materials and Method
Participants
A sample of N = 32 adult healthy Catalan–Spanish
bilingual participants (18 men, 14 women; mean age =
23.3 ± 2.5 years; three left-handed) were recruited for the
experiment and randomly assigned to one of the two groups
of the study (16 participants each). Inclusion criteria included
no self-report of psychiatric, neurological, and voice/speech/
language disorders, no family antecedents of these disorders,
no excessive alcohol consumption, no formal musical
training for more than 3 years, normal sleep habits, and
normal hearing levels. A pure-tone audiometry (frequency
range: 250–4000 Hz), using audiometric Beyerdinamic
DT48-A headphones (Beyerdynamic GmbH & Co, Heilbronn,
Germany), was performed for each participant before the
experiment started to confirm mean hearing thresholds be-
low 20 dB HL at each ear. The study was conducted accord-
ing to the WMA Declaration of Helsinki Ethical Principles
for Medical Research Involving Human Subjects and with
the approval of the Bioethics Committee of the University
of Barcelona. Before the experimental sessions, written in-
formed consent was obtained from each participant, after
providing a detailed description of the methods involved in
the study, without, however, revealing the nature of the
1Forbrain® cost is $299 per unit according to its official webpage
(https://www.forbrain.com/order-now/order-form). SpeechEasy®
ranges from $2,500 to $4,500 depending on the model (http://www.
speecheasy.com/models.php). SmallTalk® cost is $2,495, whereas
Basic Fluency System® is worth $1,495 (http://www.casafuturatech.
com/). Data was retrieved from the Internet on February 7, 2017.
802
Journal of Speech, Language, and Hearing Research • Vol. 61 • 801–810 • April 2018
Downloaded from: https://pubs.asha.org 77.173.35.219 on 06/05/2019, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions 
 working hypothesis. At the end of the experiment, partici-
pants were compensated by monetary payment (8 €/hr).
Device
A standard headset of Forbrain® (Sound For Life
Ltd/Soundev, Luxemburg; http://www.forbrain.com) was
used in this study. The headset was provided at no cost
by the manufacturer. As described above, Forbrain® is
equipped with a microphone and a pair of bone conductors,
which, during its use, feeds the user back with his or her
own voice speech through bone conduction, after digital
processing, to amplify high frequencies and manipulate its
intensity, so it is filtered with alternating contrast. At the
beginning of the experimental session, a Forbrain® headset
was placed on the participants’ heads in a way that they
felt comfortable, with the microphone located at 3 cm
from the participant’s mouth. Forbrain® is a completely
safe device, and its use does not convey any risk for the
participant’s health.
According to its patent registration (Guajarengues
& Lohmann, 2015), Forbrain® implements a dynamic,
two-band equalizer filter (close to a Baxandall equalizer;
Baxandall, 1952) that applies to the voice input either of
two different settings. These two settings are switched to
by the user’s voice energy at 1 kHz (mic input). One of
the settings (Setting 1) raises low frequencies (100–800 Hz,
+12 dB) while dampers high frequencies (800–15000 Hz,
−12 dB) when the input signal energy at 1 kHz exceeds
−56 dBV for a trigger time t1 = 10–50 ms. The other setting
(Setting 2) performs the opposite (i.e., dampers low fre-
quencies ranging 100–800 Hz and raises high frequencies
ranging 800–15000 Hz) when the input signal at 1 kHz drops
below −66 to −70 dBV for a holding time t2 = 20–200 ms.
By applying these functionalities, it is conceivable that
Forbrain® conveys some kind of AAF on the speaker’s
voice, which is in turn fed back via a bone conductor. Yet,
to objectively characterize the actual nature of these effects,
we performed a comparison of a speech signal at the input
(microphone) and the output (bone conductor), following
the approach suggested by Stuart et al. (2003). The speech
signal was the classical opening statement, in Spanish, of
Don Quixote by Miguel de Cervantes (1605): “En un lugar
de la Mancha de cuyo nombre no quiero acordarme” (“In a
village of La Mancha, the name of which I have no desire to
call to mind”). It lasted 4.14 s and was uttered by a female
voice and recorded in WAV format with a sampling rate
of 44.1 kHz using a DR-40 TASCAM Microphone (TEAC
America, Inc.) located at 30 cm from the speaker’s mouth.
This signal was then sent as input to Forbrain®’s micro-
phone and recorded in WAV format with a 44.1-kHz sam-
pling rate, at the system’s output from leads connected at
the input of the bone transducer through the microphone
external input of the DR-40 TASCAM Microphone. Notice
that with this approach, we could only measure the effect
of Forbrain® on its electrical output, and hence, the bone
conduction transducer is not considered. Both the input
and output signals were compared in the time domain,
cross-correlated, and analyzed with the Fast Fourier
Transform (0.17-Hz resolution) and, subsequently, with
Praat 6.0.10 software (Boersma, 2001; Boersma & Weenink,
2016) to retrieve their spectrograms. Because we did not
have access to the internal device hardware, we let it
operate in its normal mode so that Settings 1 and 2 as
described above could alternate on the basis of the input
characteristics.
Figure 1 shows the comparison of these recordings
and their cross-correlation and spectral analysis; Figure 2
shows the corresponding spectrograms retrieved with Praat
(Boersma, 2001; Boersma & Weenink, 2016). While it is
evident in the time domain that Forbrain® modified the
input signal (Figure 1A), cross-correlogram yielded a lag
zero, indicating that the output was not delayed compared
to the input (Figure 1B). However, the Fast Fourier Trans-
form of the signals revealed clear differences (Figure 1C),
in the sense that all frequencies present in the input speech
were enlarged in spectral power (Figure 1D), particularly
over high-frequency ranges (above 800 Hz). Moreover,
the analysis of the spectrograms revealed that these spec-
tral changes had particular effects on the formant structure
of the speech, which resulted in larger amplitude and
less-defined or blurred in the output compared with the
input, and the impossibility to track the first formant
(Figure 2).
Procedure and Experimental Design
The experiments were conducted on a single session for
each participant, at the premises of the Brainlab-Cognitive
Neuroscience Research Group (http://www.ub.edu/brainlab),
located in the Department of Clinical Psychology and
Psychobiology, University of Barcelona. Participants were
asked to refrain from alcohol intake and from taking any
drugs during the 24 hr before the experiment. Addition-
ally, they were asked to let us know in case they were
taking any medication, which might affect speech and
attentive and other cognitive abilities (e.g., antihistamines),
but none of the participants reported the intake of such
medication.
Participants were assigned randomly to either the
experimental (Forbrain on) or the control (Forbrain off)
group in a blind manner, so that the participant was not
told to which of the groups he or she pertained. The only
restriction in the assignment of participants was that about
the same number of men and women were assigned to each
of the groups. Moreover, the experimenter carrying out
the experiment and the subsequent analyses was also blind
to the participant’s group, as a third independent experi-
menter kept track of the subjects’ assignment. Besides, this
latter experimenter was in charge to set the Forbrain®
device to the participant and to turn it on or keep it off
according to the assigned group and was not involved in
data analysis. This is, therefore, a randomized double-blind
design providing the strongest falsative power for clinical
studies. Only when conclusions of the study were drawn
based on the final set of statistical results were the group
Escera et al.: Forbrain® Effects on Voice Control
803
Downloaded from: https://pubs.asha.org 77.173.35.219 on 06/05/2019, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions 
 identities disclosed and any potential differences attributed
to either Forbrain® or placebo.
During the experimental sessions, participants were
seated comfortably in a sound-attenuated chamber and
were instructed to read aloud, in their preferred language
(either Catalan or Spanish, yet they all chose to read in
Spanish), on a self-administered but regular pace, a self-
selected text during three separate runs of 7, 14, and 7 min,
while wearing the Forbrain® headset. During these runs,
participant’s voice was recorded. For participants belonging
to the experimental group, Forbrain® device was in off, on,
and off modes, respectively, for each of the three reading
phases. For participants belonging to the control group,
Forbrain® device was in off mode in the three phases.
Between reading phases, an experimenter entered into the
chamber to turn on or off the Forbrain® device when needed
(by pressing a button built into the device), as well as to stop
and restart the audio recordings.
Voice Recording and Analysis
The participant’s voice was recorded during reading
aloud with a sampling rate of 44.1 kHz using a DR-40
TASCAM Microphone (TEAC America, Inc.) placed in a
fixed position on the table in front of the participant, with
a mouth-to-microphone distance of approximately 30 cm.
The voice samples were saved in WAV format.
To analyze the quality of the participant’s voice dur-
ing reading, the voice samples of the three reading phases
(7, 14, and 7 min) were trimmed into 1-min time windows
without overlap. The first and last 2 min of each voice sample
were then removed from analysis, thus obtaining three
Figure 1. Effects of Forbrain® on the input signal. The Spanish statement “En un lugar de la Mancha de cuyo nombre no quiero acordarme”
uttered by a female voice (4.14 s long) was fed as input at the microphone (red) and recorded as output (blue) right before the bone transducer.
A) Input and output signals, clearly differing in amplitude. B) The cross-correlogram between the input and the output, revealing a time lag zero.
C) The spectra of the input and the output. The vertical black line separates low (100–800 Hz) from high (800–12000 Hz) frequencies. D) Changes
over time of the spectral amplitude retrieved in two frequency bands: low (100–800 Hz) and high (800–12000 Hz). A sliding window of 50 ms
shifting 5 ms across the entire signal served to compute the average amplitude spectrum in the two frequency bands (red hues: voice; blue
hues: device).
804
Journal of Speech, Language, and Hearing Research • Vol. 61 • 801–810 • April 2018
Downloaded from: https://pubs.asha.org 77.173.35.219 on 06/05/2019, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions 
 recordings of 1 min for the baseline measurements (with
Forbrain® off), ten 1-min recordings during Forbrain® use
(with Forbrain® on or off, depending on the experimental
group), and three 1-min recordings for the posttreatment
measurement (with Forbrain® off). Six different acoustic
parameters were derived from every single of the mentioned
1-min recordings, using Praat 6.0.10 software (Boersma,
2001; Boersma & Weenink, 2016) according to the method
proposed by Maryn and Weenink (2015).
First, because the acoustic measures used to analyze
voice quality are only valid for voiced segments of the
running speech, automated detection, segmentation, and
concatenation of these voice segments were applied employ-
ing a modified version of the Praat script created by Maryn
et al. (2010). The algorithm for the detection and extraction
of voiced segments was based on the three criteria pro-
posed by Parsa and Jamieson (2001), where frames of 30
ms are designated as voiced if sound energy exceeded 30%
of the overall signal energy, zero crossing rate was below
1500 Hz, and the normalized autocorrelation peak was
above 0.3.
Then, the six acoustic parameters mentioned above
were determined for the obtained voiced segments. The
smoothed cepstral peak prominence (CPPS) measures the
degree of harmony in a voice sample, which increases as
the voice signal is more periodic, and it is considered a
reliable and valid measure of voice quality, especially breathi-
ness (Maryn, Corthals, Van Cauwenberge, Roy, & De Bodt,
2010). It was determined as the distance between the first
harmonic’s peak and the point with equal frequency on the
regression line through the smoothed cepstrum (Heman-
Ackah, Michael, & Goding, 2002; Hillenbrand & Houde,
1996). Harmonics-to-noise ratio (HNR) is a glottal noise
measure that refers to the relative contributions of aperi-
odic and periodic components of the voice signal, with
periodic voice signals having larger HNR. This feature
is closely related to the efficacy of the vocal fold closure
(Zhang, Mongeau, Frankel, Thomson, & Park, 2004),
and it was calculated as the base 10 logarithm of the ratio
between the periodic energy and the noise energy multi-
plied by 10.
Shimmer local (ShimLoc) and shimmer local Db
(ShimDB) are measures of the irregularities in the amplitude
of cycles of the waveform signal, that is, the perturbation
in amplitude along the voice sample. Physiologically, such
perturbation could be produced by some asymmetry in
the vocal folds, which would make them to meet the same
way only every two or three cycles, causing the periodicity
to be achieved every second or third cycle of the vibration,
respectively. This results in random variations in timing and
amplitude of the voice signal. ShimLoc value was calculated
as the absolute difference between the amplitudes of con-
secutive periods in the voice sample, divided by the average
amplitude, whereas the ShimdB is the average absolute
base-10 logarithm of the difference between the amplitudes
of consecutive periods, multiplied by 20 (Maryn & Weenink,
2015).
The trendline of the long-term average spectrum
(LTAS) is a spectral measure and shows the average fre-
quency distribution of the sound energy in a continuous
(at least 30 s) speech sample. By averaging over a long
portion of speech, spectral differences due to individual
segments are evened out, and the method thus yields infor-
mation pertaining to the general voice quality (Vaňková
& Skarnitzl, 2014). In the LTAS, the general spectral
slope (slope of the long-term average spectrum [sLTAS])
was measured as the difference between the energy in the
0–1 kHz range and the energy in the 1–10 kHz range of
the LTAS. The spectral trendline inclination (tilt of long-
term average spectrum [tLTAS]) was computed as the
difference between the energy in the 0–1 kHz range and
the energy in the 1–10 kHz range of the trendline through
the LTAS.
Figure 2. Waveforms and spectrograms at Forbrain® input and
output. Analysis is for the early part (1.92 s: “En un lugar de la
Mancha”) of the sentence at the input (top) and recorded at the
output of Forbrain® (bottom). A visual comparison between the two
waveforms clearly shows a larger overall amplitude at the device
output. Moreover, the spectrograms corroborate this overall larger
amplitude at the device output (yellow lines) and further indicate
that formants were less defined (red lines), particularly the first one
(bottom red line), which could not be tracked.
Escera et al.: Forbrain® Effects on Voice Control
805
Downloaded from: https://pubs.asha.org 77.173.35.219 on 06/05/2019, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions 
 Statistical Analysis
Voice data during reading aloud were analyzed by
means of analysis of variance for repeated measures with
phase (baseline, test, and posttest) and group (Forbrain and
control) as factors for each of the six acoustic parameters
to assess voice quality. Whenever the interaction resulted
significant, post-hoc pairwise comparisons were carried
out, and the Greenhouse–Geisser correction was applied
whenever the assumption of sphericity was violated, the
corrected degrees of freedom being reported. The alpha level
was set to 0.05. For all the statistical analyses, Bonferroni
corrections for multiple comparisons were performed to
adjust the p values of the post-hoc tests.
Results
Results for each of the six voice parameters are illus-
trated in Figure 3 and described below. Out of the six
parameters analyzed, two of them yielded strong significant
results regarding the use of Forbrain®.
The CPPS was significantly affected by the use of
Forbrain®. The results obtained on this parameter revealed
a main effect of phase, F(2, 60) = 7.145, p = .002, ηp
2 = .192,
indicating an effect with time speaking, and a Phase ×
Group interaction, F(2, 60) = 4.044, p = .023, ηp
2 = .119
(Figure 3A). This latter effect, however, did not survive
Bonferroni correction for the multiple voice variables mea-
sured (p = .138). Post-hoc pairwise comparison revealed
that, whereas in the control group, there were no statistical
differences between measurements (baseline, test, and post-
test phases), the Forbrain group’s voice was perturbed by
the use of Forbrain®, as measurements dropped from base-
line to Forbrain® use (test phase; t(15) = 4.085, p = .001,
d = 0.28) to restore its normal values after the Forbrain®
device was turned off (i.e., a significant difference between
test and posttest phases, t(15) = 3.921, p = .001, d = 0.26,
while no difference remained in the posttest compared with
the baseline phase, t(15) = 0.270, p = .791, d = 0.01.
Analyses of the HNR (Figure 3B) revealed a signif-
icant effect of phase, F(1.57, 47.32) = 4.332, p = .026,
ηp
2 = .126, suggesting variations on this measure occur-
ring along the reading session. However, the effect did
not survive as significant after the Bonferroni correction
(p = .156). Furthermore, there were no overall effect of
group factor, F(1, 30) = 3.163, p = .085, ηp
2 = .095, and no
Phase × Group interaction, F(1.57, 47.32) = 1.432, p = .247,
ηp
2 = .046.
As for the perturbation measures, ShimDB (Figure 3C)
and ShimLoc (Figure 3D) were not significantly affected
by the use of Forbrain®, as there were no significant varia-
tions as a function of the time reading (phase) neither for
the ShimDB, F(1.46, 43.95) = 1.287, p = .278, ηp
2 = .041, nor
for the ShimLoc, F(1.37, 41.25) = 1.292, p = .275, ηp
2 = .041.
Moreover, these voice parameters did not differ between
Forbrain® and control groups (ShimDB); F(1, 30) = 0.134,
p = .716, ηp
2 = .004. ShimLoc; F(1, 30) = 0.343, p = .563,
ηp
2 = .011, overall across the experimental sessions, and there
was no Phase × Group interaction (ShimDB); F(1.46, 43.95) =
2.745, p = .090, ηp
2 = .084. ShimLoc; F(1.37, 41.25) = 2.057,
p = .154, ηp
2 = .064, suggesting variations along the session
in the irregularities of the voice sample, as measured with
ShimDB and ShimLoc, were not dependent on the use of the
device.
Finally, measures of the LTAS yielded different re-
sults for the slope (sLTAS; Figure 3E) and the tilt (tLTAS;
Figure 3F). sLTAS values were not significantly affected
neither by phase, F(2, 60) = 0.228, p = .797, ηp
2 = .008,
nor by group, F(1, 30) = 1.406, p = .245, ηp
2 = .045, and
no Phase × Group interaction was present, F(2, 60) = 1.400,
p = .255, ηp
2 = .045. However, in the tLTAS, there was
a strong significant interaction between Phase × Group,
F(2, 60) = 9.885, p = .001, ηp
2 = .248. After applying the
Bonferroni correction, this interaction remained signifi-
cant (p = .006). The results obtained here, illustrated in
Figure 3F, revealed a tonic decrease of tLTAS across the
reading sessions (main effect of phase: F(2, 60) = 11.763,
p = .001, ηp
2 = .282), whereas the use of Forbrain® pre-
vented this effect to occur during its use; that is, for the
Forbrain group, the measurements obtained in the baseline
and test phases did not differ, t(15) = 1.876, p = .08, d = 0.14,
whereas they did for the control group, t(15) = 4.206,
p = .001, d = 0.31. This contrasted with the lack of differ-
ences for the control group between the test and posttest
phases, t(15) = 0.439, p = .667, d = 0.03, whereas there
was a clear decrease for the Forbrain group, t(15) = 5.099,
p = .001, d = 0.45. This suggests that the use of Forbrain®
softened the tLTAS of voice and, thus, enhanced the voice
quality, at least during the short period of 14 min that
lasted its use.
Discussion
This study was set as a proof of concept to investigate
the potential effects of Forbrain® on voice production and
to establish whether it could be considered as of clinical
relevance in the areas of speech and language therapy as
an AAF device. Forbrain® is a headset equipped with a
microphone, which feeds the user back with his or her own
voice during natural speech through a pair of bone conduc-
tors. According to its patent description (Guajarengues &
Lohmann, 2015), Forbrain® applies to the voice input a
dynamic, two-band equalizer filter, which is triggered by
the user’s voice energy at 1 kHz over a time window of inte-
gration ranging 10–200 ms. Moreover, the results reported
here when comparing a test speech signal at the input (micro-
phone) and the output (bone transducer) of Forbrain® have
shown that the device indeed alters the input by changing
its amplitude over the overall spectra and the spectrographic
characteristics of the speech it processes (see Figures 1 and 2).
Hence, by its technical specifications and the results pro-
vided herein, Forbrain® can be considered as a device that
falls within the category of an AAF system. Previous studies
have shown that delivering AAF in the amplitude/intensity
domain, such as with the Lombard effect (Arciuli et al., 2013;
Garnier et al., 2010; Stathopoulos et al., 2014), sidetone
806
Journal of Speech, Language, and Hearing Research • Vol. 61 • 801–810 • April 2018
Downloaded from: https://pubs.asha.org 77.173.35.219 on 06/05/2019, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions 
 amplification (Bauer et al., 2006; Garber et al., 1976;
Heinks-Maldonado & Houde, 2005), and feedback filtering
(Burzynski & Starr, 1985; Garber et al., 1976, 1980, 1981),
alters the speech of fluent speakers and those who stutter
(Martin et al., 1984). Therefore, although not falling within
the category of the most common and clinically used AAF
manipulations, such as delayed auditory feedback, frequency-
altered feedback, or masking noise, it is conceivable that
Forbrain® provides some form of AAF capable to alter the
speaker’s voice and, hence, that it may have a relevant clini-
cal utility as a general purpose AAF device. The purpose
of this study was, thus, to gather some controlled empirical
evidence on the potential effects of Forbrain®. We focused
on fluent speakers and voice quality to avoid an effortful
and costly study on a clinical population on a device not
tested so far for effectiveness and to obtain a reliable and
Figure 3. Voice quality measures. Participants’ voice was recorded during reading aloud on three different phases: one serving as baseline
(baseline; 7 min), one during the use of Forbrain® in the experimental group (treatment; dashed line) or during a placebo (same settings,
Forbrain® device off serving as control; continuous line; 14 min), and one posttreatment (follow-up; 7 min). Six quantitative parameters of
voice quality were determined for each of the reading phases: (A) the smoothed cepstral peak prominence (CPPS); (B) harmonics-to-noise
ratio (HNR); (C) shimmer dB (ShimDB); (D) shimmer local (ShimLoc); (E) slope of the long-term average spectrum (sLTAS); (F) tilt of the trendline
of the long-term average spectrum (tLTAS). Error bars show the standard error of the mean. Analysis of variance yielded a significant Group ×
Phase interaction for the tLTAS, and post-hoc analyses revealed that using Forbrain® enhanced tLTAS and attenuated CPPS, indicating
that when Forbrain® is on, user’s voice reacts to the device’s feedback.
Escera et al.: Forbrain® Effects on Voice Control
807
Downloaded from: https://pubs.asha.org 77.173.35.219 on 06/05/2019, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions 
 quantitative measure of fine-grained voice adjustment to
challenge the potential effects of the device.
The participants in the present experiment were ran-
domly assigned, in a double-blind manner, to either of
two groups that underwent the same experimental protocol.
This consisted of three runs of 7, 14, and 7 min, respectively,
in which the healthy, young participants read aloud a text
of their choice. All participants wore a Forbrain® headset
during the whole experiment, the only difference between
groups being that, for the long middle reading session (test
phase), in half of the participants, the device was set on.
Notice that for the other group of participants, the device
remained off, yet a research assistant not involved in the
data collection and analyses entered the room and manipu-
lated the device with a similar handling as in the Forbrain
group. This way, neither the participants nor the experi-
menters were aware of the condition being conducted (e.g.,
Forbrain® on or off). Participants’ voice during the reading
was recorded, digitized, and subsequently analyzed to derive
six different quantitative parameters typically used in voice
quality studies (Maryn et al., 2010; Maryn & Weenink, 2015).
The results obtained in this study were clear with
regard to the effects of the use of Forbrain® during natural
speech. Out of the six voice quantitative parameters analyzed,
two of them yielded statistically significant results when
comparing the two groups. Indeed, both the CPPS and the
tLTAS resulted in significant Group × Phase interactions,
indicating that, when using Forbrain®, participant’s voice
was significantly affected compared with baseline and pos-
tuse phases and with regard to the control group as well.
Specifically, CPPS is a measure of the degree of harmony
in a voice sample, so that it is larger when the voice signal
is more periodic, and has been considered to indicate voice
quality, particularly, breathiness (Heman-Ackah et al.,
2002; Hillenbrand & Houde, 1996; Maryn et al., 2010).
The results on CPPS revealed a attenuation in voice harmony
and, hence, its breathiness, with time reading (significant
effect of phase) across groups, as well as a further pro-
nounced reduction in voice harmony in the Forbrain group
when the device was turned on (signification Group × Phase
interaction; see Figure 3A), indicating that Forbrain®
further perturbed voice quality. Furthermore, results on
tLTAS also revealed a specific effect of Forbrain®. The
spectral trendline inclination tLTAS provides a measure
that captures the average frequency distribution of the
sound energy in a continuous speech sample (Maryn et al.,
2010; Vaňková & Skarnitzl, 2014). In fact, it has been sug-
gested that strong resonant voices present less differences
between the strong and weak regions of the voice spectrum,
whereas poor fluid voices present larger differences, and
poor speaking voices have relatively lower sound level in
the midfrequency range (1–3 kHz), whereas glottal closing
speed has been related with less tilting slope of LTAS (Leino,
2009). Results regarding tLTAS revealed strong effects of
phase across groups, with voice losing strength and becoming
less fluid with time on reading across all reading phases.
Remarkably, results also revealed a significant Group × Phase
interaction, with Forbrain® users displaying a pronounced
restoring of the tilt of the slope during the experimental phase,
suggesting that Forbrain® use strengthened voice quality.
It is interesting to observe that the two effects of
Forbrain® on voice quality obtained in the present experi-
ment were in fact in apparent opposite directions. Indeed,
the effects on CPPS, which reflects voice harmony, indicated
reduced voice breathiness with the use of Forbrain®, whereas
the effects on tLTAS, which is thought to reflect voice
robustness, suggested strengthening of the voice during
Forbrain® use. However, an interpretation of these effects
in the context of the neural circuits of the phono-articulatory
loop may help to clarify this apparent contradiction and, in
fact, to support Forbrain®, together with its functionalities
proved here, as a device that provides AAF. Indeed, there
is increasing evidence that sensory processing is altered as
a consequence of motor adaptation to altered visual, somato-
sensory, and auditory feedback (Ostry & Gribble, 2016),
and conversely, motor output is fine-grained adjusted as
a consequence of distorted sensory input (Hahnloser &
Narula, 2017). These findings consist of the so-called corol-
lary discharge view of motor control, according to which
the motor (e.g., vocal) system sends an efferent copy or cor-
ollary discharge of the sound it aims producing, so that
the encoding of the auditory input resulting from the self-
produced sounds is attenuated in the auditory system (Scott,
2013; Wolpert, Ghahramani, & Jordan, 1995). This way,
the auditory system implements a neurophysiological mech-
anism that allows it to recognize the self-emitted sounds
and to disregard them from further processing, leaving the
processing resources for the externally generated sounds
(SanMiguel, Widmann, Bendixen, Trujillo-Barreto, &
Schröger, 2013), with the obvious adaptive and communica-
tive advantages. However, when the received input does not
match the efferent copy of the motor command, a predic-
tion error is generated (Hahnloser & Narula, 2017) that
forces a system readjustment. The pattern of results obtained
with Forbrain® in the present experiment nicely fits this
model. Indeed, the effects observed on CPPS indicating
reduced voice harmony support a perturbation of voice control
caused by the altered feedback of the ongoing speech fed to
the model, whereas the parallel increased voice strength during
Forbrain® would indicate an attempt of the audio-vocal loop
to compensate for the voice perturbation caused by the
altered feedback. Although this is a conceivable interpretation
of the data, future experiments should aim at identifying
the underlying processes involved in this pattern of effects.
Conclusions
This study investigated, in a double-blind controlled
design, the potential effects of Forbrain® on quantitative
parameters of voice during natural speech, on a sample
of normal-speaking adults. It was found that turning the
device on induced changes in voice quality, in particular,
a reduction in voice harmony paralleled by a strengthening
of voice robustness. Based on its observed functionalities
and the results obtained herein, it seems that it has been
proven that Forbrain® provides AAF to its users and,
808
Journal of Speech, Language, and Hearing Research • Vol. 61 • 801–810 • April 2018
Downloaded from: https://pubs.asha.org 77.173.35.219 on 06/05/2019, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions 
 therefore, that it could be considered as a low-cost option
in treatments with AAF on a range of speech, language, and
communication disorders. Further clinical studies should
aim to validate its usefulness in clinical settings.
Acknowledgments
This research was supported by Sound For Life Ltd (Soundev)
and partially by the Catalan Government (SGR2014-177), the
Spanish Ministry of Economy and Knowledge (PSI2015-63663-
P-MINECO/FEDER), and the ICREA Academia Distinguished
Professorship awarded to Carles Escera. Natàlia Gorina-Careta and
Carles Escera conceived the design. Fran López-Caballero performed
the research. Fran López-Caballero analyzed the data. Fran López-
Caballero and Carles Escera interpreted the results. Fran López-
Caballero, Natàlia Gorina-Careta, and Carles Escera wrote the article.
References
Ahissar, M., Lubin, Y., Putter-Katz, H., & Banai, K. (2006).
Dyslexia and the failure to form a perceptual anchor. Nature
Neuroscience, 9(12), 1558–1564.
Alexander-Passe, N. (2008). The sources and manifestations of
stress amongst school-aged dyslexics, compared with sibling
controls. Dyslexia, 14(4), 291–313.
Arciuli, J., Simpson, B. S., Vogel, A. P., & Ballard, K. J. (2013).
Acoustic changes in the production of lexical stress during
Lombard speech. Language and Speech, 57, 149–162.
Baxandall, P. J. (1952). Negative-feedback tone control. Wireless
World, LXIII(10), 402–405.
Bauer, J. J., Mittal, J., Larson, C. R., & Hain, T. C. (2006).
Vocal responses to unanticipated perturbations in voice loud-
ness feedback: An automatic mechanism for stabilizing voice
amplitude. The Journal of the Acoustical Society of America,
119, 233–2371.
Bishop, D. V. M., Hardiman, M. J., & Barry, J. G. (2010). Lower-
frequency event-related desynchronization: A signature of late
mismatch responses to sounds, which is reduced or absent
in children with specific language impairment. The Journal
of Neuroscience, 30(46), 15578–15584.
Boersma, P. (2001). Praat, a system for doing phonetics by com-
puter. Glot International, 5(9/10), 341–345.
Boersma, P., & Weenink, D. (2016). Praat: Doing phonetics by
computer (Version 6.0.10) [Computer program]. Retrieved
from http://www.praat.org
Burzynski, C. M., & Starr, C. D. (1985). Effects of feedback on
nasalization and self-perception of nasality. Journal of Speech
and Hearing Research, 28, 585–588.
Cai, S., Beal, D. S., Ghosh, S. S., Tiede, M. K., Guenther, F. H.,
& Perkell, J. S. (2012). Weak responses to auditory feedback
perturbation during articulation in persons who stutter: Evidence
for abnormal auditory-motor transformation. PLoS ONE, 7(7),
e41830. https://doi.org/10.1371/journal.pone.0041830
Corbera, S., Corral, M. J., Escera, C., & Idiazábal, M. A. (2005).
Abnormal speech sound representation in persistent develop-
mental stuttering. Neurology, 65(8), 1246–1252.
Corbera, S., Escera, C., & Artigas, J. (2006). Impaired duration
mismatch negativity in developmental dyslexia. NeuroReport,
17(10), 1051–1055.
Cummings, A. E., & Barlow, J. A. (2011). A comparison of word
lexicality in the treatment of speech sound disorders. Clinical
Linguistics & Phonetics, 25(4), 265–286.
Eliades, S. J., & Wang, X. (2008). Neural substrates of vocaliza-
tion feedback monitoring in primate auditory cortex. Nature,
453, 1102–1106.
Fairbanks, G. (1954) Systematic research in experimental phonet-
ics. I. A theory of the speech mechanism as a servosystem.
Journal of Speech and Hearing Disorders, 19, 133–139.
Foundas, A. L., Bollich, A. M., Feldman, J., Corey, D. M., Hurley,
M., & Heilman, K. M. (2004). Atypical planum temporale
anatomy in stuttering: Relationship to delayed auditory feed-
back. Neurology, 63, 1640–1646.
Foundas, A. L., Mock, J. R., Corey, D. M., Golob, E. J., &
Conture, E. G. (2013). The SpeechEasy device in stuttering
and nonstuttering adults: Fluency effects while speaking and
reading. Brain and Language, 126(2), 141–150.
Garber, S. R., Siegel, G. M., & Pick, H. L., Jr. (1976). The influ-
ence of selected masking noises on Lombard and sidetone
amplification effects. Journal of Speech and Hearing Research,
19, 523–535.
Garber, S. R., Siegel, G. M., & Pick, H. L., Jr. (1980). The effects
of feedback filtering on speaker intelligibility. Journal of Com-
munication Disorders, 13, 289–294.
Garber, S. R., Siegel, G. M., & Pick, H. L., Jr. (1981). Regulation
of vocal intensity in the presence of feedback filtering and ampli-
fication. Journal of Speech and Hearing Research, 24, 104–108.
Garnier, M., Henrich, N., & Dubois, D. (2010). Influence of sound
immersion and communicative interaction on the Lombard
effects. Journal of Speech, Language, and Hearing Research,
53, 588–608.
Guajarengues, T., & Lohmann, K. (2015). Apparatus and method
for active voice training. Google Patents. Retrieved from http://
www.google.ch/patents/WO2015067741A1?cl=en
Hahnloser, R. H., & Narula, G. (2017). A Bayesian account of
vocal adaptation to pitch-shifted auditory feedback. PLoS
ONE, 12(1), e0169795.
Halliday, L. F., Barry, J. G., Hardiman, M. J., & Bishop, D. V.
(2014). Late, not early mismatch responses to changes in
frequency are reduced or deviant in children with dyslexia: An
event-related potential study. Journal of Neurodevelopmental
Disorders, 6(1), 21.
Hämäläinen, J. A., Salminen, H. K., & Leppänen, P. H. T. (2013).
Basic auditory processing deficits in dyslexia: Systematic review
of the behavioral and event-related potential/field evidence.
Journal of Learning Disabilities, 46(5), 413–427.
Hampton, A., & Weber-Fox, C. (2008). Non-linguistic auditory
processing in stuttering: Evidence from behavior and event-
related brain potentials. Journal of Fluency Disorders, 33(4),
253–273.
Hayiou-Thomas, M. E., Carroll, J. M., Leavett, R., Hulme, C.,
& Snowling, M. J. (2017). When does speech sound disorder
matter for literacy? The role of disordered speech errors, co-
occurring language impairment and family risk of dyslexia. The
Journal of Child Psychology and Psychiatry, 58(2), 197–205.
Heinks-Maldonado, T. H., & Houde, J. F. (2005). Compensatory
responses to brief perturbations of speech amplitude. Acoustics
Research Letters Online, 6(3), 131–137.
Heman-Ackah, Y. D., Michael, D. D., & Goding, G. S. (2002). The
relationship between cepstral peak prominence and selected
parameters of dysphonia. Journal of Voice, 16(1), 20–27.
Hickok, G., Houde, J., & Rong, F. (2011). Sensorimotor inte-
gration in speech processing: Computational basis and neural
organization. Neuron, 69(3), 407–422.
Hillenbrand, J., & Houde, R. A. (1996). Acoustic correlates of
breathy vocal quality: Dysphonic voices and continuous speech.
Journal of Speech and Hearing Research, 39(2), 311–321.
Escera et al.: Forbrain® Effects on Voice Control
809
Downloaded from: https://pubs.asha.org 77.173.35.219 on 06/05/2019, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions 
 Houde, J. F., & Jordan, M. I. (1998). Sensorimotor adaptation in
speech production. Science, 279, 1213–1216.
Iliadou, V., Chermak, G. D., & Bamiou, D. E. (2015). Differential
diagnosis of speech sound disorder (phonological disorder):
Audiological assessment beyond the pure-tone audiogram.
Journal of the American Academy of Audiology, 26(4), 423–435.
Iverach, L., & Rapee, R. M. (2014). Social anxiety disorder and
stuttering: Current status and future directions. Journal of
Fluency Disorders, 40, 69–82.
Jones, J. A., & Munhall, K. G. (2000). Perceptual calibration of F0
production: Evidence from feedback perturbation. The Journal
of the Acoustical Society of America, 108, 1246–1251.
Keller, G. B., & Hahnloser, R. H. R. (2009). Neural processing of
auditory feedback during vocal practice in a songbird. Nature,
457, 187–190.
Leino, T. (2009). Long-term average spectrum in screening of
voice quality in speech: Untrained male university students.
Journal of Voice, 23(6), 671–676.
Lincoln, M., Packman, A., & Onslow, M. (2006). Altered auditory
feedback and the treatment of stuttering: A review. Journal of
Fluency Disorders, 31(2), 71–89.
Martin, R. R., Siegel, G. M., Johnson, L. J., & Haroldson, S. K.
(1984). Sidetone amplification, noise, and stuttering. Journal
of Speech and Hearing Research, 27, 518–527.
Maryn, Y., Corthals, P., Van Cauwenberge, P., Roy, N., &
De Bodt, M. (2010). Toward improved ecological validity in
the acoustic measurement of overall voice quality: Combining
continuous speech and sustained vowels. Journal of Voice,
24(5), 540–555.
Maryn, Y., & Weenink, D. (2015). Objective dysphonia measures
in the program praat: Smoothed cepstral peak prominence and
acoustic voice quality index. Journal of Voice, 29(1), 35–43.
Miller, C. (2011). Auditory processing theories of language dis-
orders: Past, present, and future. Language, Speech, and Hearing
Services in Schools, 42(July), 309–320.
Murphy, C. F. B., Pagan-Neves, L. O., Wertzner, H. F., &
Schochat, E. (2015). Children with speech sound disorder:
Comparing a non-linguistic auditory approach with a phono-
logical intervention approach to improve phonological skills.
Frontiers in Psychology, 6, Article 64.
Näätänen, R., Paavilainen, P., Rinne, T., & Alho, K. (2007). The
mismatch negativity (MMN) in basic research of central auditory
processing: A review. Clinical Neurophysiology, 118(12), 2544–2590.
Olofsson, A., Taube, K., & Ahl, A. (2015). Academic achievement
of university students with dyslexia. Dyslexia, 21(4), 338–349.
Ostry, D. J., & Gribble, P. L. (2016). Sensory plasticity in human
motor learning. Trends in Neurosciences, 39(2), 114–123.
Packman, A. (2012). Theory and therapy in stuttering: A complex
relationship. Journal of Fluency Disorders, 37(4), 225–233.
Parsa, V., & Jamieson, D. G. (2001). Acoustic discrimination of
pathological voice: Sustained vowels versus continuous speech.
Journal of Speech, Language, and Hearing Research, 44(2),
327–339.
Peterson, R. L., Pennington, B. F., Shriberg, L. D., & Boada, R.
(2009). What influences literacy outcome in children with speech
sound disorder? Journal of Speech, Language, and Hearing
Research, 52(5), 1175–1188.
Pollard, R., Ellis, J. B., Finan, D., & Ramig, P. R. (2009). Effects
of the SpeechEasy on objective and perceived aspects of
stuttering: A 6-month, phase I clinical trial in naturalistic envi-
ronments. Journal of Speech, Language, and Hearing Research,
52, 516–533.
Riddick, B. (2001). Dyslexia and inclusion: Time for a social
model of disability perspective? International Studies in Sociol-
ogy of Education, 11(3), 223–236.
Ritto, A. P., Juste, F. S., Stuart, A., Kalinowksi, J., & de Andrade,
C. R. F. (2016). Randomized clinical trial: The use of SpeechEasy
R in stuttering treatment. International Journal of Language &
Communication Disorders, 51(6), 769–774.
Roberts, G. J., Solis, M., Ciullo, S., McKenna, J. W., & Vaughn,
S. (2015). Reading interventions with behavioral and social
skill outcomes: A synthesis of research. Behavior Modification,
39(1), 8–42.
Rota-Donahue, C., Schwartz, R. G., Shafer, V., & Sussman, E. S.
(2016). Perception of small frequency differences in children with
auditory processing disorder or specific language impairment.
Journal of the American Academy of Audiology, 27(6), 489–497.
SanMiguel, I., Widmann, A., Bendixen, A., Trujillo-Barreto, N.,
& Schröger, E. (2013). Hearing silences: Human auditory pro-
cessing relies on preactivation of sound-specific brain activity
patterns. Journal of Neuroscience, 33, 8633–8639.
Scott, M. (2013). Corollary discharge provides the sensory content
of inner speech. Psychological Science, 24(9), 1824–1830.
Siegel, G. M., & Kennard, K. L. (1984). Lombard and sidetone
amplification effects in normal and misarticulating children.
Journal of Speech and Hearing Research, 27, 56–62.
Stathopoulos, E. T., Huber, J. E., Richardson, K., Kamphaus, J.,
DeCicco, D., Darling, M., . . . Sussman, J. E. (2014). Increased
vocal intensity due to the Lombard effect in speakers with
Parkinson’s disease: Simultaneous laryngeal and respiratory
strategies. Journal of Communication Disorders, 48, 1–17.
Stuart, A., Kalinowski, J., Rastatter, M., Saltuklaroglu, T., &
Dayalu, V. (2004). Investigations of the impact of altered audi-
tory feedback in-the-ear devices on the speech of people who
stutter: Initial fitting and 4-month follow-up. International
Journal of Language & Communication Disorders, 39, 93–113.
Stuart, A., Kalinowski, J., Saltuklaroglu, T., & Guntupalli, V. K.
(2006). Investigations of the impact of altered auditory feed-
back in-the-ear devices on the speech of who stutter: One-year
follow-up. Disability and Rehabilitation, 28, 757–765.
Stuart, A., Xia, S., Jiang, Y., Jiang, T., Kalinowski, J., & Rastatter,
M. P. (2003). Self-contained in-the-ear device to deliver altered
auditory feedback: Applications for stuttering. Annals of Bio-
medical Engineering, 31, 233–237.
Unger, J., Glück, C., & Cholewa, J. (2012). Immediate effects
of AAF devices on the characteristics of stuttering: A clinical
analysis. Journal of Fluency Disorders, 37, 122–134.
Vaňková, J., & Skarnitzl, R. (2014). Within- and between-speaker
variability of parameters expressing short-term voice quality.
Speech Prosody, 2014, 1081–1085.
Wolpert, D. M., Ghahramani, Z., & Jordan, M. I. (1995). An internal
model of sensoriomotor integration. Science, 269, 1880–1882.
Yates, A. J. (1963). Delayed auditory feedback. Psychological
Bulletin, 60(3), 213–232.
Zhang, Z., Mongeau, L., Frankel, S. H., Thomson, S., & Park, J. B.
(2004). Sound generation by steady flow through glottis-shaped
orifices. The Journal of the Acoustical Society of America,
116(3), 1720–1728.
810
Journal of Speech, Language, and Hearing Research • Vol. 61 • 801–810 • April 2018
Downloaded from: https://pubs.asha.org 77.173.35.219 on 06/05/2019, Terms of Use: https://pubs.asha.org/pubs/rights_and_permissions 
