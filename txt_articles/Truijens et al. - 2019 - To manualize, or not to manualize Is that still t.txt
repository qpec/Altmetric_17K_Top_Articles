 Received: 18 January 2017 |
Revised: 9 July 2018 | Accepted: 30 August 2018
DOI: 10.1002/jclp.22712
R E V I E W A R T I C L E
To manualize, or not to manualize: Is that still
the question? A systematic review of empirical
evidence for manual superiority in psychological
treatment
Femke Truijens1
| Levin Zühlke‐van Hulzen2 | Stijn Vanheule1
1Department of Psychoanalysis and Clinical
Consulting, Faculty of Psychology and
Educational Sciences, Ghent University,
Ghent, Belgium
2Department of Social Psychology, Faculty of
Behavioral and Social Sciences, University of
Amsterdam, Amsterdam, The Netherlands
Correspondence
Femke Truijens, Department of
Psychoanalysis and Clinical Consulting,
Faculty of Psychology and Educational
Sciences, Ghent University, Henri Dunantlaan
2, B‐9000 Ghent, Belgium.
Email: Femke.Truijens@UGent.be
Abstract
Objective: Institutional promotion of psychotherapy man-
uals as a requirement for evidence‐based treatments (EBTs)
yields the assumption that manualized treatment is more
effective than nonmanualized treatment. This systematic
review examines empirical evidence for this claim.
Methods: An electronic database search identified studies
that directly or indirectly compared manual‐based and non‐
manual‐based treatment.
Results: Six studies directly compared manualized and
nonmanualized treatment (Hypothesis 1). None support
manual superiority. Eight meta‐analyses indirectly assessed
effect sizes of manual‐based treatment and control groups
(Hypothesis 2). Three support manual superiority, five do
not. One meta‐analysis and 15 further studies addressed
manual adherence as an indirect indicator of manual efficacy
(Hypothesis 3). The meta‐analysis concluded that manual
adherence does not affect outcome, additional studies
provided inconclusive results.
Conclusions:
Manualized
treatment
is
not
empirically
supported as more effective than nonmanualized treatment.
While manual‐based treatment may be attractive as a
research tool, it should not be promoted as being superior
to nonmanualized psychotherapy for clinical practice.
J. Clin. Psychol. 2018;1–15.
wileyonlinelibrary.com/journal/jclp
© 2018 Wiley Periodicals, Inc. |
1
 K E Y W O R D S
empirically supported treatment, evidence‐based treatment,
manual‐based treatment, manualization, psychotherapy, treatment
efficacy
1
|
INTRODUCTION
Psychotherapy manuals have evolved as a way to secure the application of effective psychotherapies. In 2015, the
American Psychological Association (APA) recognized over 350 evidence‐based psychotherapies (EBTs) that are
specified by means of treatment manuals (Kazdin, 2015; US Department of Health & Human Services, 2015).
According to Marshall (2009, p. 110) “manuals are intended to direct the application of treatment by specifying: (1)
a clear theoretical basis; (2) the number and sequencing of treatment sessions; (3) the content and objectives of
each session; and (d) the procedures required to achieve the objective of each session.” Manualized treatment
increasingly impacts clinical practice and mental health care policy, as influential institutions such as the APA and
the National Institute for Health and Care Excellence (NICE) stimulate the dissemination of manual‐based EBTs
(Norcross, Levant, & Beutler, 2005). For example, in the UK, the NICE guidelines require that “psychological and
psychosocial interventions should be based on the relevant treatment manual(s), which should guide the structure
and duration of the intervention” (National Institute for Health and Care Excellence, 2009). This requirement
captures the assumption that it is more effective to apply manualized treatment than to provide treatment in a less
or nonmanualized form. As this assumption seems vital to justify the dissemination of manual‐based EBTs to clinical
practice, in this paper, we review the empirical evidence for this assumption.
In clinical practice, however, the use of manuals is heavily critiqued. First, clinicians have argued that a standardized
approach might render it impossible to act on the individual characteristics of different clients (Garfield, 1996). While
some studies indeed point to difficulties in adapting manual‐based treatments to the needs of individual clients (see
Hucker & McCabe, 2012; Marshall, 2009), other research shows that an appropriate amount of attention to the
individual client is possible (Jones & McCabe, 2011). Indeed, increasing attention is given to the “flexibility within fidelity
principle,” which addresses individualization within manual training (Hamilton, Kendall, Gosch, Furr, & Sood, 2008).
Second, clinicians have argued that manualized treatments only specify treatment for one specific disorder, while clients
in practice generally show high levels of comorbidity (Addis, Wade, & Hatgis, 1999). However, several researchers have
shown that manualized treatments are effective towards comorbid disorders besides the target disorder (Kazdin, 2015;
Wilson, 1997). A third critique addresses the impossibility for clinicians to gain proficiency in all the different manuals
for the extensive array of psychological diagnoses (Addis, 1997). This objection gave rise to the development of
transdiagnostic treatment manuals that extrapolate the underlying, shared characteristics of a certain therapeutic
approach to different disorders (Kazdin, 2015). These critiques, as well as their proposed solutions, have in common the
fact that they focus on problems in the dissemination of manuals from scientific research into clinical practice. That is,
the problems concern how manuals could be applied in clinical practice.
However, the question if it is best to apply manuals in clinical practice remains unanswered: Does the use of
manuals actually increase therapy effectiveness? And should manuals, therefore, be embraced in clinical practice
and training? Although institutes such as NIMH and APA stimulate the use of manuals in clinical practice, the APA
also states that there is little research on the effects of the use of manuals in clinical practice (APA 2001, in
Chambless & Ollendick, 2001), yet they suggest that research does not point to decreased effectiveness (see also
Addis, Cardemil, Duncan, & Miller, 2006; Eifert, Schulte, Zvolensky, Lejuez, & Lau, 1997). The value of manual use
was critically addressed in a special issue of Clinical Psychology in 1998 (Treatment Manuals in Clinical Practice,
1998). However, the concerned papers were predominantly based on conceptual or clinical argumentation. Given
the current requirement of manuals as the core of evidence‐based psychotherapy, it seems crucial to substantiate
2
|
TRUIJENS ET AL.
 this discussion with empirical evidence. Therefore, in the present article we review the empirical support for EBT’s
thesis of the superiority of manual‐based treatment in psychotherapy.
In a first step, we evaluated the direct evidence for the primary hypothesis that manual‐based psychotherapy is more
effective than the same kind of psychotherapy applied without a manual. This hypothesis should be satisfied if manualized
treatment were indeed superior to nonmanualized treatment in clinical practice. Given the results obtained for the first
hypothesis, in the second step, we reviewed the literature for indirect evidence of manual use superiority. For this purpose,
we specified two additional hypotheses that should at least be satisfied if the use of manuals were to be favored in the
dissemination of EBTs. The second hypothesis therefore purports that if manuals indeed enhance the efficacy of
psychotherapy, efficacy studies that use no‐treatment, delayed‐treatment, minimal treatment or alternative treatment
control groups should yield larger efficacy for manual‐based therapies than for non‐manual‐based therapies. If manuals
capture the treatment effect then the hypothesized difference should be found regardless of the form of the control
group; although it could be larger in the case of intent‐to‐fail control groups (cf. Westen, Novotny, & Thompson‐Brenner,
2004) than for alternative treatment control groups administered without a treatment manual. For our purposes,
therefore, we consider all control groups regardless of their form or credibility. The third hypothesis purports that a low
adherence to the treatment manual should be related to lowered treatment effectiveness, while good manual adherence
should entail higher effectiveness. This follows from the assumption that a treatment manual captures the specific
effective aspects of psychotherapy.
2
|
METHODS
2.1
|
Data collection
In line with the Moher, Liberati, Tetzlaff, Altman, and The PRISMA Group (2009) statement for systematic reviews,
an electronic database literature search was conducted between April and May 2015 and repeated in March 2016.
First, a broad search was conducted in the electronic search‐engine of the University of Amsterdam (The
Netherlands) with the search terms tailor‐made and standardized in combination with psychology and psychiatry.
Second, a search was conducted in Web of Science with the search terms therapy manual*, treatment manual*,
standardized and individualized. These terms were used in all combinations and refined to psychology and psychiatry.
As the search term protocol predominantly yielded protocol descriptions in the medical and psychological literature,
a search was conducted with the terms nonprotocol*, no protocol* , and unprotocol*. As the few results found by the
negation were identical to findings from the previous search, the remainder of the searches was conducted with the
manual‐related search terms. Third, all the found articles (empirical, theoretical, and review papers) were read and
cross‐checked for references that were not yet found in the electronic databases (i.e., “the snowball method”). The
papers identified in the three searches were used for each of the three hypotheses formulated in the current study.
Additionally, for testing the third hypothesis, a replication was conducted of the literature search done by Webb,
DeRubeis, and Barber (2010) on the relation between manual adherence and treatment efficacy. As Webb et al. only
reviewed the literature up until April 2009, their search was replicated with identical search terms to identify papers
published since then. The replication search was conducted on 17th of March 2016 in the PsycINFO (American
Psychological Association, Washington, DC) database.
As the preference for manualized or nonmanualized treatment by research might be prone to allegiance effects,
the current project was designed as a joint effort by one social psychologist (research intern) and two clinical
psychologists (predoc and tenure), with different clinical and academic experience regarding manualized treatment.
The primary literature searches were conducted by the social psychologist, who was not familiar with any clinical
opinions on the use of psychotherapy manuals, for avoiding bias and preferences as much as possible in conducting
the systematic review. The search process was supervised by the first author, and the findings were assessed,
discussed and written up jointly by the three authors.
TRUIJENS ET AL.
|
3
 2.2
|
Data selection
Papers were included if they satisfied the following conditions: (a) published in English, Dutch, or German language;
(b) reporting a direct or indirect comparison of manualized and nonmanualized treatment; and (c) presenting
empirical results, either in reports of original data or in reviews or meta‐analyses of empirical research. Given the
eligibility criterion of empirical results, conceptual, clinical and editorial papers were only used in the snowball
search to cross‐check any reference to empirical papers. As this review addresses psychotherapeutic manuals,
papers were excluded if they covered: (a) pharmacological treatments or treatment of symptoms caused by brain
damage; (b) self‐help or online treatment without a therapist; (c) manual development.
No restrictions were applied with regard to the year of publication, type of psychotherapy, and type of sample.
For transparency, the quality of the included empirical articles was assessed using a Jadad Scale for clinical trials
(cf. Jadad et al., 1996). The primary Jadad Scale was complemented with two additional criteria relevant for the
hypotheses in this paper. The used criteria were: (a) randomization, (b) double‐blinding, (c) description of
withdrawals and dropouts, (d) clear inclusion/exclusion criteria, and (e) clear description of interventions. Each
article received 1 point per criterion that was both reported and present. Our assessment suffers from what Jadad
et al. (1996) mentioned as the “major disadvantage of the instrument described in this paper and of most others”
(p. 10) that the assessment is impacted by missing information in the assessed reports. Nonetheless, given the small
number of found articles that addressed our research question, all found articles were included in this paper,
regardless of their quality.
3
|
RESULTS
3.1
|
Search findings
The final body of literature included six empirical studies that directly assessed the differences in therapy efficacy
by manualized or nonmanualized treatment, as well as 16 empirical studies and nine meta‐analyses that provided
indirect assessments of manual effectiveness. Specifically, our primary hypothesis was covered by six papers, our
second additional hypothesis by eight meta‐analyses, and our third additional hypothesis by one meta‐analysis and
15 empirical studies. Below, we specify the findings per stage of the search process (see Figure 1).
The first search resulted in 36 hits, which were all thoroughly assessed to make sure that all the articles
with empirical results were included. Two empirical studies were identified as directly relevant for our primary
hypothesis. One review article did not contain empirical information but provided relevant background
information in the introduction and discussion and was therefore kept to cross‐check references in the third
search, see below. The remainder of the findings in the first search consisted of conceptual, theoretical or
clinical discussions and clinical research agendas rather than controlled empirical studies, and were therefore
excluded from our corpus of empirical literature. The second search resulted in 218 papers, of which two were
FIGURE 1
Flow chart of findings in three searches and an additional search. * = Meta-analysis [Color figure can be
viewed at wileyonlinelibrary.com]
4
|
TRUIJENS ET AL.
 empirical studies that assessed our primary hypothesis. Furthermore, 11 review articles containing the
relevant background information were identified and were kept to cross‐check references in the third search,
see below. The remainder of the findings in the second search again yielded conceptual, theoretical or clinical
discussions rather than empirical research and were therefore excluded from our corpus of empirical
literature. The third search resulted in the identification of two empirical studies that covered our primary
hypothesis, eight meta‐analyses that covered our second additional hypothesis, and one meta‐analysis that
contained empirical findings concerning our third additional hypothesis. Another 86 review articles were
identified based on a keyword hit in the abstract, but none of these contained empirical information regarding
our hypotheses. Additionally, the meta‐analysis that was found to cover our third hypothesis was replicated.
This replication search resulted in 15 empirical studies that were published after the meta‐analysis. Full
reference lists of all included and excluded papers are available upon request. In the following section, we
present the results of the literature review ordered per hypothesis.
Hypothesis 1
Is manual‐based psychotherapy more effective than the same kind of psychotherapy applied
without a manual?
In the first step, we examined the hypothesized superiority of manual‐based psychotherapy over the same kind
of psychotherapy applied without a manual. Only six studies were identified that directly assessed this primary
hypothesis. One study showed manual use superiority. Three studies demonstrated that the efficacy of manualized
and nonmanualized treatments did not differ. Two studies observed that nonmanualized psychotherapy was more
effective. Table 1 shows the quality assessment by means of the Jadad Scale (cf. Jadad et al., 1996) and conclusions
about manual superiority.
Schulte, Künzel, Pepping, and Schulte‐Bahrenberg (1992) tested the effectiveness of a manualized and a
nonmanualized cognitive‐behavioral therapy (CBT) for phobias. The nonmanualized treatment was planned by the
therapist based on a functional analysis of the problems of the individual client (Schulte, 1981), using a nonspecified
amount and order of cognitive‐behavioral techniques. In the manualized condition, the order and type of cognitive‐
behavioral techniques was specified a priori and without preliminary information on the nature of the client’s
phobic anxiety complaints. The manualized treatment was found to be more effective. The difference was explained
by the exceptional effectiveness of “direct exposure” for the treatment of phobias: Nonmanualized treatment that
included direct exposure appeared to be as effective as the manualized treatment that included direct exposure. In
other words, when therapists were as prone to use this technique in nonmanualized treatment as they would be in
manualized treatment, the difference in effect would nullify. This suggests the utility of a manual as an impetus for
therapists for using a specific technique. Translated to evidence for manual use, however, this suggests a
moderating role of the manual to disseminate specific effective interventions at most, but it does not yield support
for the efficacy of manualized treatment per se.
Van Hout, Emmelkamp, Koopmans, Bögels, and Bouman (1994) conducted a similar study on CBT for obsessive–
compulsive disorders. They did not find a difference in effectiveness between the manualized and the nonmanualized
treatment. In his/her doctoral research, Fane (1998) did not find differences between manual‐based group therapy for
sexual offenders and nonmanualized group therapy with regard to aggression and attitude management. As the report
was not published, no information on the quality of the assessment was available, hence quality assessment was not
applicable. Morgenstern, Blanchard, Morgan, Labouvie and Hayaki (2001) compared the effectiveness of a manualized
CBT to a nonmanualized CBT and treatment‐as‐usual (TAU) for addiction. In the TAU condition, therapists were instructed
to provide therapy as they would to their regular clients but to use no CBT techniques. Therapists in all conditions
received comparable supervision. No efficacy differences were found for either one of the therapies.
Ghaderi (2006) showed that for bulimia nervosa both a manualized version of CBT and a nonmanualized version are
effective although the nonmanualized version showed a lower level of nonresponding patients and a lower level of relapse.
The nonmanualized therapy was based on continuous logical functional analysis, the manualized therapy followed the
TRUIJENS ET AL.
|
5
 TABLE 1
Qualitative evaluation and findings in empirical literature regarding Hypothesis 1
Quality assessment
References
Randomization
Double‐blind
Withdrawals and
dropout reported
Clear inclusion and
exclusion criteria
Clear description
of interventions
Total score
out of 5
Findings
Schulte et al. (1992)
+
−
+
+
+
4
Manual superiority
van Hout, Emmelkamp,
Koopmans, Bögels,
and Bouman
et al. (1994)
+
?
+
+
+
4
No difference
Fane (1998)
?
?
?
?
?
N/A
No difference
Morgenstern,
Blanchard, Morgan,
Labouvie, and
Hayaki (2001)
?
−
+
+
+
3
No difference
Barabasz and
Barabasz (2006)
+
−
?
+
+
3
Manual inferiority
Ghaderi (2006)
+
−
+
+
+
4
Manual inferiority
Note. Total score based on criterion 1: randomization to 5, clear description of interventions, with 1 point per criterion scored with “+.”
“+”: yes, “−”: no, “?”: not reported.
6
|
TRUIJENS ET AL.
 manual of Fairburn, Marcus, and Wilson (1993). In the same year Barabasz and Barabasz (2006) investigated
hypnotherapy for complicated irritable bowel syndrome. They found that manualized hypnotic inductions were less
effective than tailored hypnotic inductions, although patients in both conditions showed improvement.
The six studies that conducted a direct comparison of manualized and nonmanualized psychotherapy do not support
the hypothesized superiority of manual‐based psychotherapy. On the contrary, three studies found no substantial
difference, two observed the opposite, and the single study that supports superiority starts from a single specific
intervention that appeared to be exceptionally effective, regardless of the administration via a manual. If we control for
quality and exclude studies with a score of three out of five possible points or lower, still, one inconclusive, one negative,
and one indifferent result remain. This suggests that there is no sound evidence for the superiority of manualized therapy.
Yet, the limited amount of rigorous studies prevents from drawing firm conclusions on this vital hypothesis on evidence‐
based treatment. Given the lack of support for the direct hypothesis of manual superiority, we formulated two additional
hypotheses that may support manual superiority indirectly.
Hypothesis 2
Are effect sizes of manual‐based therapies larger for manual‐based than for nonmanualized
treatments?
Secondly, we evaluated whether in psychotherapy efficacy studies that use no‐treatment, delayed‐treatment,
minimal treatment or alternative treatment control groups, larger effect sizes can be observed for manual‐based
therapies than for non‐manual‐based therapies. To measure psychotherapy efficacy, researchers usually calculate
the difference between pretreatment and posttreatment symptom scores in an experimental/treatment condition
and a control condition, often using effect sizes to indicate the strength of the found differences (Olejnik & Algina,
2000). Eight meta‐analyses addressed the average effect size of manualized and nonmanualized psychotherapy
efficiency studies. Three of these concluded that manual‐based therapies were superior, but four found no
difference, and one observed the opposite. Table 2 gives an overview of the types of control conditions that were
included in each meta‐analysis as well as their findings towards manual superiority.
A meta‐analysis on the efficiency of short‐term psychodynamic treatments (Anderson & Lambert, 1995) found that
studies using manuals showed a higher effect size than studies of nonmanualized treatments on follow‐up measurements
TABLE 2
Features and findings in the empirical literature regarding Hypothesis 2
No‐treatment, delayed treatment
and/or minimal treatment control
group included
Alternative treatment
control group included
Finding
Anderson and Lambert
(1995)a
Yes
Yes
Manual superiority
DiGiuseppe and Tafrate
(2003)a
Yes
Yes
Manual superiority
Stewart and Chambless
(2009)a
Yes
No
Manual superiority
Robinson et al. (1990)a
Yes
Yes
No difference
Shadish and Baldwin (2005)a Yes
Not specified
No difference
Shadish, Navarro, Matt, and
Philipps (2000)a
Yes
No
No difference
Saini (2009)a
Yes
Yes
No difference
Wright et al. (2007)a
Yes
No
Manual inferiority
aMeta‐analysis.
TRUIJENS ET AL.
|
7
 (if specified, follow‐up measures were administered either within or after 6 months posttreatment). Yet, the difference
immediately after the intervention was not statistically significant. In a meta‐analysis on treatments for anger, DiGiuseppe
and Tafrate (2003) considered manual usage as a covariate and observed that using a manual yielded significantly higher
effect sizes. Stewart and Chambless (2009) also found larger effect sizes in case of manual‐use.
Robinson, Berman, and Neimeyer (1990) did a meta‐analysis of efficiency studies of psychotherapies for
depression. They found no difference in effect size between manual‐based and nonmanualized treatments. Shadish,
Navarro, Matt and Phillips (2000) developed criteria to score the clinical representativeness of psychotherapy
efficiency studies and conducted a meta‐analysis to examine if these criteria were related to effect size. One of the
criteria that they used was the use of a therapy manual. The analysis showed that in a highly clinically
representative sample of psychotherapy efficiency studies and also in a randomly selected sample there was no
association between effect size and the use of a treatment manual. More recent studies using the same coding
system found comparable results (Shadish & Baldwin, 2005). In a meta‐analysis on treatments for anger, Saini
(2009) also observed that no statistically significant difference in effect size could be observed between manual‐
based and non‐manual‐based therapies. Finally, one study observed a strong negative association between effect
size and the use of therapy manuals (Wright, Sabourin, Mondor, McDuff, & Mamodhoussen, 2007).
As the Jadad Scale is designed for trials, quality could not formally be scored for the identified meta‐analyses.
Nonetheless, we checked whether the meta‐analyses took the criteria of our Jadad Scale into account in the
selection of their corpus of literature. Randomization was used as a criterion in four out of eight meta‐analyses
(Saini, 2009; Shadish & Baldwin, 2005; Shadish, Navarro, Matt & Phillips, 2000; Stewart & Chambless, 2009).
Wright et al. (2007) mentioned randomization but did not use it as an eligibility criterion. Wright et al. (2007) did
select studies based on the clarity of their interventions. Furthermore, none of the papers reported whether
randomization, double‐blind assessment, withdrawals or dropouts, inclusion or exclusion criteria or description of
interventions were described in the studies incorporated in the meta‐analyses. Therefore, as the study quality has
not been evaluated systematically, the results of these meta‐analyses should be interpreted with care.
In sum, three meta‐analyses of the average effect size of psychotherapy efficacy studies show an advantage for
studies employing manuals, one shows a disadvantage and four find no relation between manual use and effect size.
These results are heterogeneous because of the varying nature of the control conditions that were entertained in
the reviewed studies. A number of meta‐analyses included alternative treatment control groups besides
no‐treatment, delayed treatment or minimal treatment control groups (see Table 2). As the comparison between
manualization and nonmanualization is less straightforward in the case of alternative treatment, inclusion of
alternative treatment control groups might limit the discriminative power to demonstrate the hypothesized
differences. If we only consider the meta‐analyses that compared manualized treatment to no‐treatment, delayed
treatment or nonmanualized minimal treatment control groups, the results remain inconclusive, as one finds
manual use superiority, one finds manual use inferiority and one finds no difference. Taken together, the reviewed
studies don’t provide sound support for the hypothesis that manualized psychotherapies yield larger effect sizes
than nonmanualized psychotherapies.
Hypothesis 3
Is manual adherence indicative of effectiveness of treatment?
Third, we studied the hypothesis that low adherence to a treatment manual is related to lowered treatment
effectiveness. We identified one meta‐analysis that investigated the association between treatment adherence and
treatment efficacy in psychotherapy (Webb et al., 2010). The meta‐analysis included 32 studies that either (a) investigated
individual psychotherapy; (b) included a quantifiable measure of both adherence and treatment outcome assessed no later
than 6 months after treatment termination; (c) assessed adherence based on videotaped, audiotaped, or transcribed
therapy sessions rated by experts or trained raters; (d) included a clinical population; (e) comprised at least five patients in
each of the treatment groups; and (f) were published in English. Analysis showed that there was no association between
adherence and treatment efficiency in the overall sample or for any specific disorder.
8
|
TRUIJENS ET AL.
 TABLE 3
Qualitative evaluation and findings in empirical literature regarding Hypothesis 3
Quality assessment
Findings
References
Randomization
Double‐blind
Withdrawals and
dropout reported
Clear inclusion and
exclusion criteria
Clear description of
interventions
Total score
out of 5
Found relationship
adherence and outcome
Webb et al. (2010)a
N/A
N/A
N/A
N/A
N/A
N/A
Inconclusive
Haug et al. (2016)
+
−
+
+
+
4
Positive relationship
Schoenwald
et al. (2009)
‐
?
−
+
+
2
Positive relationship
Sexton and
Turner (2010)
+
?
−
+
+
3
Positive relationship
Strunk et al. (2010)
+
?
−
+
−
2
Positive relationship
Suchman et al. (2012)
+
?
+
+
+
4
Positive relationship
Weck et al. (2015)
−
?
−
+
+
2
Positive relationship
Boswell et al. (2013)
−
?
+
+
+
3
No relationship
Brown et al. (2013)
−
?
−
+
+
2
No relationship
Campos‐Melady (2013)
?
?
?
?
?
0
No relationship
Weck et al. (2014)
−
?
−
+
+
2
No relationship
Weck et al. (2015)
−
?
−
?
+
1
No relationship
Weck et al. (2013)
−
?
−
+
+
2
No relationship
Robbins et al. (2011)
+
?
−
+
+
3
Partially positive
relationship
Webb et al. (2012)
+
?
−
+
−
2
Partially positive
relationship
Hauke et al. (2014)
+
?
+
+
+
4
Partially negative
relationship
Note: Total score based on criterion: 1, randomization to 5, efficacy of manuals as hypothesis, with 1 point per criterion scored with “+.”
“+”: yes; “−”: no; “?”: not reported.
ameta‐analysis (quality control scale not applicable).
TRUIJENS ET AL.
|
9
 Additionally, we replicated the search by Webb et al. (2010) to identify papers that were published since the
time of their review. Sixteen papers were found by using the same search term and inclusion criteria as were used
by Webb et al. (2010), of which one was excluded (Chapman & Schoenwald, 2011) as the article was based on the
same data analysis as a previous study (Schoenwald, Sheidow, & Chapman, 2009). Table 3 shows the quality
assessment by means of the Jadad Scale (cf. Jadad et al., 1996) and conclusions about manual superiority.
Five of the studies found a positive association of treatment adherence and efficiency (Haug et al., 2016;
Schoenwald et al., 2009; Sexton & Turner, 2010; Strunk, Brotman, & DeRubeis, 2010; Suchman, Decoste,
Rosenberger, & McMahon, 2012) and six found no relation between treatment adherence and efficiency (Boswell
et al., 2013; Brown et al., 2013; Campos‐Melady, 2013, Weck et al., 2013; Weck, Grikscheit, Höfling, & Stangier,
2014; Weck, Richtberg, Jakob, Neng, & Höfling, 2015). One study found a positive association between treatment
adherence and efficiency in one sample and no relation in a second sample (Webb et al., 2012). One study found a
positive association between treatment adherence and efficiency for some but not all outcome measures (Robbins
et al., 2011). One study found a negative association between treatment adherence and some but not all outcome
measures (Hauke et al., 2014). Weck, Grikscheit, Jakob, Höfling, and Stangier (2015) compared only treatment
outcomes for participants that were classified as treatment failure or clear treatment, pertaining to 37% of all
participants that were treated. In this selective sample they found a positive association between treatment
adherence and outcome.
In sum, before April 2009, 32 studies addressed the relation between manual adherence and treatment
efficiency, and hitherto another 15 studies were published on the topic. Given the ambiguity and the often
insufficient quality in the corpus of recent studies, the findings remain as inconclusive as the body of literature
analyzed by Webb et al. (2010). Therefore, their conclusion that better manual adherence does not automatically
entail higher treatment effectiveness was not substantially challenged by recent empirical literature. Although this
leaves the question of an association between adherence and treatment efficiency open for discussion, the findings
are insufficient as proof of indirect evidence for manual use superiority.
4
|
DISCUSSION
In the paradigm of evidence‐based treatment, manual‐based treatments are increasingly implemented both in
clinical practice and training to secure the dissemination of empirically supported psychotherapies. This rests on
the assumption that manual‐based treatment is more effective than nonmanualized treatment. In this paper, we
systematically reviewed the available empirical evidence for this basic assumption based on the primary hypothesis
that (a) manual‐based psychotherapy is more effective than the same kind of psychotherapy applied without a
manual; and two additional indirect hypotheses that (b) in no‐treatment, delayed‐treatment, minimal treatment or
alternative treatment control groups, manual‐based therapies yield larger effect sizes than non‐manual‐based
therapies, and that (c) good manual adherence entails higher effectiveness. A notably small body of literature was
found that directly or indirectly addressed the efficacy of manualization.
The primary hypothesis of the superiority of manualized treatment over nonmanualized treatment was not
supported by the available empirical literature. For the first hypothesis, only six studies were identified that directly
assessed the primary assumption of manual superiority. Out of these six, four studies showed no difference
between manualized and nonmanualized treatment, and two studies proved the opposite, indicating that
nonmanualized psychotherapy is actually more effective. The only study that found manualized treatment to be
superior was explained by the effect of a specific exposure intervention (Schulte et al., 1992). This example
showcases the simple logic that it is more effective to offer an effective intervention than not to offer the same
technique. As exposure techniques often meet with reluctance from therapists, which prohibits patients
from optimally benefiting from the intervention (cf. Powers & Deacon, 2013), these findings underscore the fact
that therapists should be informed about scientific evidence, and hence that treatment manuals may be utilized as
10
|
TRUIJENS ET AL.
 an impetus to disseminate effective techniques (cf. Wampold & Imel, 2015, for a discussion). However, this utility
still does not support the assumption that manualized treatment is more effective than nonmanualized treatment
per se.
Given the limited and inconclusive empirical support for the primary hypothesis in evidence‐based treatment, in
the second step, we reviewed the literature for indirect evidence of manual superiority. For this purpose, we
specified two additional hypotheses that should at least be satisfied if the use of manuals were to be favored in the
dissemination of EBTs. Specifically, empirical support would be needed to propose the manual as a moderator for
treatment efficacy. Concerning the second hypothesis, three meta‐analyses indicated that manual‐based therapies
were superior, four found no difference, and one observed that nonmanualized psychotherapies actually yielded
larger effect sizes. A correction for quality of the included empirical studies would not leave out much literature.
Here, we have to remark that it is fairly complex to meaningfully compare effect sizes of treatments that are so
different in nature, given their varied understanding and operationalization of treatment, control groups, diagnosis,
and outcome. First and foremost, this underlines how the universal hypothesis of manual efficacy is in trouble with
respect to empirical support, both as a direct and as a moderating factor.
With respect to the third hypothesis, one meta‐analysis concluded that manual adherence does not affect
outcome, and 15 additional studies provided inconclusive results. If manuals themselves were to have an impact on
treatment efficacy, then, at least a less strict application of manuals should yield a lowered treatment outcome. In
line with the conclusion of Webb et al. (2010), we did not find sound evidence for this indirect hypothesis of manual
superiority. Of the 15 studies that were conducted after the meta‐analysis of Webb et al. (2010), five found a
positive relationship between adherence and treatment efficiency. These should be taken into consideration
despite the contrasting results with the remainder of the corpus, as it is more common to assume that there is no
association while there could be one (i.e. type II error) than to assume an association while there is none (i.e., type I
error; cf. Mook & Parker, 2001). As such, the suggestion that adherence and fidelity to treatment principles may
impact a positive treatment outcome remains a worthwhile avenue for further research. However, as an indicator
for efficacy of the manual as a general principle for clinical practice, this conflicting body of evidence is insufficient.
Moreover, it challenges the proposed moderating role of manuals towards treatment effect. With regard to clinical
practice, this finding does not necessarily dispute the utility of manuals for training and dissemination of effective
interventions, yet it does refute the a priori requirement of manuals for psychological treatment.
Overall, this review shows that the hypothesized superiority of manual‐use in psychotherapy cannot be
established, which points to a severe problem in the justification of EBT dissemination. The current study was set
up to review the direct evidence for a crucial basic assumption that is embedded in general clinical
recommendations. Given the small number of studies that directly assessed the primary hypothesis of manual‐
based psychotherapy, we also gathered evidence for two additional indirect hypotheses. None of these hypotheses
yielded substantial evidence nor even a sound and systematic consideration of the superiority of manual use. Based
on these limited and inconclusive findings, it might be argued that clinical practice is becoming influenced by a
standardized approach that does not live up to its own claim of superiority in comparison to regular
psychotherapies in which clinicians take individual and non‐controllable decisions for each separate client.
In interpreting this literature review, a number of limitations have to be taken into account. First, given the
indirect nature of the additional hypotheses, the search was notably heterogeneous. This is due to the remarkably
small number of studies that focused on the primary hypothesis, which urged us to add two indirect hypotheses. It
is striking that only six studies—of which a substantial part was published before the rise in popularity of EBT—
directly entertained the most basic assumption of EBT, notwithstanding the 350 manual‐based treatments that are
recognized as EBT today (cf. Kazdin, 2015). Therefore, this limitation may be taken as exemplary of a vital limitation
in the evidence‐base of EBT in psychotherapy. Second, given the limited number of articles found that addressed
our research questions directly, we did not find further leads to identify additional or unpublished data. We would
expect, however, that if such data were available, they would surely be published. Third, the current study does not
yield a meta‐analysis of the found empirical evidence. As the primary hypothesis was covered by only six studies
TRUIJENS ET AL.
|
11
 that either did not indicate a difference or favored nonmanualized over manualized treatment, a meta‐analysis
would not have added to the conclusion of lacking evidence of manual‐based treatment. Moreover, as the indirect
hypotheses did not contain a sound or similar means of assessing manual superiority, conducting a meta‐analysis on
indirect and methodologically divergent studies would have been methodologically questionable as well as
undermining the signalization of the fundamental lack of empirical interest in the primary assumption. Finally, in
this study, we did not distinguish between evidence for specific disorders. As the APA, NICE and other (inter)
national institutions stimulate manual‐based treatment as a basic principle in treatment guidelines, we treated the
evidence likewise. However, specification of the evidence for disorders, symptom severity and chronicity, and
specific patient populations, could be utilized in future research to specify the feasibility of manual‐based treatment
for specific clinical cases. Based on this review, we are not inclined to call for more research to settle the dispute
about manualization in general; rather, we urge both researchers and clinicians to go beyond the dichotomy, as the
next step in understanding what works for whom in psychotherapy.
It is crucial to note that, in the first place, psychotherapy manuals are not developed as practice guidelines but
as tools for standardization in clinical research (Vanheule, 2009). In the EBT paradigm, a form of psychotherapy can
be established as evidence‐based if its efficacy has been shown in at least two independent randomized controlled
trials or similarly controlled and systematic research designs (Chambless & Hollon, 1998). The logic behind this
study design is called “interventionist causality” (Kendler & Campbell, 2009): If an experimental and a control group
are identical except for the intervention, then a difference in the “outcome” must be due to the intervention.
With this logic, it is crucial that the intervention is identical for every participant in the experimental group;
otherwise, the found differences could be due to arbitrary sample differences instead of the intervention itself
(Woodward, 2003). Therefore, the function of psychotherapy manuals is to standardize the intervention such that
causal statements on the efficacy of psychotherapy are enabled (cf. Woodward, 2003). Consequently, evidence is
systematically gathered for manualized treatments, which does not imply that manual‐based treatment is more
effective but merely that manualized treatment is methodologically favored.
Indeed, if an outcome study supports the efficacy of a manualized therapy, this does not support the use of the
manual itself but it implies that certain “ingredients” of the intervention that were specified in the manual work.
Illustrative is the study of Schulte et al. (1992), in which the advantage found for manual‐based cognitive‐behavioral
treatment for phobias appeared to be due to the exceptional effectiveness of a specific therapeutic technique rather
than due to the application of the manual per se. This example shows that whether a therapy should be manualized
or nonmanualized is not the right question to ask. Far more important is to understand what it is that works within a
specific treatment approach and for whom (cf. Wampold & Imel, 2015). Moreover, it is not necessary that “what
works” is limited to one specific ingredient—such as the specific exposure for phobias—that works for each
demarcated diagnosis.
This thesis is central to a promising line of inquiry pioneered by Chorpita, Daleiden, and Weisz (2005a, 2005b)
among others (cf. Norcross, Levant, & Beutler, 2005). This line of research focuses on individualized manualization,
in which an experienced therapist can select different manual‐based modules that can be custom‐fit to the needs,
complaints and preferences of individual patients. This could furthermore allow for a transdiagnostic approach of
comorbid symptomatology, as it moves away from a pre‐set diagnosis‐based treatment plan and towards therapy
based on core processes in individually experienced and possibly overlapping complaints (Kazdin, 2015).
Importantly, this line of research does not provide universal support for efficacy of “the manual” per se but it does
promote manualized interventions as tools within an interpersonal therapeutic context. This is in line with the
clinical integration of theory, scientific evidence and clinical experience that is being increasingly promoted as
evidence‐based practice (cf. APA Presidential Task Force on Evidence‐Based Practice, 2006), and suggests the
value of individualization beyond a more general promotion of a one‐size‐fits‐all manualization.
The current lack of empirical support for the assumed superiority of manuals as a universal principle for clinical
practice urges researchers to rethink the function of their evidence. Instead of taking the evidence for using an effective
treatment manual as a conclusion, it should be taken as a starting point to investigate which components of the therapy,
12
|
TRUIJENS ET AL.
 and which steps in the therapy process make the manual work. In this, the current general dichotomy between manualized
and nonmanualized treatment is not fruitful. Indeed, it arrests researchers’ and stakeholders’ interest at the level of the
manual and at the level of the sample, which is neither an epistemically nor clinically fruitful imperative (cf. Desmet, 2013;
Truijens, 2016). Epistemic progress seems to require that the researcher does not embrace manual‐use a priori and
generally but carefully scrutinizes when, why and how specific techniques can be utilized in clinical practice.
Importantly, to get beyond the dichotomy, it is similarly crucial for clinicians to not reject manuals a priori, as that
would merely be a rejection of form. Yet the content of treatments could be improved if clinicians try specific techniques
and treatment plans. This asks for going beyond the manual/non‐manual dichotomy but just as well beyond the divide
between researchers and clinicians. Only a joint effort between researchers and clinicians will provide both epistemic
and clinical progression. Moreover, to elucidate processes that explain therapeutic success or failure it seems crucial to
study specific (series of) cases that allow for a close look at clinical situations, focusing on how specific interventions—
manualized or nonmanualized—foster or hinder change. Along this way, the ethos of EBT ‐ disseminating research
findings to clinical practice ‐ might be established much better than by promoting manuals as such.
ACKNOWLEDGEMENTS
The authors thank Dr. Alvin Westmaas (University of Amsterdam) for providing internship supervision, Drs Rosa
De Geest (Ghent University) for collaboration at the conference and the Department of Psychoanalysis and Clinical
Consulting (Ghent University) for feedback and support throughout the process.
ORCID
Femke Truijens
http://orcid.org/0000-0003-0790-7003
Stijn Vanheule
http://orcid.org/0000-0001-8580-5809
REFERENCES
Addis, M. E. (1997). Evaluating the treatment manual as a means of disseminating empirically validated psychotherapies.
Clinical Psychology: Science and Practice, 4, 1–11.
Addis, M. E., Cardemil, E. V., Duncan, B. L., & Miller, S. D. (2006). Does manualization improve therapy outcomes? In J. C.
Norcross, L. E. Beutler, & R. F. Levant (Eds.), Evidence‐based practices in mental health: Debate and dialogue on the
fundamental questions (pp. 131–160). Washington, DC, US: American Psychological Association.
Addis, M. E., Wade, W. A., & Hatgis, C. (1999). Barriers to dissemination of evidence‐based practices: Addressing
practitioners’ concerns about manual‐based psychotherapies. Clinical Psychology: Science and Practice, 6, 430–441.
Anderson, E. M., & Lambert, M. J. (1995). Short‐term dynamically oriented psychotherapy: A review and meta‐analysis.
Clinical Psychology Review, 15, 503–514.
APA Presidential Task Force on Evidence‐Based Practice (2006). Evidence‐based practice in psychology. American
Psychologist, 61, 271–285.
Barabasz, A., & Barabasz, M. (2006). Effects of tailored and manualized hypnotic inductions for complicated irritable bowel
syndrome patients. International Journal of Clinical and Experimental Hypnosis, 54, 100–112.
Boswell, J. F., Gallagher, M. W., Sauer‐Zavala, S. E., Bullis, J., Gorman, J. M., Shear, M. K., … Barlow, D. H. (2013). Patient
characteristics and variability in adherence and competence in cognitive‐behavioral therapy for panic disorder. Journal
of Consulting and Clinical Psychology, 81, 443–454.
Brown, L. A., Craske, M. G., Glenn, D. E., Stein, M. B., Sullivan, G., Sherbourne, C., … Rose, R. D. (2013). CBT competence in
novice therapists improves anxiety outcomes. Depression and Anxiety, 30, 97–115.
Campos‐Melady, M. (2013). Therapist adherence and competence as predictors of client outcomes in adolescent substance use
treatment (Unpublished Doctoral dissertation). University of New Mexico, USA.
Chambless, D. L., & Hollon, S. D. (1998). Defining empirically supported therapies. Journal of Consulting and Clinical
Psychology, 66, 7–18.
Chambless, D. L., & Ollendick, T. H. (2001). Empirically supported psychological interventions: Controversies and evidence.
Annual Review of Psychology, 52, 685–716.
TRUIJENS ET AL.
|
13
 Chapman, J. E., & Schoenwald, S. K. (2011). Ethnic similarity, therapist adherence, and long‐term multisystemic therapy
outcomes. Journal of Emotional and Behavioral Disorders, 19, 3–16.
Chorpita, B. C., Daleiden, E., & Weisz, J. R. (2005b). Modularity in the design and application of therapeutic interventions.
Applied & Preventive Psychology, 11, 141–156.
Chorpita, B. F., Daleiden, E. L., & Weisz, J. R. (2005a). Identifying and selecting the common elements of evidence based
interventions: A distillation and matching model. Mental Health Services Research, 7, 5–20.
Desmet, M. (2013). Experimental versus naturalistic psychotherapy research: Consequences for researchers, clinicians,
policy makers and patients. Psychoanalytische Perspectieven, 31, 59–78.
DiGiuseppe, R., & Tafrate, R. C. (2003). Anger treatment for adults: A meta‐analytic review. Clinical Psychology: Science and
Practice, 10, 70–84.
Eifert, G. H., Schulte, D., Zvolensky, M. J., Lejuez, C. W., & Lau, A. W. (1997). Manualized behavior therapy: Merits and
challenges. Behavior Therapy, 28, 499–509.
Fairburn, C. G., Marcus, M. D., & Wilson, G. T. (1993). Cognitive behaviour therapy for binge eating and bulimia nervosa: A
comprehensive treatment manual. In C. G. Fairburn & G. T. Wilson (Eds.), Binge Eating: Nature, Assessment and Treatment
(pp. 361–404). New York: Guilford Press.
Fane, R. B. (1998). The effect of structured and unstructured group therapy on the anger and attitudes of domestic violence
perpetrators (Unpublished doctoral dissertation). University of Louisville, Kentucky, USA.
Garfield, S. L. (1996). Some problems associated with “validated” forms of psychotherapy. Clinical Psychology: Science and
Practice, 3, 218–229.
Ghaderi, A. (2006). Does individualization matter? A randomized trial of standardized (focused) versus individualized
(broad) cognitive behavior therapy for bulimia nervosa. Behaviour Research and Therapy, 44, 273–288.
Hamilton, J. D., Kendall, P. C., Gosch, E., Furr, J. M., & Sood, E. (2008). Flexibility within fidelity. Journal of the American
Academy of Child & Adolescent Psychiatry, 47, 987–993.
Haug, T., Nordgreen, T., Öst, L. G., Tangen, T., Kvale, G., Hovland, O. J., … Havik, O. E. (2016). Working alliance and
competence as predictors of outcome in cognitive behavioral therapy for social anxiety and panic disorder in adults.
Behaviour Research and Therapy, 77, 40–51.
Hauke, C., Gloster, A. T., Gerlach, A., Richter, J., Kircher, T., Fehm, L., & Deckert, J. (2014). Standardized treatment manuals:
Does adherence matter? Sensoria: A Journal of Mind, Brain & Culture, 10, 1–13.
van Hout, W. J., Emmelkamp, P. M., Koopmans, P. C., Bögels, S. M., & Bouman, T. K. (1994). Individualized versus standardized
therapy: A comparative evaluation with obsessive‐compulsive patients. Clinical Psychology & Psychotherapy, 1, 95–100.
Hucker, A., & McCabe, M. P. (2012). Manualized treatment programs for FSD: Research challenges and recommendations.
The Journal of Sexual Mmedicine, 9, 350–360.
Jadad, A. R., Moore, R. A., Carroll, D., Jenkinson, C., Reynolds, D. J. M., Gavaghan, D. J., & McQuay, H. J. (1996). Assessing
the quality of reports of randomized clinical trials: Is blinding necessary? Controlled Clinical Trials, 17, 1–12.
Jones, L. M., & McCabe, M. P. (2011). The effectiveness of an internet‐based psychological treatment program for female
sexual dysfunction. The Journal of Sexual Medicine, 8, 2781–2792.
Kazdin, A. E. (2015). Treatment as usual and routine care in research and clinical practice. Clinical Psychology Review, 42, 168–178.
Kendler, K. S., & Campbell, J. (2009). Interventionist causal models in psychiatry: Repositioning the mind‐body problem.
Psychological Medicine, 39, 881–887.
Marshall, W. L. (2009). Manualization: A blessing or a curse? Journal of Sexual Aggression, 15, 109–120.
Moher, D., Liberati, A., Tetzlaff, J., Altman, D. G., & The PRISMA Group (2009). Preferred reporting items for systematic reviews
and meta‐analyses: The PRISMA statement. PLOS Medicine, 6, e1000097. https://doi.org/10.1371/journal.pmed.1000097
Mook, D. G., & Parker, S. (2001). Psychological research: The ideas behind the methods. New York: Norton.
Morgenstern, J., Blanchard, K. A., Morgan, T. J., Labouvie, E., & Hayaki, J. (2001). Testing the effectiveness of cognitive‐
behavioral treatment for substance abuse in a community setting: Within treatment and posttreatment findings.
Journal of Consulting and Clinical Psychology, 69, 1007–1017.
National Institute for Health and Care Excellence (2009). Depression in adults: recognition and management. Retrieved
from https://www.nice.org.uk/guidance/CG90/chapter/Key‐priorities‐for‐implementation
Norcross, J., Levant, R., & Beutler, L. (2005). Evidence‐based practices in mental health: Debate and dialogue on the fundamental
questions. Washington, DC: American Psychological Association Press.
Olejnik, S., & Algina, J. (2000). Measures of effect size for comparative studies: Applications, interpretations, and
limitations. Contemporary Educational Psychology, 25, 241–286.
Powers, M. B., Deacon, B. J. (Eds.) (2013). Dissemination of empirically supported treatments for anxiety disorders [Special
Issue]. Journal of Anxiety Disorders, 27.
Robbins, M. S., Feaster, D. J., Horigian, V. E., Puccinelli, M. J., Henderson, C., & Szapocznik, J. (2011). Therapist adherence in
brief strategic family therapy for adolescent drug abusers. Journal of Consulting and Clinical Psychology, 79, 43–53.
Robinson, L. A., Berman, J. S., & Neimeyer, R. A. (1990). Psychotherapy for the treatment of depression: A comprehensive
review of controlled outcome research. Psychological Bulletin, 108, 30–49.
14
|
TRUIJENS ET AL.
 Saini, M. (2009). A meta‐analysis of the psychological treatment of anger: Developing guidelines for evidence‐based
practice. Journal of the American Academy of Psychiatry and the Law Online, 37, 473–488.
Schoenwald, S. K., Sheidow, A. J., & Chapman, J. E. (2009). Clinical supervision in treatment transport: Effects on adherence
and outcomes. Journal of Consulting and Clinical Psychology, 77, 410–421.
Schulte, D. (1981). Schema für Probleemanalyse und Therapie Planung, (A framework for problem analysis and therapy
planning). Unpublished manuscript.
Schulte, D., Künzel, R., Pepping, G., & Schulte‐Bahrenberg, T. (1992). Tailor‐made versus standardized therapy of phobic
patients. Advances in Behaviour Research and Therapy, 14, 67–92.
Sexton, T., & Turner, C. W. (2010). The effectiveness of functional family therapy for youth with behavioral problems in a
community practice setting. Journal of Family Psychology, 24, 339–348.
Shadish, W. R., & Baldwin, S. A. (2005). Effects of behavioral marital therapy: A meta‐analysis of randomized controlled
trials. Journal of Consulting and Clinical Psychology, 73, 6–14.
Shadish, W. R., Navarro, A. M., Matt, G. E., & Phillips, G. (2000). The effects of psychological therapies under clinically
representative conditions: A meta‐analysis. Psychological Bulletin, 126, 512–529.
Stewart, R. E., & Chambless, D. L. (2009). Cognitive–behavioral therapy for adult anxiety disorders in clinical practice: A
meta‐analysis of effectiveness studies. Journal of Consulting and Clinical Psychology, 77, 595–606.
Strunk, D. R., Brotman, M. A., & DeRubeis, R. J. (2010). The process of change in cognitive therapy for depression:
Predictors of early inter‐session symptom gains. Behaviour Research and Therapy, 48, 599–606.
Suchman, N. E., Decoste, C., Rosenberger, P., & McMahon, T. J. (2012). Attachment‐based intervention for substance‐using
mothers: A preliminary test of the proposed mechanisms of change. Infant Mental Health Journal, 33, 360–371.
Truijens, F. L. (2016). Do the numbers speak for themselves? A critical analysis of procedural objectivity in
psychotherapeutic efficacy research. Synthese, 194, 4721–4740.
US Department of Health and Human Services (2015). National registry of evidence‐based programs and practices
(NREPP). Retrieved from http://nrepp.samhsa.gov/
Vanheule, S. (2009). Psychotherapy and research: A relation that needs to be reinvented. British Journal of Psychotherapy,
25, 91–109.
Wampold, B. E., & Imel, Z. E. (2015). The great psychotherapy debate. The evidence for what makes psychotherapy work
(2nd ed.). New York: Routledge.
Webb, C. A., DeRubeis, R. J., & Barber, J. P. (2010). Therapist adherence/competence and treatment outcome: A meta‐
analytic review. Journal of Consulting and Clinical Psychology, 78, 200–211.
Webb, C. A., DeRubeis, R. J., Dimidjian, S., Hollon, S. D., Amsterdam, J. D., & Shelton, R. C. (2012). Predictors of patient
cognitive therapy skills and symptom change in two randomized clinical trials: The role of therapist adherence and the
therapeutic alliance. Journal of Consulting and Clinical Psychology, 80, 373–381.
Weck, F., Grikscheit, F., Höfling, V., & Stangier, U. (2014). Assessing treatment integrity in cognitive‐behavioral therapy:
Comparing session segments with entire sessions. Behavior Therapy, 45, 541–552.
Weck, F., Grikscheit, F., Jakob, M., Höfling, V., & Stangier, U. (2015). Treatment failure in cognitive‐behavioural therapy:
Therapeutic alliance as a precondition for an adherent and competent implementation of techniques. British Journal of
Clinical Psychology, 54, 91–108.
Weck, F., Richtberg, S., Jakob, M., Neng, J. M. B., & Höfling, V. (2015). Therapist competence and therapeutic alliance are
important in the treatment of health anxiety (hypochondriasis). Psychiatry Research, 228, 53–58.
Weck, F., Rudari, V., Hilling, C., Hautzinger, M., Heidenreich, T., Schermelleh‐Engel, K., & Stangier, U. (2013). Relapses in
recurrent depression 1 year after maintenance cognitive‐behavioral therapy: The role of therapist adherence,
competence, and the therapeutic alliance. Psychiatry Research, 210, 140–145.
Westen, D., Novotny, C. M., & Thompson‐Brenner, H. (2004). The empirical status of empirically supported
psychotherapies: Assumptions, findings, and reporting in controlled clinical trials. Psychological Bulletin, 130, 631–663.
Wilson, G. T. (1997). Treatment manuals in clinical practice. Behaviour Research and Therapy, 35, 205–210.
Woodward, J. (2003). Making things happen: A theory of causal explanation. Oxford: Oxford University Press.
Wright, J., Sabourin, S., Mondor, J., McDuff, P., & Mamodhoussen, S. (2007). The clinical representativeness of couple
therapy outcome research. Family Process, 46, 301–316.
How to cite this article: Truijens F, Zühlke‐Van Hulzen L, Vanheule S. To manualize, or not to manualize: Is
that still the question? A systematic review of empirical evidence for manual superiority in psychological
treatment. J. Clin. Psychol. 2018;1–15. https://doi.org/10.1002/jclp.22712
TRUIJENS ET AL.
|
15
