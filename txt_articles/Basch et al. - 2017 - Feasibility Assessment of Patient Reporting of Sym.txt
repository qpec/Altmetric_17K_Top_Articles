 Feasibility Assessment of Patient Reporting of Symptomatic
Adverse Events in Multicenter Cancer Clinical Trials
Ethan Basch, MD, MSc; Amylou C. Dueck, PhD; Lauren J. Rogak, MA; Lori M. Minasian, MD;
William Kevin Kelly, DO; Ann M. O’
Mara, PhD, RN; Andrea M. Denicoff, MS, RN, ANP; Drew Seisler, BS;
Pamela J. Atherton, MS; Electra Paskett, PhD; Lisa Carey, MD; Maura Dickler, MD; Rebecca S. Heist, MD, PhD;
Andrew Himelstein, MD; Hope S. Rugo, MD; William M. Sikov, MD; Mark A. Socinski, MD; Alan P. Venook, MD;
Douglas J. Weckstein, MD; Diana E. Lake, MD; David D. Biggs, MD; Rachel A. Freedman, MD, MPH;
Charles Kuzma, MD; Jeffrey J. Kirshner, MD; Deborah Schrag, MD, MPH
IMPORTANCE In cancer clinical trials, symptomatic adverse events (AEs), such as nausea, are
reported by investigators rather than by patients. There is increasing interest to collect
symptomatic AE data via patient-reported outcome (PRO) questionnaires, but it is unclear
whether it is feasible to implement this approach in multicenter trials.
OBJECTIVE To examine whether patients are willing and able to report their symptomatic AEs
in multicenter trials.
DESIGN, SETTING, AND PARTICIPANTS A total of 361 consecutive patients enrolled in any 1 of 9
US multicenter cancer treatment trials were invited to self-report 13 common symptomatic
AEs using a PRO adaptation of the National Cancer Institute’
s Common Terminology Criteria
for Adverse Events (CTCAE) via tablet computers at 5 successive clinic visits. Patient
adherence was tracked with reasons for missed self-reports. Agreement with clinician AE
reports was analyzed with weighted κ statistics. Patient and investigator perspectives were
elicited by survey. The study was conducted from March 15, 2007, to August 11, 2011. Data
analysis was performed from August 9, 2013, to March 21, 2014.
RESULTS Of the 361 patients invited to participate, 285 individuals enrolled, with a median
age of 57 years (range, 24-88), 202 (74.3%) female, 241 (85.5%) white, 73 (26.8%) with a
high school education or less, and 176 (64.7%) who reported regular internet use
(denominators varied owing to missing data). Across all patients and trials, there were 1280
visits during which patients had an opportunity to self-report (ie, patients were alive and
enrolled in a treatment trial at the time of the visit). Self-reports were completed at 1202
visits (93.9% overall adherence). Adherence was highest at baseline and declined over time
(visit 1, 100%; visit 2, 96%; visit 3, 95%; visit 4, 91%; and visit 5, 85%). Reasons for missing
PROs included institutional errors in 27 of 48 (56.3%) of the cases (eg, staff forgetting to
bring computers to patients at visits), patients feeling “too ill” in 8 (16.7%), patient refusal in 8
(16.7%), and internet connectivity problems in 5 (10.4%). Patient-investigator CTCAE
agreement was moderate or worse for most symptoms (most κ < 0.05), with investigators
reporting fewer AEs than patients across symptoms. Most patients believed that the system
was easy to use (234 [93.2%]) and useful (230 [93.1%]), and investigators thought that the
patient-reported AEs were useful (133 [94.3%]) and accurate (119 [83.2%]).
CONCLUSIONS AND RELEVANCE Participants in multicenter cancer trials are willing and able to
report their own symptomatic AEs at most clinic visits and report more AEs than
investigators. This approach may improve the precision of AE reporting in cancer trials.
JAMA Oncol. 2017;3(8):1043-1050. doi:10.1001/jamaoncol.2016.6749
Published online February 16, 2017.
Editorial page 1029
Author Audio Interview
Related article page 1035
Supplemental content
Author Affiliations: Author
affiliations are listed at the end of this
article.
Corresponding Author: Ethan Basch,
MD, MSc, Lineberger Comprehensive
Cancer Center, Department of
Medicine, School of Medicine,
University of North Carolina Physician
Office Building, Room CB 7305, 170
Manning Dr, Chapel Hill, NC 27516
(ebasch@med.unc.edu).
Research
JAMA Oncology | Original Investigation
(Reprinted)
1043
© 2017 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/03/2019
 I
n cancer trials, it is standard practice for clinical investiga-
tors to report adverse events (AEs) using the US National
CancerInstitute’
s(NCI’
s)CommonTerminologyCriteriafor
Adverse Events (CTCAE).1 The CTCAE is a library of items rep-
resenting approximately 800 discrete AEs graded using a
5-point numerical grading system, with each grade anchored
to discrete clinical criteria. Approximately 10% of CTCAE items
representsymptoms(eg,nauseaandsensoryneuropathy)that,
like nonsymptom AEs (eg, neutropenia and retinal detach-
ment), have historically been reported by investigators and not
by patients.2 However, there is empirical evidence that inves-
tigators miss up to half of symptomatic AEs, that clinician in-
terrater reliability for reporting symptomatic AEs is generally
low, and that collection of this information directly from study
participants as patient-reported outcomes (PROs) may
improve the reliability and precision of symptomatic AE
detection.3-7
Patient-reported outcomes are the standard used in clini-
cal trials for measurement of health-related quality of life,
physical functioning, and disease-related symptoms and are
of growing interest in hospital quality assessment and com-
parative effectiveness research.8-14 In 2005, the Food and Drug
Administration published a draft guidance document (final-
ized in 2009) recommending the use of PROs whenever mea-
suring concepts in clinical trials that are best evaluated from
the patient’
s perspective,15 with a similar statement from the
European Medicines Agency.16
Although PROs are increasingly used in these other con-
texts,theyarenotyetstandardforAEreportinginclinicaltrials.
The need for such an approach is particularly salient in oncol-
ogy given that cancer therapies often carry substantial toxic-
ity burdens that contribute to treatment nonadherence, dis-
continuation, dose reduction, and discomfort.17-20 In a survey
of more than 700 cancer clinical investigators and research
staff, more than 90% believed that patient reporting of symp-
tomaticAEscouldimprovedatacompleteness,accuracy,mean-
ingfulness, and actionability compared with the current stan-
dard approach based on physician reporting.21 Single-center
studies have demonstrated that collecting symptomatic AE
information via the internet from patients receiving chemo-
therapy is feasible.22,23
Therefore, the NCI supported a national cooperative group
study to assess the feasibility of asking patients to report
their symptomatic AEs using plain language items based on
CTCAE,version3.0,22,23viaaweb-basedplatform24duringpar-
ticipation in national multicenter NCI-sponsored cancer trials.
Methods
Patients and Sites
Patients enrolled in any 1 of 9 US national multicenter cancer
trials supported by the NCI were eligible for simultaneous par-
ticipation in this Cancer and Leukemia Group B (CALGB) cor-
relative PRO feasibility study (CALGB 70501; clinicaltrials.gov,
NCT00417040). The CALGB study is now part of the Alliance
for Clinical Trials in Oncology. Patients could be registered to
the PRO feasibility study at any time up until and including the
second scheduled visit (cycle 2 of therapy). Included were 4
breast cancer trials,25-28 1 colorectal cancer trial,29 2 lung can-
cer trials,30,31 1 prostate cancer trial,32 and 1 supportive care
trial.33 (eTable 1 in the Supplement provides details of each
trial.) This PRO feasibility study was approved by the institu-
tional review board at each accruing site (eAppendix in the
Supplement), and all participants provided written informed
consent that was separate from their consent to enroll in the
associated treatment trial.
At each site, clinical research professionals (CRPs) under-
went a standardized 20-minute, web-enabled teleconfer-
ence before initiation of enrollment to learn how to use a se-
cureonlinequestionnairesystemthathasbeenusabilitytested
andemployedinmultiplepreviousstudies.22-24TheCRPswere
taught how to register patients into the system and adminis-
tersymptomquestionnairestopatientsviawirelesstabletcom-
puters. Sites were assessed for wireless internet connectivity
in clinic waiting areas and the availability of computers, and
wireless tablet computers and/or wireless connection hard-
ware were provided to sites when needed.
Consecutive patients enrolled in the treatment trials were
approached and invited to participate in the feasibility study
if they were able to read and comprehend English and able to
see a computer screen or were accompanied by a companion
who could read a screen to the patient. Reasons for refusal to
participate were systematically tracked. At the time of enroll-
ment, site CRPs educated each participant to complete self-
reported questions via tablet computers using a 10-minute
standardized training session.
Questionnaire and Administration
The AE patient questionnaire included plain language items
based on CTCAE, version 3.0 (eTables 2 and 3 in the Supple-
ment). These items served as a basis for the NCI’
s recently de-
veloped PRO-CTCAE item library.34,35 Specifically, patients
completed questions about 13 symptomatic AEs, including an-
orexia (appetite loss), constipation, cough, diarrhea, dyspnea
(shortnessofbreath),fatigue,handorfootreactionorrash,mu-
cositis (mouth sores), nausea, neuropathy, pain, vomiting, and
wateryeyes(eTable2intheSupplement).Thesequestionswere
graded similarly to the clinician CTCAE using a 5-point ordi-
nal scale for responses, with verbal descriptors of clinical an-
chors except with the use of lay terminology. For example,
Key Points
Question Is it feasible to collect patient-reported symptomatic
adverse events in large multicenter oncology clinical trials?
Findings Among 285 patients enrolled in 9 US multicenter cancer
treatment trials, symptomatic adverse events were successfully
self-reported by paients at 93.9% of expected times. Most
patients believed that the system was easy to use and useful, and
investigators thought that the patient-reported adverse event
data were useful and accurate.
Meaning Participants in multicenter cancer trials can report their
own symptomatic adverse events, which may improve the
efficiency and accuracy of safety monitoring in clinical research.
Research Original Investigation
Patient Reporting of Symptomatic Adverse Events in Multicenter Cancer Trials
1044
JAMA Oncology
August 2017
Volume 3, Number 8
(Reprinted)
jamaoncology.com
© 2017 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/03/2019
 grade 3 anorexia is defined for clinicians in the CTCAE as “as-
sociated with significant weight loss or malnutrition (eg, in-
adequate oral caloric and/or fluid intake); IV [intravenous] flu-
ids,tubefeedings,orTPN[totalparenteralnutrition]indicated,
”
and grade 3 wording for the PRO adaptation is, “I am losing a
lotofweightorIammalnourished,andIamtakinginverylittle
food or fluids (or I have needed to get IV fluids, tube feedings,
or IV nutrition).”22(p3555) To harmonize with the general ap-
proach to clinician CTCAE reporting, patient questionnaire in-
structions specified the following recall period: “Please an-
swerthefollowingquestionstotellustheworstyoursymptoms
have been since your last chemotherapy treatment. If you have
not received chemotherapy, or your treatment has been held,
please tell us the worst your symptoms have been since your
last chemotherapy visit.”22(p3555) In the 9 clinical trials, treat-
ment cycle length varied, and the recall periods for patient
questionnaires therefore varied based on cycle length. Spe-
cifically, the cycle length was weekly in 1 trial, every 2 weeks
in 1 trial, every 3 weeks in 5 trials, and every 4 weeks in 2 trials.
At each of 5 consecutive chemotherapy cycle clinic visits, a
tablet computer was brought to participants in a private area of
clinic waiting rooms to complete the questionnaire. The CRPs
could provide technical assistance or explain terminology but
couldnotprovideassistanceinsymptomrating.Ateachvisit,the
CRPsprintedreportsshowingthelongitudinaltrajectoryofsymp-
toms and added this information to medical records for nurses
andoncologists.Nospecificinstructionsweregiventoclinicians
regarding how to use these reports for clinical trial documenta-
tionorpatientmanagement.Simultaneously,cliniciansreported
the same symptomatic toxic effects using the standard CTCAE
case report form utilized in cooperative group trials.
Adherence to self-reporting was systematically tracked,
and site staff logged reasons for missed patient self-reports.
At the third cycle visit (or off-study visit if before the third
cycle), patients and clinical investigators completed a feed-
back survey with items regarding the ease of use and per-
ceived value of the system.
Statistical Analysis
Participation rate was computed as the number of patients en-
rolled divided by the number approached to participate. Ad-
herence was defined as the number of patients who com-
pleted the assessment divided by the total number who were
alive and enrolled in the trial at each given visit. Criteria for
determining feasibility were specified a priori as 80% or more
participation and adherence rates. Descriptive statistics for pa-
tient symptom scores and clinician grades included means
(SDs) and frequencies of each response category. Agreement
between patients and clinicians was assessed across all re-
sponse categories using weighted κ statistics, with κ values
ranging from 0.01 to 0.20 demarcating slight agreement; 0.21
to0.40,fairagreement;0.41to0.60,moderateagreement;and
0.61 or higher, substantial agreement.36 Time to grade 2 or
higher AEs was analyzed using the Kaplan-Meier37 approach
and is presented as a cumulative incidence curve separately
based on patient and clinician reports. Feedback surveys were
analyzed using descriptive statistics. Sample size was capped
at 300 based on available funding and an assumption that this
number would provide robust estimates of feasibility and pre-
liminary estimates of agreement for patients who are repre-
sentative of enrollees in National Clinical Trials Network trials.
Data collection and statistical analyses were conducted by the
Alliance Statistics and Data Center (SDC). Data quality was en-
sured by review of data by the Alliance SDC (A.C.D., D. Seisler,
and P.J.A.) and by the study chairperson (E.B.) following
Alliance SDC policies. Statistical analysis was conducted from
August 9, 2013, to March 21, 2014, and was performed using
SAS, version 9.3 (SAS Institute).
Results
This study enrolled patients between March 15, 2007, and
August 11, 2011. Thirty-seven US sites completed CRP training
and actively enrolled patients; 32 (86.5%) sites required tablet
computers and 5 (13.5%) required wireless connectivity hard-
ware to be set up in waiting rooms. A total of 361 patients were
approached, with 313 agreeing to participate (86.7% participa-
tionrate),and285(91.1%)werealiveandstillreceivingprotocol-
directed treatment at the time of study initiation. Among the
48 patients who refused participation, the most common rea-
sons for nonparticipation were that the patient was not inter-
ested(29[60.4%])andwastooanxious(6[12.5%]);only2[4.2%]
were too sick, 1 [2.1%] did not want to use a computer, 1 [2.1%]
was too busy, 1 [2.1%] did not like research, and 8 [16.7%] did
not specify a reason. More participants were women (202
[74.3%]) due to the included breast trials (4 of 9 included treat-
ment trials), and most were white (241 [85.5%]); denomina-
torsdifferedforsomevariablesbecauseofmissingdata(Table1).
Within each trial, the patients enrolled in this PRO feasibility
study were demographically similar to all other enrolled pa-
tients with respect to age, sex, and race. In some trials, the pro-
portionofHispanic/Latinopatientswashigherintheoveralltrial
compared with those enrolled in this feasibility study because
the PRO questionnaire was offered only in English.
Duringthestudy,therewere1280scheduledvisitsatwhich
participantswereexpectedtocompleteaquestionnaire(ie,vis-
its at which patients were alive and enrolled in the associated
trial). Of these, questionnaires were completed at 1202 visits
(93.9% overall adherence rate). Adherence was best at base-
line and successively declined over time (Figure 1). Rates ex-
ceeded the a priori feasibility threshold of 80% or higher ad-
herence. Documented reasons for nonadherence included
institutional errors (eg, staff forgetting to bring tablets to pa-
tients at visits) in 27 of 48 (56.3%) cases, internet connectiv-
ityproblemsin5cases(10.4%),patientsfeelingtooillin8cases
(16.7%), and patient refusal in 8 cases (16.7%).
Among the 285 participants, 222 (77.9%) had no missing
assessmentsduringthestudyand63(22.1%)hadatleast1miss-
ingassessmentduringthestudy.Incomparingthelinkedtreat-
ment trial, age, sex, race, and ethnicity between the 63 pa-
tients with at least 1 missing assessment and the 222 patients
without missing assessments, none reached statistical signifi-
cance. Women were more likely to have no missing assess-
ments, although this finding was not significant (81.0% vs
70.3% for men; P = .07).
Patient Reporting of Symptomatic Adverse Events in Multicenter Cancer Trials
Original Investigation Research
jamaoncology.com
(Reprinted)
JAMA Oncology
August 2017
Volume 3, Number 8
1045
© 2017 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/03/2019
 Agreement in grade level between patient and clinician re-
ports on toxic effects is reported in Table 2. Agreement based
on weighted κ statistics was generally fair, with 6 of 13 symp-
tomatic toxic AEs having weighted κ statistics between 0.21
and 0.40. Agreement was highest for vomiting (κ = 0.82) and
lowest for hand-foot reaction or rash (κ = 0.03). Cumulative
incidence of patient and clinician symptomatic toxic AEs of
grade 2 or higher, shown in Figure 2 and the eFigure in the
Supplement, demonstrate lower levels of reporting by clini-
cians compared with patients over time across all toxic AEs ex-
cept hand-foot reaction or rash, where AE rates were low over-
all. The greatest levels of clinician underreporting compared
with patients occurred for anorexia, fatigue, nausea, and pain.
Despite these discrepancies between patients and clini-
cians, most investigators reported in the feedback survey that
they viewed and discussed patient self-reports at clinic visits
and found the reports to be useful and accurate (Table 3). The
survey was completed by 144 investigators at all 36 partici-
pating sites. The patient feedback survey, returned by 252 of
285 (88.4%) participants, found that most patients com-
pleted the reports themselves, viewed the system as easy to
use and useful, and believed that the PRO approach im-
proved discussions with clinicians (Table 3).
Discussion
To our knowledge, this is the first prospective study assessing
patient self-reporting of symptomatic AEs in cancer multi-
centerclinicaltrials.Mostpatientswerewillingandabletoself-
reportAEsatconsecutivevisitsandfoundthisprocesstobeeasy
and useful. Similarly, most investigators found the patient re-
ports to be useful and accurate, confirming a prior national sur-
vey in which more than 90% of investigators projected that
patient reporting of AEs could improve meaningfulness and
accuracy of AEs in clinical research.8
The most common reason for nonadherence was related
to staff members; specifically, staff members forgot to bring
Figure 1. Proportion of Clinical Trial Participants Adhering
to Symptomatic Adverse Event Reporting at Successive Clinic Visits
100
80
60
40
20
0
Patients, %
Visit 1
Visit 2
Visit 3
Visit 4
Visit 5
At each predetermined scheduled clinic visit, the proportion of remaining
participants who successfully self-reported their own adverse events
electronically was tabulated.
Table 2. Levels of Agreement Between Symptomatic Toxic Effect Grades
as Reported by Patients vs Clinicians
Symptomatic Toxic Effect
Weighted κ (95% CI)a
Anorexia
0.22 (0.07 to 0.37)
Constipation
0.39 (0.24 to 0.54)
Cough
0.36 (0.16 to 0.56)
Diarrhea
0.63 (0.49 to 0.76)
Dyspnea
0.32 (0.13 to 0.50)
Fatigue
0.33 (0.17 to 0.49)
Hand or foot rash
0.03 (−0.05 to 0.11)
Mouth sores
0.44 (0.25 to 0.63)
Nausea
0.65 (0.49 to 0.81)
Neuropathy
0.48 (0.33 to 0.64)
Pain
0.61 (0.48 to 0.74)
Vomiting
0.82 (0.62 to 1.00)
Watery eyes
0.23 (0.00 to 0.45)
a Weighted κ values ranging from 0.01 to 0.20 demarcate slight agreement;
0.21 to 0.40, fair agreement; 0.41 to 0.60, moderate agreement; and 0.61 or
higher, substantial agreement.
Table 1. Characteristics of the 285 Participants
Characteristic
No. (%)
Age, median (range), y
57 (24-88)
Sex
Female
202 (74.3)
Missing/NRa
13
Raceb
White
241 (85.5)
Black
31 (11.0)
Asian
8 (2.8)
American Indian/Alaska native
2 (0.7)
Missing/NRa
3
Ethnicity
Hispanic/Latino
7 (2.9)
Missing/NRa
47
Cancer treatment trial type
Breast cancer
151 (53.0)
Colorectal cancer
16 (5.6)
Lung cancer
10 (3.5)
Prostate cancer
14 (4.9)
Supportive care
94 (33.0)
Computer at home
Yes
222 (82.5)
Missing/NRa
16
Frequency of internet use
Regularly
176 (64.7)
Occasionally/rarely
57 (21.0)
Never
39 (14.3)
Missing/NRa
13
Highest educational level
High school or less
73 (26.8)
Some college/college degree
152 (55.9)
Graduate degree
47 (17.3)
Missing/NRa
13
Abbreviation: NR, not reported.
a Data were not reported for clinical trials in which these individuals were
enrolled. Missing data were removed from the denominator for proportions in
each demographic category.
bBased on self-report. Percentages sum to greater than 100% owing to
rounding.
Research Original Investigation
Patient Reporting of Symptomatic Adverse Events in Multicenter Cancer Trials
1046
JAMA Oncology
August 2017
Volume 3, Number 8
(Reprinted)
jamaoncology.com
© 2017 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/03/2019
 tablets to patients in 56.3% of the documented cases. An ad-
ditional 10.4% of missing self-reports were due to internet con-
nectivity problems. These findings suggest that adherence
rates could be boosted through standardized mechanisms to
support staff and technology.
In subsequent National Clinical Trials Network studies in-
tegrating patient-reported AEs as a standard metric, central-
ized monitoring of adherence and automated reminders have
been used to prompt staff to remember to collect data.38-41 In
addition, approaches have been used for between-visit report-
ing by patients via the internet or automated telephone sys-
tems to avoid reliance on site staff to bring computers to
patients.38,40 Strategies to optimize patient response rates will
invariably improve as this approach to data collection be-
comes more commonly used in trials. Nonetheless, the high
participation and adherence rates observed within the present
study suggest immediate feasibility of implementation.
In terms of internet connectivity problems and other tech-
nology limitations, there have been substantial technical and
connectivity advances since this study opened; during the
course of this study, we observed the frequency of such prob-
lems to fall substantially. Virtually all US oncology clinics now
have high-speed internet in waiting areas, and most patients
ownawirelessdevice.Weanticipatethattheconnectivityprob-
lems experienced in this study will be less of a barrier in the
future, which is being assessed in follow-up work.38,40
Although most investigators reported viewing PROs at
visitsandbelievedthatthesewereanaccuratereflectionoftrue
patient status, there were discrepancies between patient and
investigator grades, with investigators consistently reporting
lower grades than patients. This paradoxical finding suggests
either that investigators viewed PROs after documenting AEs
or that investigators did not use the PROs to inform their AE
documentation even though they found them valuable. In pre-
vious studies in which patients and clinicians reported side-
by-side without viewing each other’
s documentation, there
were similar discrepancies in grades4,5,7; in a more recent
single-center phase 2 trial, there was more than 90% agree-
ment between patients and investigators when investigators
were compelled by a computer interface to review PROs
before documenting AEs.42 Ongoing National Clinical Trials
Network trials are assessing the sharing of PRO AEs with in-
vestigators to assess whether investigator grades will better
align with PROs.38,40 Nonetheless, unfiltered patient reports
provide a direct reflection of the patient’
s experience with
symptomatic AEs, and the US Food and Drug Administration
has advocated for this approach.43
Adverse events reported by patients but missed by clini-
cians reflect an area of the patient’
s experience that may war-
rant particular attention in the future, both to alleviate pa-
tient discomfort and identify currently undocumented safety
signals. Such focus may be particularly salient for targeted
Figure 2. Cumulative Incidence of Common Terminology Criteria for Adverse Events (CTCAE) Grade 2 or Higher Patient- and Clinician-Reported
Adverse Events
0
0
8
4
12
16
20
100
80
Cumulative Incidence, %
Time to Adverse Event, wk
60
40
20
No. at risk
 CTCAE
 PRO
285
285
276
265
258
240
230
212
163
152
93
88
Grade 2+ constipation
A
0
0
8
4
12
16
20
100
80
Cumulative Incidence, %
Time to Adverse Event, wk
60
40
20
No. at risk
 CTCAE
 PRO
285
285
264
219
231
152
196
124
128
77
76
45
Grade 2+ fatigue
B
0
0
8
4
12
16
20
100
80
Cumulative Incidence, %
Time to Adverse Event, wk
60
40
20
No. at risk
 CTCAE
 PRO
285
285
275
277
250
260
225
228
158
158
88
88
Grade 2+ rash on hands or feet
C
0
0
8
4
12
16
20
100
80
Cumulative Incidence, %
Time to Adverse Event, wk
60
40
20
No. at risk
 CTCAE
 PRO
285
285
273
265
256
231
232
208
162
146
90
80
Grade 2+ nausea
D
PRO
CTCAE
Incidence aggregated from 9 US multicenter clinical trials for constipation (A), fatigue (B), hand or foot rash (C), and nausea (D). The eFigure in the Supplement
provides the incidence for all 13 adverse events. PRO indicates patient-reported outcome.
Patient Reporting of Symptomatic Adverse Events in Multicenter Cancer Trials
Original Investigation Research
jamaoncology.com
(Reprinted)
JAMA Oncology
August 2017
Volume 3, Number 8
1047
© 2017 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/03/2019
 therapies and immunotherapies that cause long-standing,
low-grade toxic effects.
Limitations
There are several limitations of this study. Accrual was depen-
dent on the 9 linked treatment trials, which increased at vari-
able rates, leading to a relatively prolonged study period. Al-
though we included a range of linked treatment trials in this
study to allow for broad generalization of study results, the
findings may not generalize to clinical trials that enroll pa-
tients with different characteristics (eg, higher rate of males
or higher median age). The questionnaire was in English only,
and future evaluations should include additional languages.
Patient reporting was conducted only at clinic visits and not
between visits when patients may experience important AEs.
Ongoing trials are assessing between-visit reporting. A cen-
tralized backup reminder approach was not used, and this may
be 1 reason that more than half of missing data were attribut-
able to site staff forgetting to approach patients for self-
reports at visits. A centralized reminder model is being as-
sessed in ongoing work. Although the rates of reporting
were high overall, they diminished over time. Work is in pro-
cess to assess adherence rates with longer durations of self-
reporting; in other settings, adherence has been shown to be
durable over time.44
This study did not track time and effort by investigators,
staff, or patients for conducting work for the PRO system, and
this is a focus of ongoing evaluations in the National Clinical
Trials Network. The recall period for patient questions in this
study was “since your last chemotherapy,
” which ranged from
1 to 4 weeks in the 9 trials. Ongoing work assessing the
PRO-CTCAE has used standardized recall periods in clinical
trials, and there is evidence that recall periods up to 4 weeks
correlate with daily reporting, although shorter recall peri-
ods may be more precise.45,46
The questionnaire and software used in this study were
precursors to the NCI’
s PRO-CTCAE item library and software
platform, which is now available and should be considered the
standard approach for assessment of patient-reported AEs in
oncology.34,35 The conceptual framework for the study re-
ported herein as well as the study team’
s experiences through-
out the conduct of this study informed the development of the
PRO-CTCAE, but the data were not formally available until this
analysis. The patient questions included in this study mirror
the structure of CTCAE items with lay terminology, whereas
the development of PRO-CTCAE items was based on estab-
lished methods for designing PRO measures.
Performance status data were not universally collected
in the linked clinical trials and therefore were not available
as a baseline variable. It is possible that adherence rates
would be lower in a population with worse or declining per-
formance status, although adherence rates remained high
over time in this study and are comparable to those of
single-center PRO studies that included patients with sub-
stantial performance status limitations at baseline.22,42,44
Most participants (74.3%) were women due to the composi-
tion of linked clinical trials and so may not be representative
of trials with a different distribution by sex, although no sig-
nificant differences in adherence rates were discernable
between men and women in this study.
Conclusions
This study demonstrates the feasibility of patient self-
reporting of AEs in multicenter cancer clinical trials, eluci-
datesareasforfurtherrefinement,andpavesthewayforamore
patient-centered and accurate approach to symptomatic AE
reporting in cancer clinical research.
ARTICLE INFORMATION
Accepted for Publication: November 22, 2016.
Published Online: February 16, 2017.
doi:10.1001/jamaoncol.2016.6749
Author Affiliations: Department of Medicine,
Lineberger Comprehensive Cancer Center,
University of North Carolina, Chapel Hill (Basch,
Carey); Department of Epidemiology and
Biostatistics, Memorial Sloan Kettering Cancer
Center, New York, New York (Basch, Rogak);
Alliance Statistics and Data Center, Division of
Health Sciences Research, Mayo Clinic, Scottsdale,
Arizona (Dueck); Division of Cancer Prevention,
National Cancer Institute (NCI), Rockville, Maryland
(Minasian); Department of Medical Oncology and
Urology, Division of Solid Tumor, Sidney Kimmel
Table 3. Clinical Investigator and Patient Feedback Surveys
Survey Item
Respondents,
No. (%)
Clinical Investigator Feedbacka
Patient-reported symptomatic toxicities
Were reviewed at visits
131/143 (91.6)
Were discussed with patients at visits
110/144 (76.4)
Are useful for monitoring toxicities
133/141 (94.3)
Could be a source of research-grade data
120/143 (83.9)
Were an accurate reflection of patient
clinical status
119/143 (83.2)
Impression of relationship between adverse event
grade severities reported by patients vs clinicians
They are generally the same
63/143 (44.1)
Patients generally grade more severe
than clinicians
50/143 (35.0)
Patients generally grade less severe
than clinicians
13/143 (9.1)
Don’
t know
17/143 (11.9)
Patient Feedbackb
Person who entered symptom grades
Myself
220/250 (88.0)
Relative or friend
5/250 (2.0)
Professional caregiver
16/250 (6.4)
Other
9/250 (3.6)
The patient adverse event reporting system
Was easy to use
234/251 (93.2)
Was useful
230/247 (93.1)
Improved discussions with my doctor/nurse
211/247 (85.4)
a Overall, there were 144 clinical investigator respondents across 37 sites, but
not all investigators responded to all questions; therefore, the denominator
for each question varies with missing responses subtracted.
bOverall, there were 252 patient respondents of 285 study participants, but not
all patients responded to all questions; therefore, the denominator for each
question varies with missing responses subtracted.
Research Original Investigation
Patient Reporting of Symptomatic Adverse Events in Multicenter Cancer Trials
1048
JAMA Oncology
August 2017
Volume 3, Number 8
(Reprinted)
jamaoncology.com
© 2017 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/03/2019
 Medical College at Thomas Jefferson University,
Philadelphia, Pennsylvania (Kelly); Clinical Research
and Prostate Cancer Program, Sidney Kimmel
Cancer Center, Philadelphia, Pennsylvania (Kelly);
Division of Cancer Treatment and Diagnosis, NCI,
Rockville, Maryland (O’
Mara, Denicoff); Alliance
Statistics and Data Center, Division of Health
Sciences Research, Mayo Clinic, Rochester,
Minnesota (Seisler, Atherton); Division of Cancer
Prevention and Control, Department of Internal
Medicine, Division of Epidemiology, College of
Public Health, The Ohio State University, Columbus
(Paskett); Department of Medicine, Memorial Sloan
Kettering Cancer Center, New York, New York
(Dickler, Lake); Department of Thoracic Oncology,
Harvard Medical School, Massachusetts General
Hospital, Boston (Heist); Delaware/Christiana Care
NCI Community Oncology Research Program
(NCORP), Helen F. Graham Cancer Center &
Research Institute, Newark (Himelstein, Biggs);
Department of Medicine, University of California at
San Francisco, Helen Diller Family Comprehensive
Cancer Center, San Francisco (Rugo, Venook);
Program in Women’
s Oncology, Department of
Obstetrics & Gynecology, Women and Infants
Hospital of Rhode Island, Providence (Sikov);
Department of Medicine, Warren Alpert Medical
School of Brown University, Providence,
Rhode Island (Sikov); Thoracic Oncology Program,
Florida Hospital Cancer Institute, Orlando
(Socinski); New Hampshire Oncology Hematology,
Hooksett (Weckstein); Department of Medical
Oncology, Harvard Medical School, Dana-Farber
Cancer Institute, Boston, Massachusetts
(Freedman); Southeast Clinical Oncology Research
Consortium, Winston-Salem, North Carolina
(Kuzma); Hematology Oncology Associates of
Central New York, East Syracuse (Kirshner); Division
of Population Sciences, Dana-Farber Cancer
Institute, Boston, Massachusetts (Schrag).
Author Contributions: Drs Basch and Dueck had
full access to all the data in the study and take
responsibility for the integrity of the data and the
accuracy of the data analysis.
Study concept and design: Basch, Rogak, Minasian,
Paskett, Sikov, Socinski, Schrag.
Acquisition, analysis, or interpretation of data:
Basch, Dueck, Rogak, Kelly, O’
Mara, Denicoff,
Seisler, Atherton, Carey, Dickler, Heist, Himelstein,
Rugo, Sikov, Socinski, Venook, Weckstein, Lake,
Biggs, Freedman, Kuzma, Kirshner, Schrag.
Drafting of the manuscript: Basch, Dueck, Rogak,
Kelly, O’
Mara, Atherton, Carey, Socinski, Schrag.
Critical revision of the manuscript for important
intellectual content: Basch, Dueck, Rogak, Minasian,
Kelly, O’
Mara, Denicoff, Seisler, Paskett, Carey,
Dickler, Heist, Himelstein, Rugo, Sikov, Socinski,
Venook, Weckstein, Lake, Biggs, Freedman, Kuzma,
Kirshner, Schrag.
Statistical analysis: Dueck, Rogak, Seisler, Atherton.
Administrative, technical, or material support:
Rogak, Kelly, Paskett, Carey, Heist, Himelstein,
Rugo, Socinski, Venook, Weckstein, Kuzma.
Study supervision: Rogak, Kelly, Denicoff,
Himelstein, Socinski, Weckstein, Biggs, Schrag.
Conflict of Interest Disclosures: None reported.
Funding/Support: Research reported in this
publication was supported by the NCI of the
National Institutes of Health under award numbers
U10CA037447 and UG1CA189823 (Alliance for
Clinical Trials in Oncology NCORP grant),
U10CA031946, U10CA033601, U10CA180821,
U10CA180882, U10CA032291, U10CA045389,
U10CA045418, U10CA045808, U10CA047559,
U10CA077651, U10CA077658, U10CA138561,
U10CA180791, U10CA180844, U10CA180850,
U10CA180838, U10CA180867, UG1CA189819, and
UG1CA189858.
Role of the Funder/Sponsor: The US NCI had input
into the design and conduct of the study; collection,
management, analysis, and interpretation of the
data; preparation, review, and approval of the
manuscript; and decision to submit the manuscript
for publication.
Institutions Participating in This Study: Bay Area
Tumor Institute NCORP, Oakland, California: Jon
Greif, DO (UG1CA189817); Dana-Farber/Partners
CancerCare Lead Academic Participating Sites
(LAPS), Boston, Massachusetts: Harold Burstein,
MD, PhD (U10CA032291, U10CA180867);
Dartmouth College–Norris Cotton Cancer Center
LAPS, Lebanon, New Hampshire: Konstantin
Dragnev, MD (U10CA004326, U10CA180854);
Delaware/Christiana Care NCORP, Newark: Gregory
Masters, MD (U10CA045418, UG1CA189819);
Eastern Maine Medical Center Cancer Care, Brewer:
Thomas Openshaw, MD; Heartland Cancer Research
NCORP, Decatur, Illinois: James Wade III, MD
(U10CA114558, UG1CA189830); Hematology
Oncology Associates of Central New York, East
Syracuse: Jeffrey J. Kirshner, MD (U10CA045389);
Kansas City NCORP, Prairie Village: Rakesh Gaur,
MD, MPH (UG1CA189853); Mayo Clinic LAPS,
Rochester, New York: Steven Alberts, MD
(U10CA180790); Memorial Sloan Kettering Cancer
Center LAPS, New York, New York: Clifford Hudis,
MD (U10CA077651, U10CA180791); NCORP of the
Carolinas (Greenville Health System NCORP),
Greenville, South Carolina: Jeffrey Giguere, MD
(U10CA029165, UG1CA189972); Nevada Cancer
Research Foundation Cancer Community Oncology
Program, Las Vegas: John Ellerton, MD
(U10CA035421, UG1CA189829); Nevada Cancer
Research Foundation NCORP, Las Vegas: John
Ellerton, MD (UG1CA189829); New Hampshire
Oncology Hematology PA–Hooksett, Hooksett:
Douglas J. Weckstein, MD; North Shore–Long Island
Jewish Health System NCORP, Manhasset,
New York: Daniel Budman, MD (U10CA035279,
UG1CA189850); Northern Indiana Cancer Research
Consortium, South Bend,: Rafat Ansari, MD
(U10CA086726); Rhode Island Hospital,
Providence: Howard Safran, MD (U10CA008025);
Southeast Clinical Oncology Research Consortium
NCORP, Winston-Salem, North Carolina: James N.
Atkins, MD (U10CA045808, UG1CA189858); State
University of New York Upstate Medical University,
Syracuse: Stephen Graziano, MD (U10CA021060);
University of North Carolina Lineberger
Comprehensive Cancer Center LAPS, Chapel Hill:
Thomas Shea, MD (U10CA047559, U10CA180838);
University of California, San Diego: Barbara A.
Parker, MD (U10CA011789); University of Chicago
Comprehensive Cancer Center LAPS, Chicago: Hedy
Kindler, MD (U10CA041287, U10CA180836);
University of Iowa/Holden Comprehensive Cancer
Center, Iowa City: Daniel Vaena Satele, MS
(U10CA047642); University of Vermont College of
Medicine, Burlington: Claire Verschraegen, MD
(U10CA077406); Wake Forest University Health
Sciences, Winston-Salem, North Carolina: Heidi
Klepin, MD (U10CA003927); and Yale University,
New Haven, Connecticut: Lindsay N. Harris, MD
(U10CA016359). The investigators received no
direct funding for conduct or analysis of this
specific trial.
Disclaimer: The content is solely the responsibility
of the authors and does not necessarily represent
the official views of the National Institutes of
Health.
Additional Contributions: Richard Schilsky, MD
(American Society of Clinical Oncology),
encouraged the development and conduct of this
study. There was no financial compensation.
REFERENCES
1. National Cancer Institute, National Institutes of
Health, US Department of Health and Human
Services. Common Terminology Criteria for Adverse
Events (CTCAE), version 3. http://ctep.cancer.gov
/protocolDevelopment/electronic_applications
/docs/ctcaev3.pdf. Published August 9, 2006.
Accessed March 23, 2016.
2. Trotti A, Colevas AD, Setser A, Basch E.
Patient-reported outcomes and the evolution of
adverse event reporting in oncology. J Clin Oncol.
2007;25(32):5121-5127.
3. Atkinson TM, Li Y, Coffey CW, et al. Reliability of
adverse symptom event reporting by clinicians.
Qual Life Res. 2012;21(7):1159-1164.
4. Fromme EK, Eilers KM, Mori M, Hsieh YC, Beer
TM. How accurate is clinician reporting of
chemotherapy adverse effects? a comparison with
patient-reported symptoms from the
Quality-of-Life Questionnaire C30. J Clin Oncol.
2004;22(17):3485-3490.
5. Pakhomov SV, Jacobsen SJ, Chute CG, Roger VL.
Agreement between patient-reported symptoms
and their documentation in the medical record. Am
J Manag Care. 2008;14(8):530-539.
6. Basch E. The missing voice of patients in
drug-safety reporting. N Engl J Med. 2010;362(10):
865-869.
7. Basch E, Iasonos A, McDonough T, et al. Patient
versus clinician symptom reporting using the
National Cancer Institute Common Terminology
Criteria for Adverse Events: results of a
questionnaire-based study. Lancet Oncol. 2006;7
(11):903-909.
8. Bruner DW, Bryan CJ, Aaronson N, et al; National
Cancer Institute. Issues and challenges with
integrating patient-reported outcomes in clinical
trials supported by the National Cancer
Institute–sponsored clinical trials networks. J Clin
Oncol. 2007;25(32):5051-5057.
9. Minasian L, O’
Mara A. Introduction to special
JNCI monograph on patient-reported outcomes.
J Natl Cancer Inst Monogr. 2007;(37):5063-5069.
10. Ganz PA, Gotay CC. Use of patient-reported
outcomes in phase III cancer treatment trials:
lessons learned and future directions. J Clin Oncol.
2007;25(32):5063-5069.
11. Lipscomb J, Reeve BB, Clauser SB, et al.
Patient-reported outcomes assessment in cancer
trials: taking stock, moving forward. J Clin Oncol.
2007;25(32):5133-5140.
12. Rock EP, Kennedy DL, Furness MH, Pierce WF,
Pazdur R, Burke LB. Patient-reported outcomes
supporting anticancer product approvals. J Clin Oncol.
2007;25(32):5094-5099.
Patient Reporting of Symptomatic Adverse Events in Multicenter Cancer Trials
Original Investigation Research
jamaoncology.com
(Reprinted)
JAMA Oncology
August 2017
Volume 3, Number 8
1049
© 2017 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/03/2019
 13. Wu AW, Snyder C, Clancy CM, Steinwachs DM.
Adding the patient perspective to comparative
effectiveness research. Health Aff (Millwood). 2010;
29(10):1863-1871.
14. Cella D, Riley W, Stone A, et al; PROMIS
Cooperative Group. The Patient-Reported
Outcomes Measurement Information System
(PROMIS) developed and tested its first wave of
adult self-reported health outcome item banks:
2005-2008. J Clin Epidemiol. 2010;63(11):1179-1194.
15. US Department of Health and Human Services,
Food and Drug Administration. Guidance for
industry: patient-reported outcomes
measures—use in medical product
development to support labeling claims.
http://www.fda.gov/downloads/Drugs
/GuidanceComplianceRegulatoryInformation
/Guidances/UCM193282.pdf. Published December
2009. Accessed March 24, 2014.
16. European Medicines Agency. Committee for
Medicinal Products for Human Use (CHMP).
Pre-authorisation evaluation of medicines for
human use: reflection paper on the regulatory
guidance for the use of health-related quality of life
(HRQL) measures in the evaluation of medicinal
products. https://www.ispor.org/workpaper
/emea-hrql-guidance.pdf. Published January 2005.
Accessed March 24, 2014.
17. Wagner LI, Zhao F, Chapman J-AW, et al.
Patient-reported predictors of early treatment
discontinuation: NCIC JMA.27/E1Z03 quality of life
study of postmenopausal women with primary
breast cancer randomized to exemestane or
anastrozole. Paper presented at: San Antonio
Breast Conference; December 9, 2011;
San Antonio, TX.
18. Bhattacharya D, Easthall C, Willoughby KA,
Small M, Watson S. Capecitabine non-adherence:
exploration of magnitude, nature and contributing
factors. J Oncol Pharm Pract. 2012;18(3):333-342.
19. Eliasson L, Clifford S, Barber N, Marin D.
Exploring chronic myeloid leukemia patients’
reasons for not adhering to the oral anticancer drug
imatinib as prescribed. Leuk Res. 2011;35(5):626-630.
20. Timmers L, Boons CC, Mangnus D, et al. The
use of erlotinib in daily practice: a study on
adherence and patients’experiences. BMC Cancer.
2011;11:284.
21. Bruner DW, Hanisch LJ, Reeve BB, et al.
Stakeholder perspectives on implementing the
National Cancer Institute’
s patient-reported
outcomes version of the Common Terminology
Criteria for Adverse Events (PRO-CTCAE). Transl
Behav Med. 2011;1(1):110-122.
22. Basch E, Artz D, Dulko D, et al. Patient online
self-reporting of toxicity symptoms during
chemotherapy. J Clin Oncol. 2005;23(15):3552-3561.
23. Basch E, Iasonos A, Barz A, et al. Long-term
toxicity monitoring via electronic patient-reported
outcomes in patients receiving chemotherapy. J Clin
Oncol. 2007;25(34):5374-5380.
24. Basch E, Artz D, Iasonos A, et al. Evaluation of
an online platform for cancer patient self-reporting
of chemotherapy toxicities. J Am Med Inform Assoc.
2007;14(3):264-268.
25. clinicaltrials.gov. Paclitaxel, Nab-Paclitaxel, or
Ixabepilone With or Without Bevacizumab in
Treating Patients With Stage IIIC or Stage IV Breast
Cancer. NCT00785291. https://clinicaltrials.gov/ct2
/show/NCT00785291. Accessed January 8, 2017.
26. clinicaltrials.gov. Tamoxifen Citrate or Letrozole
With or Without Bevacizumab in Treating Women
With Stage III or Stage IV Breast Cancer.
NCT00601900. https://clinicaltrials.gov/ct2/show
/NCT00601900. Accessed January 8, 2017.
27. clinicaltrials.gov. Paclitaxel and Trastuzumab
With or Without Lapatinib in Treating Patients With
Stage II or Stage III Breast Cancer That Can Be
Removed by Surgery. NCT00770809. https:
//clinicaltrials.gov/ct2/show/NCT00770809.
Accessed January 8, 2017.
28. clinicaltrials.gov. Paclitaxel With or Without
Carboplatin and/or Bevacizumab Followed by
Doxorubicin and Cyclophosphamide in Treating
Patients With Breast Cancer That Can Be Removed
by Surgery. NCT00861705. https://clinicaltrials.gov
/ct2/show/NCT00861705. Accessed January 8,
2017.
29. clinicaltrials.gov. Cetuximab and/or
Bevacizumab Combined With Combination
Chemotherapy in Treating Patients With Metastatic
Colorectal Cancer. NCT00265850. https:
//clinicaltrials.gov/ct2/show/NCT00265850.
Accessed January 8, 2017.
30. clinicaltrials.gov. Sunitinib Malate as
Maintenance Therapy in Treating Patients With
Stage III or Stage IV Non-Small Cell Lung Cancer
Previously Treated With Combination
Chemotherapy. NCT00693992. https://clinicaltrials
.gov/ct2/show/NCT00693992. Accessed January
8, 2017.
31. clinicaltrials.gov. Pemetrexed and/or Sunitinib
as Second-Line Therapy in Treating Patients With
Stage IIIB or Stage IV Non-small Cell Lung Cancer.
NCT00698815. https://clinicaltrials.gov/ct2/show
/NCT00698815. Accessed January 8, 2017.
32. clinicaltrials.gov. Docetaxel and Prednisone
With or Without Bevacizumab in Treating Patients
With Prostate Cancer That Did Not Respond to
Hormone Therapy. NCT00110214. https:
//clinicaltrials.gov/ct2/show/NCT00110214.
Accessed January 8, 2017.
33. clinicaltrials.gov. Zoledronic Acid in Treating
Patients With Metastatic Breast Cancer, Metastatic
Prostate Cancer, or Multiple Myeloma With Bone
Involvement. NCT00869206. https://clinicaltrials
.gov/ct2/show/NCT00869206. Accessed January
8, 2017.
34. Dueck AC, Mendoza TR, Mitchell SA, et al;
National Cancer Institute PRO-CTCAE Study Group.
Validity and reliability of the US National Cancer
Institute’
s patient-reported outcomes version of
the Common Terminology Criteria for Adverse
Events (PRO-CTCAE). JAMA Oncol. 2015;1(8):1051-
1059.
35. Basch E, Reeve BB, Mitchell SA, et al.
Development of the National Cancer Institute’
s
patient-reported outcomes version of the Common
Terminology Criteria for Adverse Events
(PRO-CTCAE). J Natl Cancer Inst. 2014;106(9):dju244.
36. Landis JR, Koch GG. The measurement of
observer agreement for categorical data. Biometrics.
1977;33(1):159-174.
37. Kaplan EL, Meier P. Nonparametric estimation
from incomplete observations. J Am Stat Assoc.
1958;53(282):457-481.
38. clinicaltrials.gov. PROSPECT: Chemotherapy
Alone or Chemotherapy Plus Radiation Therapy in
Treating Patients With Locally Advanced Rectal
Cancer Undergoing Surgery. NCT01515787. https:
//clinicaltrials.gov/ct2/show/NCT01515787.
Accessed January 8, 2017.
39. clinicaltrials.gov. Manuka Honey in Preventing
Esophagitis-Related Pain in Patients Receiving
Chemotherapy and Radiation Therapy for Lung
Cancer. NCT01262560. https://clinicaltrials.gov/ct2
/show/NCT01262560. Accessed January 8, 2017.
40. clinicaltrials.gov. A Randomized Phase III Trial
of Eribulin Compared to Standard Weekly Paclitaxel
as First- or Second-Line Therapy for Locally
Recurrent or Metastatic Breast Cancer.
NCT02037529. https://clinicaltrials.gov/ct2/show
/NCT02037529. Accessed January 8, 2017.
41. clinicaltrials.gov. Trastuzumab Emtansine in
Treating Older Patients With Human Epidermal
Growth Factor Receptor 2-Positive Stage I-III Breast
Cancer. NCT02414646. https://clinicaltrials.gov
/ct2/show/NCT02414646. Accessed January 8,
2017.
42. Basch E, Wood WA, Schrag D, et al. Feasibility
and clinical impact of sharing patient-reported
symptom toxicities and performance status with
clinical investigators during a phase 2 cancer
treatment trial. Clin Trials. 2016;13(3):331-337.
43. Kluetz PG, Slagle A, Papadopoulos EJ, et al.
Focusing on core patient-reported outcomes in
cancer clinical trials: symptomatic adverse events,
physical function, and disease-related symptoms.
Clin Cancer Res. 2016;22(7):1553-1558.
44. Judson TJ, Bennett AV, Rogak LJ, et al.
Feasibility of long-term patient self-reporting of
toxicities from home via the internet during routine
chemotherapy. J Clin Oncol. 2013;31(20):2580-2585.
45. Broderick JE, Schwartz JE, Vikingstad G,
Pribbernow M, Grossman S, Stone AA. The accuracy
of pain and fatigue items across different reporting
periods. Pain. 2008;139(1):146-157.
46. Schneider S, Broderick JE, Junghaenel DU,
Schwartz JE, Stone AA. Temporal trends in
symptom experience predict the accuracy of recall
PROs. J Psychosom Res. 2013;75(2):160-166.
Research Original Investigation
Patient Reporting of Symptomatic Adverse Events in Multicenter Cancer Trials
1050
JAMA Oncology
August 2017
Volume 3, Number 8
(Reprinted)
jamaoncology.com
© 2017 American Medical Association. All rights reserved.
Downloaded From: https://jamanetwork.com/ on 06/03/2019
