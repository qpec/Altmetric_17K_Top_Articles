 Lower- Versus Higher-Income Populations In The Alternative 
Quality Contract: Improved Quality And Similar Spending
Zirui Song1, Sherri Rose2, Michael E. Chernew3, and Dana Gelb Safran4
1Zirui Song is a resident physician in the Department of Medicine at Massachusetts General 
Hospital and a clinical fellow at Harvard Medical School, both in Boston
2Sherri Rose is an associate professor of health care policy (biostatistics) in the Department of 
Health Care Policy, Harvard Medical School
3Michael E. Chernew is the Leonard D. Schaeffer Professor of Health Care Policy in the 
Department of Health Care Policy, Harvard Medical School
4Dana Gelb Safran is senior vice president of performance measurement and improvement at 
Blue Cross Blue Shield of Massachusetts and an associate professor of medicine at Tufts 
University School of Medicine, in Boston
Abstract
As population-based payment models become increasingly common, it is crucial to understand 
how such payment models affect health disparities. We evaluated health care quality and spending 
among enrollees in areas with lower versus higher socioeconomic status in Massachusetts before 
and after providers entered into the Alternative Quality Contract, a two-sided population-based 
payment model with substantial incentives tied to quality. We compared changes in process 
measures, outcome measures, and spending between enrollees in areas with lower and higher 
socioeconomic status from 2006 to 2012 (outcome measures were measured after the intervention 
only). Quality improved for all enrollees in the Alternative Quality Contract after their provider 
organizations entered the contract. Process measures improved 1.2 percentage points per year 
more among enrollees in areas with lower socioeconomic status than among those in areas with 
higher socioeconomic status. Outcome measure improvement was no different between the 
subgroups; neither were changes in spending. Larger or comparable improvements in quality 
among enrollees in areas with lower socioeconomic status suggest a potential narrowing of 
disparities. Strong pay-for-performance incentives within a population-based payment model 
could encourage providers to focus on improving quality for more disadvantaged populations.
Across the United States, public and private payers are increasingly entering population-
based payment arrangements with accountable care organizations (ACOs). These payment 
arrangements reward providers for improving the quality of care for a defined population of 
patients and establish accountability for spending. They may also influence disparities in 
quality of care that exist along socioeconomic and demographic lines.1–4 On the one hand, 
population-based payment models that reward high quality care could motivate physician 
organizations to focus on improving quality for more disadvantaged patients who have a 
greater opportunity for improvement, given that populations in areas with lower 
socioeconomic status may have lower quality scores at baseline.5,6 On the other hand, these 
HHS Public Access
Author manuscript
Health Aff (Millwood). Author manuscript; available in PMC 2018 February 08.
Published in final edited form as:
Health Aff (Millwood). 2017 January 01; 36(1): 74–82. doi:10.1377/hlthaff.2016.0682.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
 payment models could fail to address—or could even exacerbate—disparities, because 
physicians who serve more disadvantaged populations could face greater social or health 
care system–level challenges in achieving higher quality performance. Provider groups that 
serve areas with lower socioeconomic status might also be less likely than provider groups 
in other areas to join population-based payment models. To date, evidence related to the 
impact of population-based payment models on disparities in quality is lacking. Evidence is 
also lacking on whether medical spending differs by socioeconomic status under such 
payment models.
We evaluated changes in quality of care and medical spending among populations in areas 
with lower and higher socioeconomic status before and after their physicians entered the 
Alternative Quality Contract (AQC) with Blue Cross Blue Shield of Massachusetts. The 
AQC, launched in 2009, is a multiyear, population-based global budget model that has two-
sided incentives: It rewards physicians for savings below the risk-adjusted budget (shared 
savings) but also requires them to share in deficits with Blue Cross Blue Shield of 
Massachusetts for spending above the budget (shared risk). During the first four years of the 
AQC, the enrollee population comprised primarily those in health maintenance organization 
plans.
The Alternative Quality Contract rewards performance on sixty-four quality measures across 
ambulatory and inpatient settings and within both process and outcome domains. While the 
measures are similar to those in ACO contracts used by Medicare and other private insurers, 
rewards under the AQC tend to be substantially larger.7–10 The contract grew from seven 
provider organizations in 2009 to about 90 percent of Massachusetts physicians in the Blue 
Cross Blue Shield of Massachusetts network by 2012. Previous analyses have found 
decreases in medical spending on claims and improved quality performance associated with 
the contract relative to control, with net savings appearing in the fourth year.11,12
Study Data And Methods
Principal Component Analysis
We assigned enrollees to subgroups by lower and higher socioeconomic status, using a 
principal component analysis of socioeconomic and demographic characteristics for each 
enrollee's area of residence. Characteristics were obtained at the census block group level 
using the 2010 census and 2011 five-year American Community Survey from the Census 
Bureau.13,14 Census block groups better represent individuals than ZIP codes or census 
tracts because they comprise smaller and more homogenous populations than ZIP codes or 
census tracts, both of which are substantially larger geographic units.15 Five-year estimates 
from the American Community Survey allow for greater precision than one- or three-year 
estimates and are preferable when analyzing smaller populations or geographies.16 The area 
characteristics included variables such as race, education, income, and employment, which 
have been linked to quality of care.1–6,17,18
Principal component analysis is widely used in the biological and social sciences to collapse 
multidimensional data into fewer dimensions by generating variables that summarize the 
essential features of the original data.19 We performed a principal component analysis at the 
Song et al.
Page 2
Health Aff (Millwood). Author manuscript; available in PMC 2018 February 08.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
 census block group level, identifying three variables whose eigenvalues were above 1 (for 
details, see online Appendix Exhibit 1).20 Using the first principal component, we grouped 
enrollees by lower or higher socioeconomic status using the median as the cutoff. In 
sensitivity analyses, we used alternative cutoffs of the twenty-fifth and seventy-fifth 
percentiles.
Data, Population, and Variables
We analyzed data on process measures, outcome measures, and medical spending at the 
enrollee level. For process measures, data were collected at the enrollee level from 2007 to 
2012. For outcome measures, data at the enrollee level were available during the 
postintervention years (2009– 12) only. For medical spending, enrollee-level claims data 
were available from 2006 to 2012.
We focused on comparisons between subgroups in areas with lower and higher 
socioeconomic status within the 2009 AQC cohort, which comprised enrollees whose 
primary care physicians belonged to organizations that joined the AQC in that year. This 
included 299,285 individuals in the lower-socioeconomic-status subgroup who were 
continuously enrolled for at least one year and 244,415 individuals in the higher-
socioeconomic-status subgroup who were analogously enrolled.
In secondary analyses of process measures and spending, we included enrollees whose 
primary care physicians belonged to organizations not in the Alternative Quality Contract as 
a control group, to test whether trends by income group varied outside of the contract. This 
comparison population included 1,053,089 lower-socioeconomic-status and 650,041 higher-
socioeconomic-status Blue Cross Blue Shield of Massachusetts enrollees who were also 
continuously enrolled for at least one year. In secondary analyses of outcome measures, we 
used national and New England Healthcare Effectiveness Data and Information Set (HEDIS) 
average performance scores as an unadjusted comparison benchmark.
Process measures included eighteen ambulatory measures across three domains: chronic 
disease management, adult preventive care, and pediatric care (for a complete list of the 
measures, see Appendix Exhibit 2).20 Each measure was applied to enrollees eligible for the 
measure, and performance was measured as a binary outcome based on whether 
performance met criteria in a given year. For example, patients with diabetes would satisfy 
the eye exam measure if they received an eye exam in a given year. In the AQC, providers 
would receive a composite measure of quality performance annually, based on the weights 
assigned to each measure listed in Appendix Exhibit 2.20 The composite performance was 
then converted into financial rewards based on five “gates” of performance thresholds 
defined by the percentage of eligible members for whom the measure was met. We analyzed 
process measures in aggregate as a weighted average and by domain.
The Alternative Quality Contract included five outcome measures: hemoglobin A1c level at 
or below 9 percent, low-density lipoprotein (LDL) cholesterol level below 100 mg per 
deciliter, and blood pressure below 140/80 mmHg for patients with diabetes; LDL 
cholesterol in patients with coronary artery disease; and blood pressure in patients with 
hypertension. Outcome measures were collected at the enrollee level during postintervention 
Song et al.
Page 3
Health Aff (Millwood). Author manuscript; available in PMC 2018 February 08.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
 years for AQC enrollees, which precluded difference-in-differences analysis but enabled 
adjusted comparisons of postintervention trends. In unadjusted comparisons, we provided 
average performance at the Blue Cross Blue Shield of Massachusetts network level for the 
preintervention years and used the national and New England HEDIS average performance 
for a rough comparison group. Given the confidential nature of outcomes data, these 
measures had different anonymous enrollee identifiers that prevented cross-linkages with 
other Blue Cross Blue Shield of Massachusetts claims or quality data. Enrollees were linked 
to specific provider organizations in the contract via their primary care physician's 
affiliation.
Spending was the combination of the insurer payment and enrollee cost sharing. This 
reflects utilization and negotiated prices between payers and physician organizations. We 
captured differences in plan benefit design by using plan-level fixed effects in our main 
analyses. Given that plan-level benefit design might change over time, we also used average 
enrollee cost sharing at the plan level in a sensitivity analysis.11,12 Similar to prior analyses, 
pharmaceutical spending was excluded from the main analysis because some enrollees had 
drug benefits carved out of their benefit package, so claims for these services were not 
available in Blue Cross Blue Shield of Massachusetts claims. Spending was inflation 
adjusted to 2012 dollars.
Statistical Analysis
We used a difference-in-differences framework to isolate changes in process measures and 
spending associated with the Alternative Quality Contract among the subgroup of lower 
socioeconomic status relative to changes in the subgroup of higher socioeconomic status.
21,22 For outcome measures, we tested differences in postcontract trends between the 
subgroups of lower and higher socioeconomic status.
We used a linear multivariable model that regresses the dependent variable on an indicator of 
socioeconomic status interacted with postintervention years at the enrollee level. With a 
large sample size, linear models are often preferable to two-part models and other 
specifications in estimating the population average, which was the parameter of interest.23,24 
The base model controlled for age categories, interactions between age and sex, concurrent 
risk score based on the diagnostic cost group system, secular trends, and plan fixed effects. 
Regressions with quality as the dependent variable also included fixed effects for each type 
of quality measure, to identify “within measure” changes associated with socioeconomic 
status. Standard errors were clustered at the plan level. Given the confidentiality of outcomes 
data, which did not include plan information, standard errors in outcomes models were 
clustered at the physician organization level. Results were reported with two-tailed p values.
A major threat to the validity of this design is differential preintervention trends between 
AQC enrollees in areas with lower and higher socioeconomic status. Thus, we tested for 
differences in preintervention trends between the two subgroups. We also complemented 
these analyses with a triple-difference approach that included non–AQC enrollees similarly 
assigned to subgroups of lower and higher socioeconomic status. Because more physicians 
in Massachusetts joined the AQC over time, a reliable control group of non-AQC Blue Cross 
Song et al.
Page 4
Health Aff (Millwood). Author manuscript; available in PMC 2018 February 08.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
 Blue Shield of Massachusetts enrollees became less available two years after the contract.12 
Thus, triple-difference analyses were limited to two postintervention years.
Limitations
This study had several limitations. Data for the principal component analysis were census 
variables at the census block group level, instead of characteristics of individual enrollees. 
Thus, assignment of enrollees to subgroups of lower and higher socioeconomic status using 
geographic data might involve assignment error. Nevertheless, we used the geography of 
residence in determining the census block group, consistent with other studies.25,26 
Moreover, the census block group unit of geography is smaller and more homogenous than 
the ZIP code, county, or census tract, which improves the accuracy of socioeconomic status 
assignment.27,28
In addition, because we lacked individual-level outcome measures prior to the Alternative 
Quality Contract and for non-AQC enrollees, we could not draw strong inferences about 
outcome measures. However, our aggregate unadjusted analyses suggest no differential 
trends in improvement by socioeconomic status postintervention, resulting in similarly large 
improvements relative to national and New England comparisons.
Findings from the AQC might not be representative of global payment models by other 
payers or similar contracts in other states, as the population, the providers, and the incentives 
for this payment model might be different from other ACO contexts in important ways.29–31 
For example, the median household income for enrollees in the subgroup of lower 
socioeconomic status was higher than the median US household income, which is consistent 
with Massachusetts having one of the highest median incomes relative to other states. Thus, 
the subgroup of lower socioeconomic status in this study might not be representative of the 
degree of socioeconomic distress or vulnerability experienced by disadvantaged populations 
in other states. In sensitivity analyses, we examined comparisons using different cutoffs for 
defining subgroups of lower and higher socioeconomic status.
In addition, the average cost sharing in the study population was lower than in typical 
privately insured populations, which suggests that Blue Cross Blue Shield of Massachusetts 
plans were more generous, on average.
Our observational design also precludes strong causal inferences about AQC effects, given 
that entry into the contract was nonrandom and there could be unobserved factors that 
affected the results.
Lastly, the quality measures we studied do not capture all dimensions of quality that are 
important to physicians and patients. The process measures were largely primary care 
oriented, and the outcome measures touched on a small subset of intermediate outcomes of 
interest. Future developments in quality measures for specialties and in outcome measures 
would enrich such analyses of quality.
Song et al.
Page 5
Health Aff (Millwood). Author manuscript; available in PMC 2018 February 08.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
 Study Results
Population
Enrollees in the 2009 Alternative Quality Contract cohort in areas with lower and higher 
socioeconomic status were similar in age, sex, diagnostic cost group risk score, and average 
cost sharing (for details, see Appendix Exhibit 3).20 Enrollees of lower socioeconomic status 
lived in census block groups that had larger minority populations than did enrollees of 
higher socioeconomic status (12.6 percent black and 9.6 percent Hispanic, versus 1.6 percent 
black and 2.4 percent Hispanic), lower levels of education attainment (85.8 percent versus 
95.9 percent with at least high school completion), lower median household income 
($58,967 with 9.7 percent of families in poverty, versus $101,658 with 2.2 percent in 
poverty), and higher unemployment (9.6 percent versus 6.2 percent). Similar differences 
were evident among non-AQC enrollees (for details, see Appendix Exhibit 4).20 For 
summary characteristics of census block groups served by each AQC organization in the 
2009 cohort, see Appendix Exhibit 5.20
Process Measures
Unadjusted aggregate process measures improved more among AQC enrollees in the 
subgroup of lower socioeconomic status than among enrollees in the higher socioeconomic 
status subgroup during the four years, narrowing the difference between these subgroups 
(Exhibit 1). In adjusted analysis, the lower-socioeconomic-status subgroup in the AQC had a 
greater improvement in aggregate performance relative to the higher-socioeconomic-status 
subgroup—on average, 1.2 percentage points per year during the four years (p < 0.001) 
(Exhibit 2). Preintervention trends were not significantly different between the two 
subgroups (0.1 percentage points per year, p = 0.45). Sensitivity analyses were consistent 
with our main results (for results of the sensitivity analyses, see Appendix Exhibit 6).20
Analyses by domain showed that the differences in improvement were not statistically 
significant among chronic disease management measures (0.3 percentage points per year in 
favor of the subgroup of lower socioeconomic status, p = 0.53) but were statistically 
significant for the adult preventive care and pediatric care measures—on average, 1.2 and 
1.8 percentage points per year in favor of the subgroup of lower socioeconomic status, 
respectively (p < 0.001) (Exhibit 2). In secondary analyses involving non-AQC enrollees, the 
triple-difference model demonstrated qualitatively similar results consistent with Exhibit 1, 
which suggests that differential trends by socioeconomic status were not driving our 
findings.
Outcome Measures
Aggregate unadjusted performance on outcome measures demonstrated continuous 
improvement after the intervention among AQC enrollees in areas with both lower and 
higher socioeconomic status (Exhibit 3). Unadjusted performance for lower-socioeconomic-
status enrollees improved from 63.6 percent in 2009 to 73.8 percent in 2012 (a 10.2-
percentage-point change), while that for higher-socioeconomic-status enrollees improved 
from 65.3 percent to 76.0 percent (a 10.7-percentage-point change). In adjusted analysis, 
average improvement in outcome measures was not statistically different between lower-
Song et al.
Page 6
Health Aff (Millwood). Author manuscript; available in PMC 2018 February 08.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
 socioeconomic-status and higher-socioeconomic status subgroups across the four post-AQC 
years (−0.11 percentage point per year, p = 0.82). Sensitivity analyses supported our results 
(see Appendix Exhibit 7).20
In secondary analyses, the slope of improvement in outcome measures was comparably 
greater for AQC enrollees of both lower and higher socioeconomic status compared to 
national and New England HEDIS averages (Exhibit 3). This comparison is limited because 
HEDIS performance was not disaggregated by socioeconomic status, but it offers a sense of 
AQC performance across socioeconomic status subgroups relative to HEDIS.
Spending
Average unadjusted medical spending on claims was higher among AQC enrollees of lower 
socioeconomic status than among those of higher socioeconomic status nearly throughout 
the study period, and both subgroups saw slower growth in spending after the intervention 
(Exhibit 4).
In adjusted analyses, AQC enrollees of lower socioeconomic status had similar changes in 
spending as did their higher-socioeconomic-status peers during the first four years of the 
contract, but the difference was not statistically significant (−$5.74 per enrollee per quarter, 
p = 0.43) (Exhibit 2). Preintervention trends in spending between these two subgroups were 
also not significantly different (−$3.06 difference, p = 0.52) (data not shown). Sensitivity 
analyses were broadly consistent with these findings, although a more restrictive definition 
of lower socioeconomic status produced a small but statistically significant difference in 
spending (see Appendix Exhibit 8).20 The triple-difference model also demonstrated 
qualitatively similar results.
Discussion
Improvements in process measures were generally greater among Alternative Quality 
Contract enrollees in areas with lower socioeconomic status than among those in higher-
socioeconomic status areas during the AQC's first four years. This finding was robust to 
secondary analyses and sensitivity analyses, including those that used Blue Cross Blue 
Shield of Massachusetts enrollees who were not in the AQC as controls. The lack of 
preintervention and control data for outcome measures at the individual level precluded as 
thorough of an analysis for outcomes. Nevertheless, our adjusted analysis of outcomes 
postintervention shows comparable trends between subgroups of lower and higher 
socioeconomic status, and both subgroups outperformed national and New England HEDIS 
averages. Meanwhile, spending trends were similar between the subgroups. Overall, these 
findings suggest a likely narrowing of disparities in process quality under the AQC without 
significant differences in spending along the socioeconomic status dimension.
The fact that disparities between enrollees in areas with lower and higher socioeconomic 
status narrowed among process measures but not for outcome measures, despite larger 
improvements for both subgroups in outcome measures, could reflect a weak relationship 
between process and outcome measures. For example, monitoring hemoglobin A1c for 
patients with diabetes (process measure) might not translate into lower hemoglobin A1c 
Song et al.
Page 7
Health Aff (Millwood). Author manuscript; available in PMC 2018 February 08.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
 levels (outcome measure). Moreover, most process measures, such as cancer screening, do 
not have a corollary in the outcome measure domain (for example, cancer-specific survival 
rates), and improvements in outcomes may take longer to manifest. In general, improvement 
in outcome measures is considered more complex and challenging because it requires patient 
adherence and changes in health behaviors, which are less under the direct influence of 
providers than process measures are. The fact that outcomes improved substantially for AQC 
enrollees of both lower and higher socioeconomic status is meaningful.
Furthermore, quality measures in the AQC exhibited different trends in improvement when 
compared to national and New England HEDIS averages. Process measures improved 
slowly across the postintervention years, potentially reflecting the increased difficulty of 
further improvement at higher baseline levels of performance. Meanwhile, outcome 
measures improved more quickly and in a sustained fashion. This difference could be 
explained by lower baseline performance for outcome measures as compared with process 
measures, rendering outcome measures less susceptible to a ceiling effect by which 
improvement is increasingly difficult from higher levels of performance. This ceiling effect 
may have analogously contributed to greater improvements in process quality attained by 
enrollees of lower socioeconomic status, who began with lower performance levels than 
those of their peers in higher-socioeconomic-status areas. The fact that outcome measures 
were triple-weighted toward determining incentive payments in the AQC, whereas process 
measures were largely single-weighted, might have also contributed to the difference. Gains 
in the intermediate outcomes of hemoglobin A1c, LDL, and blood pressure reflect improved 
control of major chronic illnesses including hypertension, diabetes, and risk factors for 
coronary artery disease and stroke—an encouraging sign relative to regional and national 
averages.
The sizable incentives for quality under the AQC might have played an important role in the 
greater gains among enrollees of lower socioeconomic status compared to their peers in 
higher-socioeconomic-status areas. In 2009– 10, physician organizations could earn up to 10 
percent of their risk-adjusted budgets in bonus payments for quality performance—an 
amount substantially larger than the 2.3 percent average bonus for quality performance in 
prior pay-for-performance contracts.10 Since 2011, rewards for quality were determined as a 
per member per month amount to equalize payments across physician organizations for a 
given level of performance, but they nevertheless remained substantial.32 For population-
based payment models elsewhere in the country, the Alternative Quality Contract could 
provide an example of the potential of large quality incentives to improve quality without 
exacerbating disparities. Indeed, even in a relatively higher-average-income population 
overall, differences in quality still narrowed under the AQC.
Qualitative evidence suggests that AQC organizations tended to place an emphasis on 
quality improvement, partly because bonuses were large and could be allocated freely by the 
organization internally.33 Additional discussions from Blue Cross Blue Shield of 
Massachusetts collaborations with AQC providers and best-practice sharing forums suggest 
that providers serving areas with lower socioeconomic status developed strategies for patient 
engagement, in many cases adopting new staffing models to enable more customized 
outreach to improve access and achieve quality goals for patients. For patients, receiving 
Song et al.
Page 8
Health Aff (Millwood). Author manuscript; available in PMC 2018 February 08.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
 more frequent communication regarding preventive care may help compliance with 
recommended services. Moreover, the size of the Blue Cross Blue Shield of Massachusetts 
enrollee population could help facilitate positive peer- or neighborhood-level effects on 
health, given that populations with similar socioeconomic and demographic characteristics 
tend to cluster geographically.34,35 Ultimately, social and environmental factors are 
recognized to play a larger role than health care in determining the health of populations. 
This suggests that efforts to reduce disparities in poverty, education, and related factors 
would be an important complement to interventions in the health care system.36,37
Conclusion
During the first four years of the Alternative Quality Contract in Massachusetts, 
improvements in quality of care for enrollees in areas with lower socioeconomic status were 
comparable or greater than those in areas with higher socioeconomic status, without 
statistically significant differences in spending trends. These results suggest that in its early 
years, the AQC likely contributed to a narrowing of disparities in some dimensions of 
quality, notably as reflected by process measures in the contract. Moreover, our results 
suggest that in a population-based global budget model, sufficiently large quality incentives 
with an overall adequate budget could be important factors in giving physician organizations 
the financial resources necessary to intensify efforts toward improving quality of care for 
disadvantaged populations.
Supplementary Material
Refer to Web version on PubMed Central for supplementary material.
Acknowledgments
This study was presented in the plenary sessions of both the 2016 Society of General Internal Medicine (SGIM) 
New England meeting and the 2016 SGIM annual meeting. The authors are grateful for feedback and suggestions 
from the meetings. The study was supported by a National Institute on Aging MD/PhD National Research Service 
Award (to Zirui Song, No. F30 AG039175) and a grant from the Commonwealth Fund (to Michael Chernew). The 
views expressed in this article are those of the authors and do not necessarily represent the official views of the 
National Institute on Aging or the National Institutes of Health. The authors are grateful to Angela Li, Lulu Liu, 
Matthew Day, and Young Sul for assistance with the data.
Notes
1. Institute of Medicine. workshop summary Washington (DC). National Academies Press; 2012 Sep. 
How far have we come in reducing health disparities? Progress since 2000. 
2. Agency for Healthcare Research and Quality; Rockville (MD): AHRQ; 2015 Jun. 2014 national 
healthcare quality and disparities report [Internet]. [cited 2016 Nov 15]. Available for download 
from: http://www.ahrq.gov/research/findings/nhqrdr/nhqdr14/index.html
3. Institute of Medicine. Crossing the quality chasm: a new health system for the 21st century. 
Washington (DC): National Academies Press; 2001. 
4. Institute of Medicine. Unequal treatment: confronting racial and ethnic disparities in health care. 
Washington (DC): National Academies Press; 2003. 
5. Schneider EC, Zaslavsky AM, Epstein AM. Racial disparities in the quality of care for enrollees in 
Medicare managed care. JAMA. 2002; 287(10):1288–94. [PubMed: 11886320] 
6. Trivedi AN, Zaslavsky AM, Schneider EC, Ayanian JZ. Trends in the quality of care and racial 
disparities in Medicare managed care. N Engl J Med. 2005; 353(7):692–700. [PubMed: 16107622] 
Song et al.
Page 9
Health Aff (Millwood). Author manuscript; available in PMC 2018 February 08.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
 7. Chernew ME, Mechanic RE, Landon BE, Safran DG. Private-payer innovation in Massachusetts: the 
“Alternative Quality Contract”. Health Aff (Millwood). 2011; 30(1):51–61. [PubMed: 21209437] 
8. Song Z, Safran DG, Landon BE, He Y, Ellis RP, Mechanic RE, et al. Health care spending and 
quality in year 1 of the Alternative Quality Contract. N Engl J Med. 2011; 365(10):909–18. 
[PubMed: 21751900] 
9. Centers for Medicare and Medicaid Services. Baltimore (MD): CMS; Quality measures and 
performance standards [Internet]. [last updated 2015 Mar 2; cited 2016 Nov 15] Available from: 
https://www.cms.gov/Medicare/Medicare-Fee-for-Service-Payment/sharedsavingsprogram/
Quality_Measures_Standards.html
10. Rosenthal MB, Landon BE, Howitt K, Song HR, Epstein AM. Climbing up the pay-for-
performance learning curve: where are the early adopters now? Health Aff (Millwood). 2007; 
26(6):1674–82. [PubMed: 17978386] 
11. Song Z, Safran DG, Landon BE, Landrum MB, He Y, Mechanic RE, et al. The “Alternative 
Quality Contract,” based on a global budget, lowered medical spending and improved quality. 
Health Aff (Millwood). 2012; 31(8):1885–94. [PubMed: 22786651] 
12. Song Z, Rose S, Safran DG, Landon BE, Day MP, Chernew ME. Changes in health care spending 
and quality 4 years into global payment. N Engl J Med. 2014; 371(18):1704–14. [PubMed: 
25354104] 
13. Census Bureau. 2010 census data [Internet]. Washington (DC): Census Bureau; [cited 2016 Nov 
15]. Available from: http://www.census.gov/2010census/data/
14. Census Bureau. American Community Survey (ACS) [Internet]. Washington (DC): Census Bureau; 
[cited 2016 Nov 15]. Available from: https://www.census.gov/programs-surveys/acs/
15. Census Bureau. Geographic terms and concepts—block groups [Internet]. Washington (DC): 
Census Bureau; [cited 2016 Nov 15]. Available from: https://www.census.gov/geo/reference/gtc/
gtc_bg.html
16. Census Bureau. American Community Survey: when to use 1-year, 3-year, or 5-year estimates 
[Internet]. Washington (DC): Census Bureau; [last updated 2015 Aug 25; cited 2016 Nov 15 
Available from: https://www.census.gov/programs-surveys/acs/guidance/estimates.html
17. Zaslavsky AM, Hochheimer JN, Schneider EC, Cleary PD, Seidman JJ, McGlynn EA, et al. Impact 
of sociodemographic case mix on the HEDIS measures of health plan quality. Med Care. 2000; 
38(10):981–92. [PubMed: 11021671] 
18. Trivedi AN, Zaslavsky AM, Schneider EC, Ayanian JZ. Relationship between quality of care and 
racial disparities in Medicare health plans. JAMA. 2006; 296(16):1998–2004. [PubMed: 
17062863] 
19. Jolliffe, IT. Principal component analysis. First edition. New York (NY): Springer; 1986. 
20. To access the Appendix, click on the Appendix link in the box to the right of the article online.
21. Angrist, JD., Pischke, JS. Mostly harmless econometrics: an empiricist's companion. Princeton 
(NJ): Princeton University Press; 2009. 
22. Wooldridge, JM. Econometric analysis of cross section and panel data. Cambridge (MA): MIT 
Press; 2001. 
23. Buntin MB, Zaslavsky AM. Too much ado about two-part models and transformation? Comparing 
methods of modeling Medicare expenditures. J Health Econ. 2004; 23(3):525–42. [PubMed: 
15120469] 
24. Manning WG, Basu A, Mullahy J. Generalized modeling approaches to risk adjustment of skewed 
outcomes data. J Health Econ. 2005; 24(3):465–88. [PubMed: 15811539] 
25. Friedberg MW, Safran DG, Coltin K, Dresser M, Schneider EC. Paying for performance in primary 
care: potential impact on practices and disparities. Health Aff (Millwood). 2010; 29(5):926–32. 
[PubMed: 20439882] 
26. Mullan F, Phillips RL Jr, Kinman EL. Geographic retrofitting: a method of community definition in 
community-oriented primary care practices. Fam Med. 2004; 36(6):440–6. [PubMed: 15181557] 
27. Neuman P, Strollo MK, Guterman S, Rogers WH, Li A, Rodday AM, et al. Medicare prescription 
drug benefit progress report: findings from a 2006 national survey of seniors. Health Aff 
(Millwood). 2007; 26(5):w630–43. [PubMed: 17711865] 
Song et al.
Page 10
Health Aff (Millwood). Author manuscript; available in PMC 2018 February 08.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
 28. Safran DG, Strollo MK, Guterman S, Li A, Rogers WH, Neuman P. Prescription coverage, use, and 
spending before and after Part D implementation: a national longitudinal panel study. J Gen Intern 
Med. 2010; 25(1):10–7. [PubMed: 19882193] 
29. McWilliams JM, Chernew ME, Landon BE, Schwartz AL. Performance differences in year 1 of 
Pioneer accountable care organizations. N Engl J Med. 2015; 372(20):1927–36. [PubMed: 
25875195] 
30. Pham HH, Cohen M, Conway PH. The Pioneer accountable care organization model: improving 
quality and lowering costs. JAMA. 2014; 312(16):1635–6. [PubMed: 25229477] 
31. Nyweide DJ, Lee W, Cuerdon TT, Pham HH, Cox M, Rajkumar R, et al. Association of Pioneer 
accountable care organizations vs traditional Medicare fee for service with spending, utilization, 
and patient experience. JAMA. 2015; 313(21):2152–61. [PubMed: 25938875] 
32. Blue Cross Blue Shield of Massachusetts. Massachusetts payment reform model: results and 
lessons [Internet]. Boston (MA): BCBSMA; 2012 Oct. [cited 2016 Nov 15]. Available from: 
https://www.bluecrossma.com/visitor/pdf/aqc-results-white-paper.pdf
33. Mechanic RE, Santos P, Landon BE, Chernew ME. Medical group responses to global payment: 
early lessons from the “Alternative Quality Contract” in Massachusetts. Health Aff (Millwood). 
2011; 30(9):1734–42. [PubMed: 21900665] 
34. Ludwig J, Sanbonmatsu L, Gennetian L, Adam E, Duncan GJ, Katz LF, et al. Neighborhoods, 
obesity, and diabetes—a randomized social experiment. N Engl J Med. 2011; 365(16):1509–19. 
[PubMed: 22010917] 
35. Ludwig J, Duncan GJ, Gennetian LA, Katz LF, Kessler RC, Kling JR, et al. Neighborhood effects 
on the long-term well-being of low-income adults. Science. 2012; 337(6101):1505–10. [PubMed: 
22997331] 
36. Bradley, EH., Taylor, LA. The American health care paradox: why spending more is getting us 
less. New York (NY): Public Affairs; 2013. 
37. Bradley EH, Elkins BR, Herrin J, Elbel B. Health and social services expenditures: associations 
with health outcomes. BMJ QualSaf. 2011; 20(10):826–31.
Song et al.
Page 11
Health Aff (Millwood). Author manuscript; available in PMC 2018 February 08.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
 Exhibit 1. Performance on Process Quality Measures, 2007-2012*
* Unadjusted aggregate process quality as a weighted average composite of 18 process 
measures across 3 domains: chronic disease management, adult preventive care, and 
pediatric care. Each measure was applied to enrollees eligible for the measure, such as 
hemoglobin A1c measurement for patients with diabetes. Performance was measured as a 
binary outcome based on whether the measure was satisfied in a given year.
Song et al.
Page 12
Health Aff (Millwood). Author manuscript; available in PMC 2018 February 08.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
 Exhibit 2. Changes in quality of care and medical spending by socioeconomic status under the 
Alternative Quality Contract (AQC), 2006–12
SOURCE Authors' analysis of data from Blue Cross Blue Shield of Massachusetts.
NOTES aFor quality, preintervention refers to 2007–08 and postintervention refers to 2009–
12. The difference-in-differences results represent the average changes in the percentage of 
eligible enrollees for a measure who met quality performance for the measure from before to 
after the AQC in the lower socioeconomic status subgroup as compared with the higher 
socioeconomic status subgroup. Quality measures are measured on an annual basis. bFor 
spending, preintervention refers to 2006–08 and postintervention refers to 2009–12. PMPQ 
represents per member per quarter. The difference-in-differences results represent the 
average change in medical spending on claims per enrollee per quarter from before to after 
the AQC in the lower socioeconomic status subgroup as compared with the higher 
socioeconomic status subgroup. Spending is inflation-adjusted to 2012 dollars.
Song et al.
Page 13
Health Aff (Millwood). Author manuscript; available in PMC 2018 February 08.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
 Exhibit 3. Performance on Outcome Quality Measures, 2007-2012*
* Unadjusted aggregate outcome quality comprising 5 measures: hemoglobin A1c level 
≤9%, low-density lipoprotein (LDL) cholesterol level <100 mg per deciliter, and blood-
pressure <140/80 mmHg for patients with diabetes;LDL cholesterol in patients with 
coronary artery disease; blood-pressure <140/80 mmHg for patients with hypertension. 
Given that 2007 and 2008 were pre-intervention years, data were collected at the BCBSMA 
network level andperformance was not separable by SES for AQC enrollees.
Song et al.
Page 14
Health Aff (Millwood). Author manuscript; available in PMC 2018 February 08.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
 Exhibit 4. Medical Spending, 2006-2012*
* Unadjusted aggregate medical spending per enrollee per quarter as obtained through 
medical claims, representing the sum of the amount paid by the payer and the amount paid 
through enrollee cost-sharing. Spending is inflation-adjusted to 2012 dollars.
Song et al.
Page 15
Health Aff (Millwood). Author manuscript; available in PMC 2018 February 08.
Author Manuscript
Author Manuscript
Author Manuscript
Author Manuscript
