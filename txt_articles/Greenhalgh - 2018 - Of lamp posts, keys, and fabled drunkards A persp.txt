 O R I G I N A L A R T I C L E
Of lamp posts, keys, and fabled drunkards: A perspectival tale
of 4 guidelines
Trisha Greenhalgh F. Med. Sci, Professor
Nuffield Department of Primary Care Health
Sciences, University of Oxford, Oxford, UK
Correspondence
Trisha Greenhalgh, Nuffield Department of
Primary Care Health Sciences, University of
Oxford, Radcliffe Primary Care Building,
Radcliffe Observatory Quarter, Woodstock
Road, Oxford OX2 6GG, UK.
Email: trish.greenhalgh@phc.ox.ac.uk
Funding information
National Institute for Health Research Bio-
medical Research Centre, Grant/Award Num-
ber: BRC‐1215‐20008
Abstract
Background:
Evidence‐based medicine is the application of research findings to
inform individual clinical decisions. There is a tension—both philosophical and practi-
cal—between the average result from a population study and the circumstances and
needs of an individual patient. This personal account of “evidence‐based” trauma care
illustrates and explores this tension.
The case:
The author, a keen athlete, describes her experience of a high‐impact
cycle accident that led to limb fractures (which were diagnosed and treated according
to evidence‐based guidelines) and also an occult injury to the cervical spine (which
was not diagnosed at the time). Some evidence‐based guidelines are reviewed and
applied to the case.
The clinical record described the cycle accident as a “fall.” Initial assessment directed
the clinicians' gaze to the obvious injuries, whose treatment was straightforward. On
admission, the patient (aged 55 years at the time) was offered “falls prevention” via a
guideline‐based checklist. Several months later, neurological sequelae indicated possi-
ble damage to the cervical spine. But the NICE Guideline recommending cervical spine
imaging in cases of high‐impact trauma had not been considered—perhaps because
the clinical narrative had been prematurely assigned to the script of “older person
with fall.” Furthermore, the author, who was (appropriately) treated with neurosur-
gery, was surprised at the response of clinical colleagues, based on application of an
irrelevant section of a guideline, that her cervical discectomy was “nonevidence
based.” Nonsteroidal anti‐inflammatory drugs for postoperative pain were indicated
in this patient even though they were not recommended for the average patient.
Conclusion:
As
Sir
John
Grimley
Evans'
warned,
we
should
avoid
using
evidence‐based guidelines in the manner of the fabled drunkard who searched under
the lamp post for his key because that was where the light was, even though he knew
he had lost his key somewhere else.
KEYWORDS
auto‐ethnography, evidence‐based medicine, guidelines, narrative, rationality, reason
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
This is an open access article under the terms of the Creative Commons Attribution‐NonCommercial License, which permits use, distribution and reproduction in any
medium, provided the original work is properly cited and is not used for commercial purposes.
© 2018 The Authors Journal of Evaluation in Clinical Practice Published by John Wiley & Sons Ltd
Received: 25 February 2018
Accepted: 9 March 2018
DOI: 10.1111/jep.12925
1132
J Eval Clin Pract. 2018;24:1132–1138.
wileyonlinelibrary.com/journal/jep
 1
|
INTRODUCTION
I owe my life to evidence‐based medicine (EBM),1 but that is not the
story I want to tell in this article. Here, I want to tell a more critical
story—of how the assiduous application of “good” evidence‐based
guidelines can sometimes result in a “bad” patient experience. My reflec-
tions are not intended as criticism of the particular doctors who treated
me. They are pitched at a much wider audience: each and all of us who
seek to apply evidence‐based guidelines to individual patients.
Evidence‐based medicine saves lives, but it is not perfect.2 Valkenburg
et al distinguish between limits to EBM that might someday be overcome
by more research (either methodological or empirical) and more philosoph-
ical limits that are inherent to EBM's recommended approach.3 The latter
category, they argue, covers 2 main issues: first, that EBM standardizes
the patient and second, that EBM standardizes moral considerations.
Evidence‐based medicine standardizes the patient because (for
example) evidence‐based guidelines are based largely on findings from
randomized controlled trials (RCTs). Conceptually speaking, RCTs are sim-
ple (indeed, somewhat crude) experiments: take a sample of individuals
who meet particular inclusion criteria, allocate them at random to inter-
vention or control arms, follow through to a predefined primary endpoint,
and assess whether differences between the 2 arms are both clinically
and statistically significant. The result, if definitive, can inform a recom-
mendation in a guideline. Such a recommendation states (effectively) that,
on average, people meeting inclusion criteria XYZ (and ignoring people
meeting exclusion criteria PQR) will gain significant benefit from the inter-
vention tested, compared with whatever was offered to those in the con-
trol arm. It does not (indeed, it cannot) mean that every individual meeting
the inclusion criteria of the trial will benefit from the intervention.4
Evidence‐based
medicine
standardizes
moral
considerations
because responsibility for the case‐based moral question that drives
every clinical decision (“what is the best thing to do for this patient,
in these circumstances?”) is, at least in part, removed from the clinician
and assigned to the processes and procedures inscribed in an
evidence‐based guideline or recommendation.
The consequence of standardizing both the patient and the moral
considerations of how to manage him or her means that (a) patients—
who come in all shapes and sizes and with a vast range of
co‐morbidities, sociocultural influences, and personal idiosyncrasies—
are wrongly assumed to conform to the “ideal type” patient around
which the trial was designed and (b) the clinician is placed under pow-
erful but clandestine moral pressure to align the management of this
patient with the management of the ideal type.
An evidence‐based guideline is rarely based on a single RCT. It is the
product of a complex and laborious process of identifying, reviewing, and
collatingbothprimaryevidenceandsystematicreviews(andmostespecially,
meta‐analyses andmega‐trials).5 The developmentofanewguideline, orthe
updating of an existing one, generally requires the convening of a panel of
experts (clinical, academic, and—these days—1 or 2 “experts by experience”
previously known as patients) whose credentials and conflicts of interest are
carefully examined to ensure they are both capable and dispassionate.
Drawing on the French philosopher Bruno Latour, Valkenburg
et al highlight how the highly systematic and meticulously policed gen-
eration of evidence‐based guidelines has the effect of turning particu-
lar scientific findings into “facts.” They observe that
… a fact is developed following a certain path. First there
is the inspiration to a new claim. The scientist starts with
a large amount of existing texts. They are shaped as
schoolbooks, articles, results from experiments etc. etc.
These texts form the starting point for a scientist. He
[sic] uses them, and reorganises them in a new fashion.
He
may
cite
them,
stimulate
their
(re)publication,
discuss them in seminars etc. etc. The scientist uses the
texts to underpin a claim he wants to make. He actually
builds a complex network around his claim, in order to
provide it with solid ground. In this network, the
function of a text may be altered. What, for example,
previously had been presented as a surmise, may now
be presented as an undisputed fact. (page 465)3
The “facts” in guidelines are regularly disputed of course, but
there is more than a grain of truth in the claim that the effort, expense,
and apparent rigour of the guideline development process place the
clinician under substantial pressure to adhere to them.
Real‐world clinicians are often rightly cautious of the “facts” in
evidence‐based guidelines, since the guideline development process
and its documentation tend to generate a sanitized (and misleadingly
clear‐cut) account of how particular items of evidence and/or particu-
lar caveats were either included in, or excluded from, the guideline. As
Kelly and Moore have observed:
The principles of the elimination of the possibility of bias
in the hierarchy of evidence, of the rule‐driven principles
of guideline development and appraisal are based on an
ideal version of the scientific method, which owe more
to the logical precepts of the a priori relations of ideas
than they do to messy empirical observation. (page 10)6
Beforeusingapersonalcasestudytoillustratethepicklethatcanresult
from uncritical adherence to evidence‐based guidelines, I want to introduce
a third philosophical limitation of EBM, which is a consequence of the 2 lim-
itations described above. Because of its reliance on population‐derived evi-
dence, EBM drives (indeed, requires) the clinician to reason from the general
to the particular, which cuts across traditional clinical assessment and man-
agement (which runs from the particular to the general).
To understand traditional clinical reasoning, we need to go back to
an era before EBM became the norm. Back in 1982, Jerome Kassirer
and colleagues published an article entitled “Toward a Theory of
Clinical Reasoning.”7 In it, they reproduce a transcript of a discussion
between one of them (“experimenter,” E) and a doctor‐subject (S),
about a hypothetical patient (page 254)7:
E: This is a 57‐year‐old admitted to the hospital with the chief complaint
of nausea, vomiting, abdominal pain, and frequency of urination.
S: First I'm going to ask some questions about the character of her uri-
nary stream because I'm thinking in terms of infection of her urinary
tract. Did the patient notice any blood in her urine?
E: No, she didn't.
S: That she didn't have gross hematuria makes me turn away from one
possibility—that she might have passed a stone in association with
infection. She might have had a hemorrhagic cystitis but that makes it
GREENHALGH
1133
 unlikely, just at first cut. You said she had frequency—did she have pain
on urination? I'm asking that in terms of also inflammation of the
bladder.
E: She did complain of some burning on urination.
S: Now again continuing along the infection line, I'm going to ask
whether she had a fever just in terms of general infection.
This transcript illustrates how, in analysing an (albeit hypothetical)
case, the traditional clinician first asks a question about the patient and
only then considers what evidence from the literature may be
relevant. When one possible diagnosis does not match, the clinician
returns to seek more information about the patient—thus reasoning
from the particular to the general (“the patient has characteristic X;
could it be illness Y?”).
This kind of reasoning still occurs in clinical practice. But my own
experience as a patient suggests that it now receives far less attention
from clinicians, whose primary focus now tends to be assigning their
patient to a particular guideline, after which management will be more
or less protocol based. As early as 1998, Mark Tonelli was moved to
comment that:
… in EBM, the individuality of patients tends to be
devalued, the focus of clinical practice is subtly shifted
away from the care of individuals toward the care of
populations, and the complex nature of sound clinical
judgement is not fully appreciated.8
More recently, Engebretsen et al9 summarized the literature
critiquing EBM's lack of engagement with the need to individualize
assessment and diagnosis. Drawing on Lonergan, they remind us that
the process of clinical inquiry is a complex process of interpretation,
comprising 4 overlapping phases: (a) collecting sensations and obser-
vations (“something that calls for explanation”)—what we might call
data; (b) interpreting those data (asking “what could this be?”)—and
leading, hopefully, to understanding; (c) weighing up competing inter-
pretations by a process of judgement; and (d) choosing how to act
(by asking “what is the right thing to do?”)—a process of deliberation.
This individual‐to‐general reasoning, these authors argue, should be
reflexive and informed by scientific evidence—but the latter can never
replace the former.
In the remainder of this paper, I describe a personal experience
to illustrate the dangers of replacing the sequence of data‐
understanding‐judgement‐deliberation centred on the patient with
the apparently more rational approach of reaching immediately for
an evidence‐based guideline.
2
|
A PERSONAL CASE HISTORY
Drawing on the principles of narrative research,10 and more specifi-
cally those of auto‐ethnography,1 I present below a subjective account
of a trauma incident and my recollections of how both the acute epi-
sode and its sequelae were managed.
Narrative research, of which auto‐ethnography is one example,
does not seek to produce hard facts, rather it is necessarily and irrev-
ocably perspectival: one person's interpretations of their observations
and experience. Indeed, the internationally renowned qualitative
researcher Norman Denzin defines auto‐ethnography as “an imagina-
tive organisation of experience that imposes a distortion of truth”
(page 13).11
Accordingly, the sequence of events below should not be viewed
as “facts” in the narrow sense. Whilst the experiences occurred a few
years ago, I have tried to reproduce the sequence of events and deci-
sions as accurately as I can. My account is to a large extent objectively
verifiable through test results and medical record notes. Nevertheless,
it is inevitable that my recall of the initial events will be incomplete
and coloured by what happened subsequently. But, importantly, this
“distortion of truth” does not invalidate the philosophical arguments
the story is intended to illustrate.
I have deliberately not included details of the hospitals or clini-
cians involved. As noted above, my goal is not to criticize individual
actions but to surface and question a contemporary approach to clin-
ical management that is increasingly widespread—and, I believe, rarely
challenged.
2.1
|
Case narrative: a cycle accident
I was riding my racing bicycle by the side of a canal. It was a sunny day
and there was nobody else around. That part of the towpath was wide
and smooth, and the surface had recently been improved with a layer
of smooth concrete. I was pedalling hard and going quite fast (about
20 miles an hour). I was wearing Lycra racing gear and special cycling
shoes that were fixed to the pedals.
Suddenly, a mechanical failure occurred. Perhaps something got
caught in my front wheel. Perhaps the chain jammed. Abruptly, my
feet were prevented from circling and the front wheel stopped dead.
The rear wheel left the ground and the entire bike somersaulted high
into the air. My feet were locked into the pedals so I went with it.
I came down heavily on the concrete, attempting to break my fall
by putting my arms over my head. I initially landed on my bent arms
(which took the brunt of the fall) and heard the crack of breaking
bones. I bounced off the concrete. The back of my head took the
second hit, splitting my cycle helmet. I was very dazed but had not
been knocked out. Both my arms were deformed and useless. All my
fingers were numb and painful.
For various reasons, it took a couple of hours to reach the hospi-
tal, by which time I was cold and shivering. A triage nurse, followed by
a more senior nurse, asked me questions and gave me paracetamol.
My arms were X‐rayed and confirmed a comminuted fracture of the
left olecranon (elbow) and a severely impacted fracture of distal radius
(forearm) on the right. An attempt to reduce the fractured radius
under regional anaesthesia was unsuccessful. I was given more pain-
killers and put on the list for an operation the next day, where the
fractures were realigned and repaired using internal fixation.
The afternoon following my accident, I was visited by a woman
who introduced herself as the “falls co‐ordinator.” She was wearing a
white coat and carrying a clipboard with a tick‐box chart on it. She
began to go through a structured list of questions, including “do you
take four or more prescription drugs a day?” and “have you ever felt
unsteady on your feet?”. After a few of these questions, we both
agreed that there was little point in continuing with the assessment,
since my accident had not been the kind of fall that the designers of
1134
GREENHALGH
 the guideline she was following had had in mind. We exchanged pleas-
antries and she wished me a speedy recovery.
In the weeks that followed, I struggled to rehabilitate myself and
return to work with both upper limbs injured. My arm muscles wasted
despite intensive physiotherapy, and the pain and numbness in my
fingers improved only marginally. The grip in both hands was weak
and getting weaker. A further operation was done to shorten the ulna
(forearm bone) in one arm to try to relieve the unexplained pain. This
was unsuccessful. I began to stumble when I walked—something that
had never occurred before.
Eight months after the original injury, I consulted a new ortho-
paedic surgeon, who examined me and ordered a magnetic resonance
imaging scan of my neck. This showed collapse of 3 lower cervical
vertebrae and herniation of several intervertebral discs. A link to the
original trauma was suspected but unproven. I was advised to have
surgery to my cervical spine with some urgency. In a 5‐hour opera-
tion, the surgeon replaced 2 damaged intervertebral discs and decom-
pressed
various
nerve
roots.
The
operation
was
immediately
successful, to the extent that when the surgeon visited me in the
recovery room, I could squeeze his hand with more power than I
had had since my accident. The pain and numbness in my fingers
were gone.
I had been warned that I should expect considerable pain after my
operation. I was offered opioid analgesia, but this class of drugs has
always made me feel very sick. In the days before my operation, I
explored the option of nonsteroidal anti‐inflammatory drugs (NSAIDs),
which I have taken in the past with no side effects. I put out a question
on Twitter (where I have many thousands of followers, many of them
clinicians interested in EBM). The response of many people to my
140‐character tweet was that (a) my forthcoming cervical spine sur-
gery was “not evidence based,” so I should pull out of having it and
(b) NSAIDs delay bone healing after orthopaedic surgery, so I should
not take those.
Both these pieces of advice were offered with apparent confi-
dence by clinicians who identified as part of the EBM movement.
Others (some of them frontline clinicians who were less closely
aligned with the EBM movement) gave anecdotal accounts of NSAIDs
being very useful analgesics after spinal surgery, with the advantage of
being “opioid sparing.”
Following my operation, I took NSAIDs (which controlled my pain
well) and made an uneventful recovery.
3
|
COMMENTARY
In this section, I offer an interpretation of what was said and done to
me by clinicians, along with discussion of relevant (and also, as it
turned out, irrelevant and imaginary) guidelines. In particular, I
consider 4 aspects of my clinical management and a guideline or pos-
sible guideline that may apply to each: (a) the decision not to order
imaging studies of my cervical spine at the time of my accident; (b)
the decision to use a falls prevention checklist; (c) the decision, several
months later, to perform cervical discectomy and decompression; and
(d) the decision to prescribe NSAIDs for postoperative pain relief after
spinal surgery.
The question of whether a patient with an acute head injury
should be offered imaging of the cervical spine is addressed in NICE
Guideline 76.12 The relevant section of the algorithm is shown in
Figure 1. It includes the situation where the patient is alert and
oriented, but there is also “suspicion of cervical spine injury” along
with a history of “fall from >1 metre” and/or “bicycle collision.” My
bicycle had somersaulted in a way that precipitated a fall from well
over 1 metre, and whilst the cycle itself did not collide with anything
(since I hit the ground before it did), its occupant collided twice with
the concrete towpath.
The question then arises as to why a cervical spine injury was not
suspected. The answer, I believe, is that whist the history I gave on
admission to hospital was very similar to the account given above,
the version that appeared in my medical record was closer to
“55‐year‐old lady, fell off bike.” The obvious fractures in the upper
limbs were, it seemed, sufficient explanation for the pain and numb-
ness in my fingers.
Whilst my impacted fractured radius was not accompanied by
dorsal displacement of the distal fragment (the classic “fork” shape
of the eponymic Colles fracture13), it was described as such by the
orthopaedic registrar who attempted unsuccessfully to reduce it.
(Indeed, I called this injury a Colles fracture myself until I explored
the literature in more detail and discovered my error.) This is impor-
tant. As Porrino et al explain in their review of the epidemiology of
fractures of the distal radius, the condition is patterned very differ-
ently in different age groups. In both teenagers and adults aged up
to 50 years, distal radius fractures are commoner in males and most
commonly result from sporting or road traffic accidents; they are not
associated with low bone density but linked to particular activities
and lifestyles.13 In the over 50s, distal radius fractures are more
common in women (and usually show the classic fork shape); these
Colles fractures are associated with osteopenia (low bone density)
and broadly follow the epidemiological pattern of other “fragility frac-
tures” (eg, hip and thoracic spine).
FIGURE 1
Extract from NICE Guideline 76 “Head Injury”12
GREENHALGH
1135
 Describing my right‐sided injury as a Colles fracture, then, aligned
the clinical gaze to an “ideal type” of a postmenopausal woman with
fragility fracture resulting from a relatively low‐impact fall onto the
outstretched hand. The Colles fracture stereotype, along with my
age (just days after my 55th birthday, which put me into the denomi-
nator population of “the over‐55s”), led the doctors looking after me to
reach for what seemed to be the appropriate guideline: covering falls
prevention in older people.
The guideline in use at the time was the 2013 version of NICE
Guideline 161,14 which defined “older people” in the community as
those over 65 and “older people” in hospital inpatients as those over
50. Since I was lying in a hospital bed, I was presumably considered
to be a member of the latter group—yet closer inspection of the guide-
line suggests that this was a misclassification. I was only in hospital as
a result of a fall that happened outside the hospital. The section of the
guideline relating to falls prevention in hospital explicitly relates to (a)
all over‐65s and (b) those inpatients aged 50 to 65 years who are
considered at risk of falling because of an underlying condition (para-
graph 1.2.1.2).
In other words, whoever sent the pleasant lady along with her
clipboard to assess my medication, cognitive function, balance, hear-
ing, and much else besides with a view to falls prevention was not
following an evidence‐based guideline—though I'm sure the attending
clinician believed that this was what they had ordered. The falls pre-
vention co‐ordinator sensibly abandoned her “evidence‐based” check-
list when she listened to my story—which was unambiguously one of
high‐impact trauma in someone who was otherwise fit and well.
The next question—and the third guideline in this narrative—
addresses whether I should have been offered a cervical discectomy
and decompression surgery. In response to a 140‐character question
posted by me on Twitter, many of my medically qualified followers
immediately answered “no.” Which evidence were they following
when they offered this advice? The answer appears to be “evidence
that does not apply to this patient.”
Here is where I think my well‐meaning advisers went astray. First,
they were aware of the evidence‐based finding that most people with
neck pain and even most people with cervical radiculopathy (that is,
symptoms in the arms resulting from nerve root compression or
tension) do no better following cervical spine surgery than they do with
conservative management.15 Second, they were aware that many if not
most patients who are being considered as potential candidates for
cervical spine surgery are suffering from common or garden cervical
spondylosis and do not have “red flag” symptoms or signs.15 It is there-
fore absolutely correct to say that, on average, patients who are contem-
plating going under the knife for their neck pain or neck‐related arm pain
(radiculopathy) would be ill‐advised to rush into surgery.
Now let us take a look at the NICE Clinical Knowledge Summary
on neck pain.16 It divides patients with radiculopathy into 3 groups:
those with “red flag” signs or symptoms; those without red flags and
a history of less than 4 to 6 weeks; and those without red flags whose
symptoms have persisted beyond 4 to 6 weeks. The knowledge
summary recommends the 2 latter groups be offered conservative
management—with pain relief, physiotherapy, lifestyle measures, and
(in longstanding cases only) magnetic resonance imaging. But red
flags—including a history of severe trauma (Figure 2)—should prompt
urgent referral and bespoke management of the underlying cause.
Randomized controlled trials demonstrating the lack of efficacy of
cervical spine surgery compared with conservative management typi-
cally exclude unusual presentations and individuals with red flag
features (see, for example, Engquist et al17). Tellingly, my Twitter
advisers had not asked me about red flags.
My final question relates to NSAIDs as opioid‐sparing analgesics
in the aftermath of spinal surgery. Again, Twitter was a rich source
of advice—and also a source of confusion in the identification and
interpretation of evidence. Whilst several respondents referred
obliquely or implicitly to “guidance,” no actual guideline was cited,
rather received wisdom was presented as if it was evidence based.
My own search of the literature could not identify a relevant guideline
(though I suspect one may exist somewhere)—but it did identify some
small studies of rodents in whom NSAIDs had apparently reduced the
bone healing rate (for example, Gerstenfeld et al18) and retrospective
case series of human patients with nonunion of bone, some of whom
had received NSAIDs (for example, Giannoudis et al19).
My search also identified 2 systematic reviews, both of which had
sought to throw light on the controversy of whether NSAIDs delay
bone healing in surgical patients.20,21 Both concluded that the evi-
dence base was weak and conflicting; they called for more and better
basic science studies as well as well‐designed RCTs. One commented:
“Animal and in vitro studies present so conflicting data that even stud-
ies with identical parameters have opposing results” (page 1).20 The
strongly held view that NSAIDs should not be given after spinal
surgery appears to be no more than a nonevidence‐based meme.
This view was reflected in the advice of 1 or 2 surgeons in my Twit-
ter following, who suggested (based on their clinical experience) that in
the absence of specific contraindications, NSAIDs after spinal surgery
are effective and safe and that they “get you up and about quickly.”
My own medical history is relevant here: As a young adult, I sustained
a number of stress fractures (metatarsal and tibial). They were treated
with high‐dose NSAIDs, and I returned to sport quickly (and ahead of
prediction) in each case. So I knew that whatever had happened to
experimental rats and patients undergoing hip replacement in method-
ologically weak studies in faraway places, in my case there was already
evidence that NSAIDs did not delay healing of my bones.
4
|
DISCUSSION
This study has considered how guidelines influenced—or failed to
influence—4 aspects of a single clinical case study told from the
perspective of the patient: (a) a guideline that existed and was relevant
FIGURE 2
Extract from NICE Clinical
Knowledge Summary “Cervical
Radiculopathy” 16
1136
GREENHALGH
 but which was not used (imaging of the cervical spine in acute head
injury); (b) a guideline that was not relevant but which was used (falls
prevention in older people); (c) a guideline that was relevant but was
misremembered and misapplied by commentators claiming to be giving
evidence‐based advice (management of cervical radiculopathy); and (d)
a guideline that did not exist but which was quoted by adherents of
EBM as if it had existed (and which was also misremembered and
misapplied).
This case study suggests—though it does not itself prove—that
despite a whole generation of research into EBM, the medical
profession remains mired in the problem that Sir John Grimley Evans
described in 1995:
There is a fear that in the absence of evidence clearly
applicable to the case in the hand a clinician might be
forced by guidelines to make use of evidence which is
only
doubtfully
relevant,
generated
perhaps
in
a
different grouping of patients in another country at
some other time and using a similar but not identical
treatment. This is evidence‐biased medicine; it is to use
evidence in the manner of the fabled drunkard who
searched under the street lamp for his door key because
that is where the light was, even though he had
dropped the key somewhere else. (page 451)22
Given the effort and expense that goes into producing guidelines,
and the philosophical arguments in favour of case‐based management
set out in the Introduction, why are we continuing to use these
resources in such a drunken way? I propose 3 explanations, the first
2 of which are psychological and the third sociological.
The first explanation is our inbuilt tendency to classify. As sociol-
ogists Geoff Bowker and Susan Leigh Star observed in their excellent
book Sorting Things Out: Classification and Its Consequences, we create
classification schemes (such as the ICD10 or targeted risk groups).23
When we encounter a patient, instead of attending to the unique
particularities of that individual, we hasten to classify them as a
member of some group or other. Once we have done that, the average
characteristics of the group not only inform but also become enshrined
in clinical guidelines and recommendations. This has the effect of
ossifying and reproducing our clinical and cultural stereotypes, which
now appear as scientific “facts.”
The second explanation is bounded rationality—that is, the idea
that because real‐world decisions often involve numerous options,
outcomes, and contextual factors, we unconsciously simplify the
problem to make it possible to cope with cognitively and manage prac-
tically.24 Indeed, the inexorable pressures of modern clinical work
often require us to use such “fast and frugal” reasoning.25 As
Kahnemann showed in the book Thinking, Fast and Slow that won
him the Nobel Prize for Economics, such heuristics give our species
a survival advantage.26 So it is not necessarily a bad thing that clini-
cians hasten to classify (so they can treat the group rather than the
individual) and then apply an oversimplified version of rules and proce-
dures. It does, however, follow that a critical dimension of clinical
judgement is knowing (at least at an intuitive level) which patients to
manage using fast thinking (based on crude classification) and which
require us to revert to slow thinking (individualized management).
The third explanation for our drunken use of guidelines is the
over‐valuing of rationality (doing the thing right—as in following rules
and guidelines) over reason (doing the right thing—as in making the
right moral choice for this patient at this time, given these contingen-
cies). As sociologist Andrew Sayer wrote in his book Why Things
Matter to People,27 and as Anthony Giddens explored in The Constitu-
tion of Society, the encroachment of rationality over reason (and the
particular phenomenon of the “expert system” that applies technology
to impose distant rules and procedures over the granularity of local
social situations) characterizes many sectors of modern society.28
It is both a strength and a weakness of EBM that so much of clin-
ical practice is now highly structured, based on rational classificatory
schemes and standardized procedures, and auditable from a distance.
We depict clinical practice as the science of advanced rule‐following
rather than the practice of case‐based moral reasoning. We train med-
ical students, for example, to perform in predictable, standardized
ways in highly standardized scenarios (“objective structured clinical
examinations” or OSCEs),29 with the implication that every time we
manage renal colic, investigate pelvic pain, or break bad news, there
is a universally “right” (and, implicitly, a “wrong”) way of going about it.
The quote from the 1982 Kassirer paper reproduced in the Intro-
duction suggests otherwise. In that scenario, the clinician is engaging
(with considerable enthusiasm, it appears) with a unique and dynami-
cally unfolding narrative, altering his or her assessment of the case
iteratively as additional patient‐derived evidence accumulates.7 Whist
she or he is aware of a (1982‐level) evidence base pertinent to the
case, the main focus of the questioning is the patient, not the
evidence. Unlike the typical contemporary clinician, Kassirer's inter-
viewee seeks to ground their decision making in what might be called
“patient‐based evidence,” which might be defined in terms of the
following questions:
What do I know about this patient: her history, the
findings from examining her, her test results, how she
reacted the last time she took this drug, her beliefs, her
family circumstances etc. And given all that, what
research evidence do I need to progress my clinical
reasoning?
In sum, my individual case narrative (deliberately chosen for being
atypical, thereby highlighting the difference between individual
evidence and population‐derived evidence) adds to a growing litera-
ture on the overuse, underuse, and misuse of clinical guidelines. The
existence of many thousands of evidence‐based guidelines is no guar-
antee that the right section of the right guideline will be applied to the
right patient at the right time. On the contrary, the accumulation of
unmanageable numbers of lengthy guidelines makes it ever more likely
that the clinician at the front line will manage his or her patients using
early categorization, frugal heuristics, and a privileging of operational
rationality over case‐based moral reasoning.
In light of this, how can we ensure that evidence‐based guidelines
are our servant rather than our master in our pursuit of good clinical
care? At the very least, we must treat guidelines with the scepticism
they deserve—remembering that the best of them is nothing more
than a statement of what is likely to happen to the average member
of a defined group of patients. We must also learn to value, and
GREENHALGH
1137
 ensure that we seek, patient‐based evidence through unfolding clinical
conversations. And we should always bear in mind Grimley Evans'
cautionary metaphor: if we did not drop our car keys under the lamp
post, there is no point looking for them in that spot.
ACKNOWLEDGEMENT
T.G.'s work on this paper was part‐funded by a National Institute for
Health
Research
Biomedical
Research
Centre,
Oxford,
grant
BRC‐1215‐20008 to the Oxford University Hospitals NHS Foundation
Trust and the University of Oxford.
ORCID
Trisha Greenhalgh
http://orcid.org/0000-0003-2369-8088
REFERENCES
1. Greenhalgh T. Adjuvant chemotherapy: an autoethnography. Subjectiv-
ity. 2017;10(4):340‐357.
2. GreenhalghT, Howick J, Maskrey N. Evidence based medicine: a move-
ment in crisis? BMJ (Clinical research ed). 2014;g3725:348.
3. Valkenburg G, Achterhuis H, Nijhof A. Fundamental shortcomings of
evidence‐based medicine. J Health Organ Manag. 2003;17(6):463‐471.
4. Deaton
A,
Cartwright
N.
Understanding
and
misunderstanding
randomized controlled trials. Soc Sci Med. 2018.
5. National Institute for Health and Clinical Excellence. How We Develop
NICE Guidelines. Accessed 24.2.18 at https://www.nice.org.uk/about/
what‐we‐do/our‐programmes/nice‐guidance/nice‐guidelines/
how‐we‐develop‐nice‐guidelines. London: NICE; 2018.
6. Kelly MP, Moore TA. The judgement process in evidence‐based
medicine and health technology assessment. Social Theory & Health.
2012;10(1):1‐19.
7. Kassirer JP, Kuipers BJ, Gorry GA. Toward a theory of clinical exper-
tise. Am J Med. 1982;73(2):251‐259.
8. Tonelli M. The philosophical limits of evidence‐based medicine. Acad
Med. 1999;73:1234‐1240.
9. Engebretsen E, Vøllestad NK, Wahl AK, Robinson HS, Heggen K.
Unpacking the process of interpretation in evidence‐based decision
making. J Eval Clin Pract. 2015;21:529–531.
10. Greenhalgh T, Wengraf T. Collecting stories: is it research? Is it good
research? Preliminary guidance based on a Delphi study. Med Educ.
2008;42(3):242‐247.
11. Denzin N. Interpretive Autoethnography. London: Sage; 2013.
12. National Institute for Health and Clinical Excellence. Head Injury. NICE
Guideline 76. London: NICE; 2014.
13. Porrino Jr JA, Maloney E, Scherer K, Mulcahy H, Ha AS, Allan C. Frac-
ture
of
the
distal
radius:
epidemiology
and
premanagement
radiographic characterization. Am J Roentgenol. 2014;203(3):551‐559.
14. National Institute for Health and Clinical Excellence. Falls in older peo-
ple: assessing risk and prevention. In: NICE Guideline. Vol.161 London:
NICE; 2013.
15. Binder AI. Cervical spondylosis and neck pain. BMJ: British Medical
Journal. 2007;334(7592):527‐531.
16. National Institute for Health and Clinical Excellence. Neck Pain–Cer-
vical Radiculopathy. Clinical Knowledge Summary.
London: NICE;
2015.
17. Engquist M, Löfgren H, Öberg B, et al. Surgery versus nonsurgical
treatment of cervical radiculopathy: a prospective, randomized study
comparing surgery plus physiotherapy with physiotherapy alone with
a 2‐year follow‐up. Spine. 2013;38(20):1715‐1722.
18. Gerstenfeld LC, Thiede M, Seibert K, et al. Differential inhibition of
fracture healing by non‐selective and cyclooxygenase‐2 selective
non‐steroidal
anti‐inflammatory
drugs.
J
Orthop
Res.
2003;21(4):670‐675.
19. Giannoudis P, MacDonald D, Matthews S, Smith R, Furlong A, De Boer
P. Nonunion of the femoral diaphysis: the influence of reaming and
non‐steroidal
anti‐inflammatory
drugs.
Bone
&
Joint
Journal.
2000;82(5):655‐658.
20. Pountos I, Georgouli T, Calori GM, Giannoudis PV. Do nonsteroidal
anti‐inflammatory drugs affect bone healing? A critical analysis.
Scientific World Journal. 2012;2012:1‐14.
21. Konstantinidis IN, Papageorgiou S, Kyrgidis A, Tzellos G, Kouvelas
D. Effect of non‐steroidal anti‐inflammatory drugs on bone turn-
over:
an
evidence‐based
review.
Rev
Recent
Clin
Trials.
2013;8(1):48‐60.
22. Evans JG. Evidence‐based and evidence‐biased medicine. Age Ageing.
1995;24(6):461‐463.
23. Bowker GC, Star SL. Sorting Things Out: Classification and Its Conse-
quences. Cambriged, MA MIT Press; 2000.
24. Gigerenzer G, Selten R. Bounded Rationality: The Adaptive Toolbox.
Cambridge, London MIT Press; 2002.
25. Gigerenzer G, Goldstein DG. Reasoning the fast and frugal way:
models of bounded rationality. Psychol Rev. 1996;103(4):650‐669.
26. Kahneman D. Thinking, Fast and Slow. Basingstoke Macmillan; 2011.
27. Sayer A. Why Things Matter to People.
Cambridge: Cambridge
University Press; 2011.
28. Giddens A. The Constitution of Society: Outline of the Theory of Structur-
ation. Berkeley, CA: Univ of California Press; 1984.
29. Atkins S, Roberts C, Hawthorne K, Greenhalgh T. Simulated con-
sultations:
a
sociolinguistic
perspective.
BMC
Med
Educ.
2016;16(1):16.
How to cite this article: Greenhalgh T. Of lamp posts, keys,
and fabled drunkards: A perspectival tale of 4 guidelines. J Eval
Clin
Pract.
2018;24:1132–1138.
https://doi.org/10.1111/
jep.12925
1138
GREENHALGH
